<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>记录思考</title>
  
  <subtitle>ML、DL、NLP</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ilewseu.github.io/"/>
  <updated>2018-05-12T15:29:18.900Z</updated>
  <id>https://ilewseu.github.io/</id>
  
  <author>
    <name>luerwei</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>统计语言模型</title>
    <link href="https://ilewseu.github.io/2018/05/07/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    <id>https://ilewseu.github.io/2018/05/07/语言模型/</id>
    <published>2018-05-07T11:06:20.000Z</published>
    <updated>2018-05-12T15:29:18.900Z</updated>
    
    <content type="html"><![CDATA[<h2 id="语言模型概述"><a href="#语言模型概述" class="headerlink" title="语言模型概述"></a>语言模型概述</h2><p>语言模型(Language Model)，就是用来计算一个句子概率的模型。从统计的角度看，自然语言中的一个句子可以由任何词串构成。不过P(s)有大有小。比如：<br><a id="more"></a></p><ul><li>s1 = 我 刚 吃 过 晚饭</li><li>s2 = 刚 我 过 晚饭 吃</li></ul><p>可以看出P(s1)&gt;P(s2)。对于给定的句子而言，通常P(s)是未知的。对于一个服从某个概率分布P的语言L，根据给定的语言样本估计P的过程被称作语言建模。<br>根据语言样本估计出的概率分布P就称为语言L的语言模型。<br>$$\sum_{s\in L}P(s)=1$$<br>语言建模技术首先在语音识别研究中提出，后来陆续用到OCR、手写体识别、机器翻译、信息检索等领域。在语音识别中，如果识别结果有多个，则可以根据语言模型计算每个识别结果的可能性，然后挑选一个可能性较大的识别结果。语言模型也可以用于汉语歧义消解。<br>那么如何计算一个句子的概率呢？对于给定的句子:<br>$$S=w_1w_2,…,w_n$$<br>它的概率可以表示为：<br>$$P(S)=P(w_1,w_2,…,w_n)=P(w_1)P(w_2|w_1)…P(w_n|w_1,w_2,…,w_{n-1})$$<br>由于上面的式子参数过多，因此需要近似的计算方法，常见的方法有n-gram模型方法、决策树方法、最大熵模型方法、最大熵马尔科夫模型方法、条件随机场(CRF)方法、神经网络方法等。本篇文章主要记录n-gram模型方法。</p><h2 id="n-gram模型"><a href="#n-gram模型" class="headerlink" title="n-gram模型"></a>n-gram模型</h2><p>对于给定的句子$S=w_1w_2…w_n,$,根据链式规则:<br>$$<br>P(S)=P(w_1,w_2,…,w_n)=P(w_1)P(w_2|w_1)…P(w_n|w_1,w_2,…,w_{n-1})=\prod_{i=1}^np(w_i|w_1…w_{i-1})<br>$$<br>P(S)就是语言模型，即用来计算一个句子S概率的模型。<br>那么，如何计算$p(w_i|w_1,w_2,…,w_{i-1})$呢？最简单、直接的方法是计数后做除法，即最大似然估计(Maximum Likelihood Estimate，MLE)，如下：<br>$$<br>p(w_i|w_1,w_2,…,w_{i-1})=\frac {count(w_1,w_2,…,w_{i-1},w_i)}{count(w_1,w_2,…,w_{i-1})}<br>$$<br>其中，$count(w_1,w_2,…,w_{i-1},w_i)$表示次序列$(w_1,w_2,…,w_{i-1},w_i)$在预料库中出现的频率。</p><p>这里面临两个重要的问题：数据稀疏严重和参数空间过大，导致无法实用。实际中，我们一般较长使用N语法模型(n-gram)，它采用了马尔科夫假设，即认为语言中的每个词只与其前面长度为n-1的上下文有关。</p><ul><li><p>假设下一个词的出现不依赖前面的词，即为uni-gram，则有:$$ \begin {aligned}<br>  P(S)&amp;=P(w_1)P(w_2|w_1)p(w_3|w_2,w_1)…p(w_n|w_1,w_2,…,w_{n-1})\\\\&amp;=p(w_1)p(w_2)…p(w_n)<br>\end{aligned}$$</p></li><li><p>假设下一个词的出现只依赖前面的一个词，即为bi-gram，则有：$$ \begin {aligned}<br>  P(S)&amp;=P(w_1)P(w_2|w_1)p(w_3|w_2,w_1)…p(w_n|w_1,w_2,…,w_{n-1})\\\\&amp;=p(w_1)p(w_2|w_1)p(w_3|w_2)…p(w_n|w_{n-1})<br>\end{aligned}$$</p></li><li>假设下一个词的出现依赖它前面的两个词，即为tri-gram，则有：<br>$$<br>\begin {aligned} P(S)&amp;=P(w_1)P(w_2|w_1)p(w_3|w_2,w_1)…p(w_n|w_1,w_2,…,w_{n-1})\\\\&amp;=p(w_1)p(w_2|w_1)p(w_3|w_1,w_2)…p(w_n|w_{n-2},w_{n-1})<br>\end {aligned}<br>$$</li></ul><p>实际上常常在对数空间里面计算概率，原因有两个：</p><ul><li>防止溢出；如果计算的句子很长，那么最后得到的结果将非常小，甚至会溢出，比如计算得到的概率是0.001，那么假设以10为底取对数的结果就是-3，这样就不会溢出；</li><li>对数空间里面加法可以代替乘法，因为log(p1p2) = logp1 +logp2，在计算机内部，显然加法比乘法执行更快；</li></ul><h3 id="n-gram中的n如何选择？"><a href="#n-gram中的n如何选择？" class="headerlink" title="n-gram中的n如何选择？"></a><strong>n-gram中的n如何选择？</strong></h3><ul><li><strong>n较大时</strong>：提供了更多的上下文语境信息，语境更具有区别性；但是，参数个数多、计算代价大、训练预料需要多，参数估计不可靠；</li><li><strong>n较小时</strong>：提供的上下文语境少，不具有区别性；但是，参数个数小、计算代价小、训练预料无须太多、参数估计可靠；</li></ul><p>理论上，n越大越好，经验上tri-gram用的最多，尽管如此，原则上，<strong>能用bi-gram解决，绝不使用tri-gram</strong>。</p><h3 id="建立n-gram语言模型"><a href="#建立n-gram语言模型" class="headerlink" title="建立n-gram语言模型"></a>建立n-gram语言模型</h3><p>构建n-gram语言模型，通过计算最大似然估计构造语言模型。一般的过程如下：</p><ul><li><strong>1、数据准备：</strong><ul><li>确定训练语料</li><li>对语料进行tokenization或切分</li><li>句子边界，增加特殊的词<bos>和<eos>开始和结束</eos></bos></li></ul></li><li><strong>2、参数估计：</strong><ul><li>利用训练语料，估计模型参数</li></ul></li></ul><p>令$c(w_1,…,w_n)$表示n-gram $w_1,…,w_n$在训练语料中出现的次数，则：<br>$$<br>    P_{MLE}(w_n|w_1,…,w_{n-1})=\frac {c(w_1,…,w_n)}{c(w_1,…,w_{n-1})}<br>$$</p><h3 id="语言模型效果评估"><a href="#语言模型效果评估" class="headerlink" title="语言模型效果评估"></a>语言模型效果评估</h3><p>目前主要有两种方法判断建立的语言模型的好坏：</p><ul><li>实用方法：通过查看该模型在实际应用（如拼写检查、机器翻译）中的表现来评价，优点是直观、实用，缺点是缺乏针对性、不够客观；</li><li>理论方法：困惑度(preplexity)，其基本思想是给测试集赋予较高概率值的语言模型较好；</li></ul><h2 id="平滑方法"><a href="#平滑方法" class="headerlink" title="平滑方法"></a>平滑方法</h2><p>最大似然估计给训练样本中未观察到的事件赋以0概率。如果某个n-gram在训练语料中没有出现，则该n-gram的概率必定是0。这就会使得在计算某个句子S的概率时，如果某个词没有在预料中出现，那么该句子计算出来的概率就会变为0，这是不合理的。<br>解决的办法是扩大训练语料的规模。但是无论怎样扩大训练语料，都不可能保证所有的词在训练语料中均出现。由于训练样本不足而导致估计的分布不可靠的问题，称为数据稀疏问题。在NLP领域中，稀疏问题永远存在，不太可能有一个足够大的语料，因为语言中的大部分词都属于低频词。</p><h3 id="Zipf定律"><a href="#Zipf定律" class="headerlink" title="Zipf定律"></a>Zipf定律</h3><p>Zipf定律描述了词频以及词在词频表中的位置之间的关系。针对某个语料库，如果某个词w的词频是f，并且该词在词频表中的序号为r(即w是所统计的语料中第r常用词)，则：<br>$$f*r=k(k是一个常数)$$<br>若$w_i$在词频表中的排名50，$w_j$在词频表中排名为150，则$w_i$的出现频率大约是$w_j$的频率的3倍。<br>Zipf定律告诉我们：</p><ul><li>语言中只有很少的常用词</li><li>语言中的大部分词都是低频词（不常用的词)</li></ul><p>Zipf的解释是Principle of Lease effort </p><ul><li>说话的人只想使用少量的常用词进行交流</li><li>听话的人只想使用没有歧义的词（量大低频）进行交流</li></ul><p>Zipf定律告诉我们：</p><ul><li>对于语言中的大多数词，它们在语料中出现是稀疏的</li><li>只有少量的词语料库可以提供它们规律的可靠样本</li></ul><h3 id="平滑技术"><a href="#平滑技术" class="headerlink" title="平滑技术"></a>平滑技术</h3><p>对于语言而言，由于数据稀疏的存在，MLE不是一种很好的参数估计方法。为了解决数据稀疏问题，人们为理论模型实用化而进行了众多的尝试，出现了一系列的平滑技术，<strong>它们的基本思想是降低已出现n-gram的条件概率分布，以使未出现的n-gram条件概率分布为非零，且经过平滑后保证概率和为1。</strong>目前，已经提出了很多数据平滑技术，如下：</p><ul><li>Add-one平滑</li><li>Add-delta平滑 </li><li>Good-Turing平滑</li><li>Interpolation平滑</li><li>回退模型-Katz平滑</li><li>…</li></ul><h4 id="Add-one平滑"><a href="#Add-one平滑" class="headerlink" title="Add-one平滑"></a>Add-one平滑</h4><p>加一平滑法，又称为拉普拉斯定律，其规定任何一个n-gram在训练预料中至少出现一次（即规定没有出现过的n-gram在训练预料中出现了1次）</p><p>$$P_{Add1}(w_1,w_2,…,w_n)=\frac {C(w_1,w_2,…,w_n)+1}{N+V}$$</p><ul><li>N:为训练预料中所所有的n-gram的数量(token);</li><li>V:所有的可能的不同的n-gram的数量(type);<br>下面两幅图分别演示了未平滑和平滑后的bi-gram示例：</li></ul><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180505/d6ljdKdckd.jpg?imageslim" alt="mark"></p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180505/EG0fA48HjC.jpg?imageslim" alt="mark"></p><p>(注：上图均来自《计算语言学-常宝宝》的课件)</p><p>训练语料中未出现的n-gram的概率不再为0，而是一个大于0的较小的概率值。但是，由于训练预料中未出现的n-gram数量太多，平滑后，所有未出现的n-gram占据了整个概率分布中的一个很大的比例。因此，在NLP中，Add-one给训练预料中没有出现过的n-gram分配太多的概率空间。同时，它认为所有未出现的n-gram概率相等，这是否合理？出现在训练语料中的哪些n-gram，都增加同样频度值，不一定合理。</p><h4 id="Add-delta平滑"><a href="#Add-delta平滑" class="headerlink" title="Add-delta平滑"></a>Add-delta平滑</h4><p>Add-delta平滑，不是加1，而是加一个比1小的整数$\lambda$:<br>$$<br>P_{AddD}(w_1,w_2,…,w_n)=\frac {C(w_1,w_2,…,w_n)+\lambda}{N+\lambda V}<br>$$<br>通常$\lambda =0.5$，此时又称为Jeffreys-Perks Law或ELE。它的效果要比Add-one好，但是仍然不理想。</p><h4 id="Good-Turing平滑"><a href="#Good-Turing平滑" class="headerlink" title="Good-Turing平滑"></a>Good-Turing平滑</h4><p>其基本思想是利用频率的类别信息对频率进行平滑。假设N是样本数据的大小，$n_r$是在样本中正好出现r次的事件的数目(在这里，事件为n-gram $w_1,w_2,…,w_n$)。即：出现1的$n_1$个，出现2次的$n_2$个,…。那么：<br>$$<br>N=\sum_{r=1}^{\infty} n_r r<br>$$<br>由于，$$N=\sum_{r=0}^{\infty}n_r r^*=\sum_{r=0}^{\infty}(r+1)n_{r+1}$$，所以，<br>$$<br>r^* = (r+1)\frac {n_{r+1}}{n_r}<br>$$</p><p>那么，Good-Turing估计在样本中出现r次的事件的概率为:<br>$$<br>P_r = \frac {r^*}{N}<br>$$<br>实际应用中，一般直接使用$n_{r+1}$代替$E(n_{r+1})$，$n_r$代替$E(n_r)$。这样，样本中所有事件的概率之和为：<br>$$<br>\sum_{r&gt;0} n_r * P_r = 1 - \frac {n_1}{N} &lt;1<br>$$<br>因此，有$\frac {n_1}{N}$的剩余的概率量就可以均分给所有未出现事件(r=0)。<br>Good-Turing估计适用于大词汇集产生的符合多项式分布的大量的观察数据。<br>在估计频度为r的n-gram的概率$p_r$时，如果数据集中没有频度为r+1的n-gram怎么办？此时，$N_{r+1}=0$导致$p_r=0$。解决的办法是对$N_r$进行平滑，设S(.)是平滑函数，S(r)是$N_r$的平滑值。<br>$$<br>r^* = (r+1)\frac {S(r+1)}{S(r)}<br>$$</p><h4 id="Interpolation平滑"><a href="#Interpolation平滑" class="headerlink" title="Interpolation平滑"></a>Interpolation平滑</h4><p>不管是Add-one，还是Good Turing平滑技术，对于未出现的n-gram都一视同仁，难免存在不合理性。所以介绍一种线性差值的的平滑技术，其基本思想是将高阶模型和低阶模型作线性组合，利用低阶n-gram模型对高阶n-gram模型进行线性差值。因为没有足够的数据对高阶n-gram模型进行概率估计时，低阶的n-gram模型通常可以提供有用的信息。因此，可以把不同阶的n-gram模型组合起来产生一个更好的模型。</p><p>把不同阶别的n-gram模型线性加权组合：<br>$$P(w_n|w_{n-1},w_{n-2})=\lambda_1P(w_n)+\lambda_2P(w_n|w_{n-1})+\lambda_3P(w_n|w_{n-1}w_{n-2})$$<br>其中，$0&lt;=\lambda_i&lt;=1,\sum_i \lambda_i=1$。$\lambda_i$可以根据实验凭经验设定，也也可以通过应用某些算法确定，例如EM算法。</p><h4 id="回退模型-Katz平滑"><a href="#回退模型-Katz平滑" class="headerlink" title="回退模型-Katz平滑"></a>回退模型-Katz平滑</h4><p>回退模型-Katz平滑，其基本思想是：当某一事件在样本中出现的概率大于K(通常K为0或1)，运用最大似然估计减值来估计其概率，否则使用低阶的，即(n-1)gram概率代替n-gram概率。而这种替代必须受归一化因子$\alpha$的作用。回退模型的一般形式如下：<br>$$<br>p_{smooth}(w_i|w_{i-n+1}^{i-1})=\begin{cases}<br>             \hat p(w_i|w_{i-n+1}^{i-1}), &amp;  if c(w_{i-n+1}^i)&gt;0 \\<br>             \alpha(w_{i-n+1}^{i-1})\cdot p_{smooth}(w_i|w_{i-n+2}^{i-1}), &amp; if c(w_{i-n+1}^{i-1})=0<br>            \end{cases}$$<br>参数$\alpha(w_{i-n+1}^{i-1})$是归一化因子，以保证$$\sum_{w_i}p_{smooth}(w_i|w_{i-n+1}^{i-1})=1$$<br>以bi-gram为例，令$r=c(w_{i-1}w_i)$，如果r&gt;0，则$p_{katz}(w_i|w_{i-1})=d_r\cdot p_{ML}(w_i|w_{i-1})$，$d_r$称为折扣率，给定$w_{i-1}$，从r&gt;0的bi-grams中折除的概率为：$$<br>S(w_{i-1}) = 1 - \sum_{w_i \in M(w_{i-1})} p_{katz}(w_i|w_{i-1}) \\其中，M(w_{i-1})={w_i|c(w_{i-1}w_i)&gt;0}<br>$$</p><p>对于给定的$w_{i-1}$，令：$$<br>Q(w_{i-1}) = {w_i|c(w_{i-1}w_i)=0}<br>$$<br><strong>如何把$S(w_{i-1})$分配给集合$Q(w_{i-1})$中的那些元素？</strong></p><p>对于$w_i \in Q(w_{i-1})$，如果$p_{ML}(w_i)$比较大，则应该分配更多的概率给它。所以，若r=0，则：$$<br>p_{katz}(w_i|w_{i-1})=\frac {p_{ML}(w_i)}{\sum_{w_j\in Q}p_{ML}(w_j)} \cdot S(w_{i-1})<br>$$<br>对于bi-gram模型，Katz平滑为：<br>$$p_{katz}(w_i|w_{i-1})=<br>             \begin{cases}<br>             d_r\cdot p_{ML}(w_i|w_{i-1}), &amp;  if r&gt;0 \\<br>             \alpha(w_{i-1}) \cdot p_{ML}(w_i), &amp; if r=0<br>             \end{cases}<br>\\<br>其中，\alpha(w_{i-1}) = \frac {1 - \sum_{w_j\in M} p_{katz}(w_j|w_{j-1}) }{\sum_{w_j\in Q} p_{ML}(w_j)}<br>$$</p><p><strong>如何计算$d_r$?</strong></p><ul><li>如果$r&gt;k$，不折扣，即$d_r=1$(Katz提出k=5)</li><li>如果$0&lt;r \leq k$，按照和Good-Turing估计同样的方式折扣，即按照$\frac {r^{*}}{r}$进行折扣。严格说，要求$d_r$满足，$1-d_r=u(1-\frac {r^{*}}{r})$</li><li>根据Good-Turing估计，未出现的n元组估计出现频次是$n_1$，$\sum_{r=1}^k n_r(1-d_r)r=n$</li><li>具体而言，若$0&lt;r \leq k$，有$$<br>d_r = \frac {\frac {r^*}{r} - \frac {(k+1)n_{k+1}}{n_1}} {1 - \frac {(k+1)n_{k+1}}{n!}}<br>$$</li></ul><p>big-gram的Katz平滑模型最终可描述为：<br>$$p_{katz}(w_i|w_{i-1})=\begin{cases}<br>             c(w_{i-1}w_i)/c(w_{i-1}), &amp;  if r&gt;k \\<br>             d_rc(w_{i-1}w_i)/c(w_{i-1}), &amp; if k \geq r &gt; 0 \\<br>             \alpha (w_{i-1})p_{katz}(w_i) &amp; r=0<br>             \end{cases}<br>$$<br>n-gram模型的Katz平滑可以此类推。<br>在回退模型和线性插值模型中，当高阶n-gram未出现时，使用低阶n-gram估算高阶n-gram的概率分布。在回退模型中，高阶n-gram一旦出现，就不再使用低阶n-gram进行估计。在线性插值模型中，无论高阶n-gram是否出现，低阶n-gram都会被用来估计高阶n-gram的概率分布。</p><h2 id="大规模n-gram的优化"><a href="#大规模n-gram的优化" class="headerlink" title="大规模n-gram的优化"></a>大规模n-gram的优化</h2><p>如果不想自己动手实现n-gram语言模型，推荐几款开源的语言模型项目：</p><ul><li>SRILM(<a href="http://www.speech.sri.com/projects/srilm/" target="_blank" rel="external">http://www.speech.sri.com/projects/srilm/</a>)</li><li>IRSTLM(<a href="http://hlt.fbk.eu/en/irstlm" target="_blank" rel="external">http://hlt.fbk.eu/en/irstlm</a>)</li><li>MITLM(<a href="http://code.google.com/p/mitlm/" target="_blank" rel="external">http://code.google.com/p/mitlm/</a>)</li><li>BerkeleyLM(<a href="http://code.google.com/p/berkeleylm/" target="_blank" rel="external">http://code.google.com/p/berkeleylm/</a>)</li></ul><p>在使用 n-gram 语言模型时，也有一些技巧在里面。例如，面对 Google N-gram 语料库，压缩文件大小为 27.9G，解压后 1T 左右，如此庞大的语料资源，使用前一般需要先剪枝（Pruning）处理，缩小规模，如仅使用出现频率大于 threshold 的 n-gram，过滤高阶的 n-gram（如仅使用 n&lt;=3 的资源），基于熵值剪枝，等等。</p><p>另外，在存储方面也需要做一些优化:</p><ul><li>采样Trie数的数据结构，可以优化时间复杂度为$O(log_{|V|}m)$|V|为字母的个数；</li><li>借助Bloom filter辅助查询，把String映射为int类型处理；</li><li>利用郝夫曼树对词进行编码，将词作为索引值而不是字符串进行存储，能将所有词编码成包含在2个字节内的索引值；</li><li>优化概率值存储，概率值原使用的数据类型是（float），用4-8bit来代替原来8Byte的存储内容；</li></ul><h2 id="N-gram模型的缺陷"><a href="#N-gram模型的缺陷" class="headerlink" title="N-gram模型的缺陷"></a>N-gram模型的缺陷</h2><ul><li>数据稀疏问题：利用平滑技术解决；</li><li>空间占用大；</li><li>长距离依赖问题；</li><li>多义性；</li><li>同义性；如 “鸡肉”和“狗肉”属于同一类词，p(肉|鸡)应当等于p(肉|狗)，而在训练集中学习到的概率可能相差悬殊；</li></ul><h2 id="语言模型应用"><a href="#语言模型应用" class="headerlink" title="语言模型应用"></a>语言模型应用</h2><h3 id="n-gram距离"><a href="#n-gram距离" class="headerlink" title="n-gram距离"></a>n-gram距离</h3><p>假设有一个字符串s，那么该字符串的n-gram就表示按长度n切分原词得到的词段，也就是s中长度为n的子串。假设有两个字符串，然后分别求它们的n-gram，那么就可以从它们的共有子串的数量这个角度定义两个字符串间的n-gram距离。但是仅仅是简单地对共有子串进行计数显然也存在不足，这种方案忽略了两个字符长度的差异，可能导致的问题。比如，字符串girl和girlfriend，二者拥有的公共子串数量显然与girl和其自身所拥有的公共子串数量相等，但是不能认为girl和girlfriend是两个等同的匹配。为解决该问题，有学者便提出以非重复的n-gram分词为基础来定义n-gram距离这一概念，可以用下面的公式来表述：</p><p>$$|G_N(s)|+|G_N(t)|-2*|G_N(s)\cap G_N(t)|$$</p><p>例如，字符串s=”ABC”，t=”AB”，分别在字符串首尾加上begin和end，采用二元语言模型，字符串s产生的bi-gram为：(begin,A),(A,B),(B,C),(C,end)；字符串t产生的bi-gram为：(begin,A),(A,B),(B,end)。<br>采用上面公式定义:4+3 - 2*2 = 3<br>显然，字符串之间的距离越小，它们就越接近。当两个字符串完全相等的时候，它们之间的距离就是0。</p><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><p>分词是NLP中一项比较基础且重要的任务。对于X=”我爱中国”这样一句话，有多种切分方案，对于$y_i$这种分词方案，如,$Y_0=(“我”，“爱”，“中国”),Y_1=(“我”，“爱中”，“国”)$，利用贝叶斯公式可以计算出每种切分的概率:$$<br>P(Y_i|X)=\frac {P(X|Y_i)P(Y_i)}{P(X)}\propto P(X|Y_i)P(Y_i),i=1,2,3,…<br>$$<br>无论在哪种$Y_i$下，最终都能生成句子X，因此$P(X|Y_i)=1$，所以$P(Y_i|S)\propto P(Y_i),i=1,2,3…$。所以，只需要最大化$P(Y_i)即可$。例如，根据bi-gram语言模型，$P(Y_0|X)\propto P(Y_0)=P(我)P(爱|我)P(中国|爱)$，$P(Y_1|X)\propto P(Y_1)=P(我)P(爱中|我)P(国|爱中)$，然后利用计算出的概率，选择最大的作为分词方案。</p><h3 id="词性标注"><a href="#词性标注" class="headerlink" title="词性标注"></a>词性标注</h3><p>词性标注（POS tagging）是一个典型的多分类问题，将每个词标注为名词、动词、形容词、副词、代词等。例如，在“我/爱/中国”句话中，“爱”有很多词性，比如，名词、动词。最简单的标注其语义的方案就是，看语料库中“爱”出现的次数，以及其词性，即：<br>$$<br>P(POS_i|爱)=\frac {c(“爱”作为POS_i )}{c(爱),i=1,2,…,k，k为词性总数}<br>$$<br>但是，这种简单的词性标注的方案依赖人工，且未考虑上下文。考虑到在一个句子中当前词的词性和前面一两个词关系比较大。因此，可以借用n-gram模型的思路进行求解。比如，在考虑“爱”的词性时，以前面一个词的词性作为参考，即“我”的词性，则，当前这个“爱”的词性概率分布为:<br>$$P(POS_i|我，爱)=P(POS_i|Pron.,爱)=\frac {前面被“副词”修饰的“爱”的POS_i}{c(前面被“副词”修饰的“爱”)},i=1,2,…,k,k为词性总数$$</p><p>计算这个概率需要对语料库进行统计。但是，前提是先判断好“我”的词性。因为，采用的是bi-gram模型，由于“我”已经是第一个词，在二元模型中主需要级简的方案判断即可。</p><h3 id="n-gram作为文本特征"><a href="#n-gram作为文本特征" class="headerlink" title="n-gram作为文本特征"></a>n-gram作为文本特征</h3><p>在处理文本的特征的时候，通常一个关键词作为一个特征。但是，在某些场景下可能词的表达能力不够，需要提取更多的特征，n-gram就是一个很好的特征。以bi-gram为例，在原始文本中，每个关键词可以作为一个特征，将每个关键词两两组合，得到一个bi-gram组合，在根据n-gram语言模型，计算各个bi-gram组合的概率，作为新的特征。</p><h3 id="英语介词短语消歧"><a href="#英语介词短语消歧" class="headerlink" title="英语介词短语消歧"></a>英语介词短语消歧</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>我们是这样理解语言的；</li><li>《计算语言学-常宝宝》的课件</li><li><a href="https://www.cnblogs.com/ljy2013/p/6425277.html" target="_blank" rel="external">https://www.cnblogs.com/ljy2013/p/6425277.html</a></li><li><a href="https://blog.csdn.net/TiffanyRabbit/article/details/72654180" target="_blank" rel="external">https://blog.csdn.net/TiffanyRabbit/article/details/72654180</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;语言模型概述&quot;&gt;&lt;a href=&quot;#语言模型概述&quot; class=&quot;headerlink&quot; title=&quot;语言模型概述&quot;&gt;&lt;/a&gt;语言模型概述&lt;/h2&gt;&lt;p&gt;语言模型(Language Model)，就是用来计算一个句子概率的模型。从统计的角度看，自然语言中的一个句子可以由任何词串构成。不过P(s)有大有小。比如：&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="NLP" scheme="https://ilewseu.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>NLP基础-熵</title>
    <link href="https://ilewseu.github.io/2018/05/02/NLP%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E7%86%B5/"/>
    <id>https://ilewseu.github.io/2018/05/02/NLP中的各种熵/</id>
    <published>2018-05-02T12:52:20.000Z</published>
    <updated>2018-05-12T14:46:25.352Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一些基础"><a href="#一些基础" class="headerlink" title="一些基础"></a>一些基础</h2><h3 id="互斥"><a href="#互斥" class="headerlink" title="互斥"></a>互斥</h3><p>如果事件A和B不可能同时发生，即$AB=\Phi$，则称A与B是互斥的。<br><a id="more"></a></p><h3 id="对立"><a href="#对立" class="headerlink" title="对立"></a>对立</h3><p>如果A与B互斥，又在每次试验中不是出现A就是出现B，即$AB=\Phi$且$A+B=\Omega$，则称B是A的对立事件。</p><h3 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h3><p>在事件B发生的条件下，事件A发生的概率称为事件A在事件B已发生的条件下的条件概率，记作P(A|B)。当P(B)&gt;0时，规定:<br>$$<br>P(A|B)=\frac {P(AB)}{P(B)}<br>$$<br>当P(B)=0时，规定P(A|B)=0。由条件概率的定义，可以得到<strong>乘法公式</strong>：<br>$$\begin {aligned}<br>&amp;P(AB)=P(A)P(B|A)\\\\<br>&amp;P(A_1A_2…A_n)=P(A_1)P(A_2|A_1)P(A_3|A_2A_1)…P(A_n|A_{n-1}A_{n-2}…A_1)=\prod_i^n P(A_i|A_{i-1}A_{i-2}…A_1)<br>\end {aligned}$$<br>一般而言，条件概率P(A|B)与概率P(A)是不等的。但在某些情况下，它们是相等的。根据条件概率的定义和乘法公式有:$$P(AB)=P(A)P(B)$$这时，称事件A与B是相互独立的。</p><h3 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h3><p>根据乘法公式，可以的得到下面重要的公式，该公式称为贝叶斯公式：<br>$$P(A|B)=\frac {P(B|A)(A)}{P(B)}$$<br>一般地，事件$A_1,A_2,…,A_n$两两互斥，事件B满足$B\subset A_1+A_2+…+A_n$且$P(A_i)&gt;0(i=1,2,…,n),P(B)&gt;0$，贝叶斯公式可以推广为：$$<br>p(A_j|B)=\frac{P(A_j)P(B|A_j)}{P(A_1)P(B|A_1)+…+P(A_n)P(B|A_n)}=\frac {P(A_j)P(B|A_j)}{\sum_i^n P(A_i)P(B|A_i)}<br>$$<br>实用上称，$P(A_1),P(A_2),…,P(A_n)$的值称为先验概率，称$P(A_1|B),P(A_2|B),…,P(A_n|B)$的值称为后验概率，贝叶斯公式便是从先验概率计算后验概率的公式。</p><h2 id="各种熵-entropy"><a href="#各种熵-entropy" class="headerlink" title="各种熵(entropy)"></a>各种熵(entropy)</h2><p>在信息论中，如果发送一个消息所需要的编码的长度较大，则可以理解为消息所蕴涵的信息量较大，如果发送一个消息所需要的编码长度较小，则该消息所蕴涵的信息量较小，平均信息量即为发送一个消息的平均编码长度，可以用<strong>熵</strong>的概念来描述。</p><h3 id="自信息"><a href="#自信息" class="headerlink" title="自信息"></a>自信息</h3><p>自信息是熵的基础，自信息表示某一事件发生时所带来的信息量的多少。当事件发生的概率越大，则自信息越小。当一件事发生的概率非常小，并且实际上也发生了（观察结果），则此时的自信息较大。某一事件发生的概率非常大，并且实际上也发生了，则此时的自信息较小。如何度量它？现在要寻找一个函数，满足条件：事件发生的概率越大，则自信息越小；自信息不能是负值，最小是0；自信息应该满足可加性，并且两个对立事件的自信息应该等于两个事件单独的自信息。自信息的公式如下：<br>$$I(p_i)=-log(p_i)$$<br>其中，$p_i$表示随机变量的第i个事件发生的概率，自信息单位是bit,表征描述该信息需要多少位。可以看出，自信息的计算和随机变量本身数值没有关系，只和其概率有关。</p><h3 id="熵的定义"><a href="#熵的定义" class="headerlink" title="熵的定义"></a>熵的定义</h3><p>设X是取有限个值的随机变量，它的分布密度为$p(x)=P(X=x),且x\in X$，则X的熵的定义为：$$H(x)=-\sum _{x \in X}p(x)log_ap(x)$$<br>熵描述了随机变量的不确定性。一般也说，熵给出随机变量的一种度量。对于数底a可以是任何正数，对数底a决定了熵的单位，如果a=2，则熵的单位称为比特(bit)。</p><h3 id="熵的基本性质"><a href="#熵的基本性质" class="headerlink" title="熵的基本性质"></a>熵的基本性质</h3><ul><li>$H(x)&lt;=log|X|$，其中等号成立当且仅当$p(x)=\frac {1}{|x|}$，这里|X|表示集合X中的元素个数。该性质表明等概场具有的最大熵；</li><li>$H(X)&gt;=0$，其中等号成立的条件当且仅当对某个i,$p(x_i)=1$，其余的$p(x_k)=0 (k!=i)$。这表明确定场(无随机性)的熵最小；</li><li>熵越大，随机变量的不确定性就越大，分布越混乱，随机变量状态数越多；</li></ul><h3 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h3><p>设X,Y是两个离散随机变量，它们的联合分布密度为p(x,y)，则给定X时Y的条件熵定义为：<br>$$\begin{aligned}<br>H(Y|X) &amp;=-\sum_{x\in X}p(x)H(Y|X=x)\\\\<br>&amp;=\sum_{x\in X}p(x)[-\sum_{y \in Y}p(y|x)log p(y|x)]\\\\<br>&amp;=-\sum_{x \in X}\sum_{y \in Y} p(x,y)log p(y|x)<br>\end{aligned}<br>$$<br>联合熵和条件熵的关系可以用下面的公式来描述，该关系一般也称为链式规则：$$<br>H(X,Y)=H(X)+H(Y|X)$$<br>信息量的大小随着消息的长度增加而增加，为了便于比较，一般使用熵率的概率。熵率一般也称为字符熵(per-letter entropy)或词熵(per-word entropy)。</p><h3 id="熵率"><a href="#熵率" class="headerlink" title="熵率"></a>熵率</h3><p>对于长度为n的消息，熵率的定义为：<br>$$<br>H_{rate}=\frac{1}{n}H(x_{1n}) = -\frac {1}{n}\sum_{x_{1n}}p(x_{1n})log p(x_{1n})<br>$$<br>这里的$x_{1n}$表示随机变量序列$X_1,X-2…X_n,p(x_{1n})表示分布密度p(x_1,x_2,…,x_n)$。<br>可以把语言看做一系列语言单位构成的一个随机变量序列$L={X_1X_2…X_n}$，则语言L的熵可以定义这个随机变量序列的熵率:<br>$$<br>H_{rate}=\lim_{x \to +\infty}\frac{1}{n}H(H_1,H_2,…,H_n)<br>$$</p><h3 id="互信息"><a href="#互信息" class="headerlink" title="互信息"></a>互信息</h3><p>根据链式规则，有:$$H(X,Y)=H(X)+H(Y|X)=H(Y)+H(X|Y)$$可以推导出：$$<br>H(X)-H(X|Y)=H(Y)-H(Y|X)<br>$$<br>H(X)与H(X|Y)的差称为互信息，一般记作I(X;Y)。I(X;Y)描述了包含在X中的有关Y的信息量，或包含在Y中的有关X的信息量。下图很好的描述了互信息和熵之间的关系。<br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180503/7Cceem39Dg.jpg?imageslim" alt="mark"><br>$$\begin{aligned}<br> I(X;Y)&amp;=H(X)-H(X|Y)\\\\&amp;=H(X)+H(Y)-H(X,Y)\\\\<br> &amp;=\sum_x p(x)log \frac {1}{p(x)}+\sum_x p(y)log \frac {1}{p(y)}+\sum_{x,y} p(x,y)log p(x, y)\\\\&amp;=\sum_{x,y}log \frac {p(x,y)}{p(x)p(y)}<br>\end{aligned}<br>$$<br><strong>互信息(mutual information),</strong>随机变量X,Y之间的互信息定义为：$$<br>I(X;Y)=\sum_{x,y}p(x,y)log \frac {p(x,y)}{p(x)p(y)}<br>$$<br><strong>互信息的性质</strong>：</p><ul><li>$I(X;Y)&gt;=0$，等号成立当且仅当X和Y相互独立。</li><li>$I(X;Y)=I(Y;X)$说明互信息是对称的。</li></ul><p>互信息相对于相对熵的区别就是，互信息满足对称性；<br>互信息的公式给出了两个随机变量之间的互信息。在计算语言学中，更为常用的是两个具体事件之间的互信息，一般称之为<strong>点式互信息</strong>。<br><strong>点式互信息(pointwise mutual information)</strong>，事件x,y之间的互信息定义为：$$<br>I(x,y) = log \frac {p(x,y)}{p(x)p(y)}<br>$$<br>一般而言，点间互信息为两个事件之间的相关程度提供一种度量，即：</p><ul><li>当$I(x,y)&gt;&gt;0$时，x和y是高度相关的；</li><li>当$I(x,y)=0$时，x和y是高度相互独立；</li><li>当$I(x,y)&lt;&lt;0$时，x和y呈互补分布；</li></ul><h3 id="交叉熵-cross-entropy"><a href="#交叉熵-cross-entropy" class="headerlink" title="交叉熵(cross entropy)"></a>交叉熵(cross entropy)</h3><p>交叉熵的概念是用来衡量估计模型与真实概率分布之间差异情况的，其定义为，设随机变量X的分布密度p(x)，在很多情况下p(x)是未知的，人们通常使用通过统计的手段得到X的近似分布q(x),则随机变量X的交叉熵定义为：<br>$$<br>H(p,q) = -\sum_{x \in X} p(x)log q(x)<br>$$<br>其中，p是真实样本的分布，q为预测样本分布。在信息论中，其计算数值表示：如果用错误的编码方式q去编码真实分布p的事件，需要多少bit数，是一种非常有用的衡量概率分布相似的数学工具。</p><h3 id="相对熵-relative-entropy"><a href="#相对熵-relative-entropy" class="headerlink" title="相对熵(relative entropy)"></a>相对熵(relative entropy)</h3><p>相对熵，设p(x),q(x)是随机变量X的两个不同的分布密度，则它们的相对熵定义为:$$<br>D(p||q)=\sum_{x \in X}p(x) log \frac {p(x)}{q(x)}=H(p,q)-H(p)<br>$$<br>相对熵较交叉熵有更多的优异性质，主要为：</p><ul><li>当p分布和q分布相等的时候，KL散度值为0；</li><li>可以证明是非负的；</li><li>KL散度是非对称的，通过公式可以看出，KL散度是衡量两个分布的不相似性，不相似性越大，则值越大，当完全相同时，取值为0；</li></ul><p>对比交叉熵和相对熵，可以发现仅仅差一个H(p)，如果从最优化的角度来看，p是真实分布，是固定值，最小化KL散度的情况下，H(p)可以省略，此时交叉熵等价于KL散度。</p><p><strong>在机器学习中，何时需要使用相对熵，何时使用交叉熵？</strong><br>在最优化问题中，最小化相对熵等价于最小化交叉熵；相对熵和交叉熵的定义其实可以从最大似然估计得到。最大化似然函数，等价于最小化负对数似然，等价于最小化交叉熵，等价于最小化KL散度。交叉熵大量应用在Sigmoid函数和SoftMax函数中，而相对熵大量应用在生成模型中，例如，GAN、EM、贝叶斯学习和变分推导中。从这可以看出：如果想通过算法对样本数据进行概率分布建模，那么通常都是使用相对熵，因为需要明确知道生成的分布和真实分布的差距，最好的KL散度值应该是0；而在判别模型中，仅仅只需要评估损失函数的下降值即可，交叉熵可以满足要求，其计算量比KL散度小。在《数学之美》一书中是这样描述它们的区别：<strong>交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除新系统的不确定性所需要付出的努力的大小；相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异。</strong></p><h3 id="困惑度-perplexity"><a href="#困惑度-perplexity" class="headerlink" title="困惑度(perplexity)"></a>困惑度(perplexity)</h3><p>对于语言$L=(x_i)~p(x)$，与其模型q的交叉熵定义为：$$<br>H(L,p)=-\lim_{x \to \infty} \frac {1}{n} \sum_{x_1^n}p(x_1^n)log q(x_1^n)<br>$$<br>其中，$x_1^n=x_1,…,x_n$为语言L的语句，$p(x_1^n)$为L中语句的概率，$q(x_1^n)$为模型q对$x_1^n$的概率估计。<br>我们可以假设这种语言是“理想”的，即n趋于无穷大时，其全部“单词”的概率和为1。就是说，根据信息论的定理：假定语言L是稳态(stationary) ergodic随机过程， L与其模型q的交叉熵计算公式就变为：<br>$$H(L,q)=-\lim_{x \to \infty} \frac {1}{n} log q(x_1^n)$$<br>由此，我们可以根据模型q和一个含义大量数据的L的样本来计算交叉熵。在设计模型q时，我们的目的是使交叉熵最小，从而使模型最接近真实的概率分布p(x)。</p><p>在设计语言模型时，通常用困惑度来代替交叉熵衡量语言模型的好坏。给定语言L的样本$l_1^n=l_1,,,,l_n$，L的困惑度为$PP_q$定义为：<br>$$<br>PP_q = 2^{H(L,q)}   \approx 2^{-\frac {1}{n}log q(l_1^n)} = [q(l_1^n)]^{- \frac {1}{n}}<br>$$<br>于是语言模型设计的任务就是寻找困惑度最小的模型，使其最接近真实语言的情况。从perplexity的计算式可以看出来，它是对于样本句子出现的概率，在句子长度上Normalize一下的结果。它越小，说明出现概率越大，所得模型就越好。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>机器学习各种熵：从入门到全面掌握：<a href="https://mp.weixin.qq.com/s/LGyNq3fRlsRSatu1lpFnnw##" target="_blank" rel="external">https://mp.weixin.qq.com/s/LGyNq3fRlsRSatu1lpFnnw##</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一些基础&quot;&gt;&lt;a href=&quot;#一些基础&quot; class=&quot;headerlink&quot; title=&quot;一些基础&quot;&gt;&lt;/a&gt;一些基础&lt;/h2&gt;&lt;h3 id=&quot;互斥&quot;&gt;&lt;a href=&quot;#互斥&quot; class=&quot;headerlink&quot; title=&quot;互斥&quot;&gt;&lt;/a&gt;互斥&lt;/h3&gt;&lt;p&gt;如果事件A和B不可能同时发生，即$AB=\Phi$，则称A与B是互斥的。&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="NLP" scheme="https://ilewseu.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>神经网络中的激活函数</title>
    <link href="https://ilewseu.github.io/2018/04/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>https://ilewseu.github.io/2018/04/21/神经网络中的激活函数/</id>
    <published>2018-04-21T06:16:20.000Z</published>
    <updated>2018-05-12T15:19:03.139Z</updated>
    
    <content type="html"><![CDATA[<h2 id="激活函数简介"><a href="#激活函数简介" class="headerlink" title="激活函数简介"></a>激活函数简介</h2><p>神经网络是目前比较流行深度学习的基础，神经网络模型模拟人脑的神经元。人脑神经元接收一定的信号，对接收的信号进行一定的处理，并将处理后的结果传递到其他的神经元，数以亿计的神经元组成了人体复杂的结构。在神经网络的数学模型中，神经元节点，将输入进行加权求和，加权求和后再经过一个函数进行变换，然后输出。这个函数就是激活函数，神经元节点的激活函数定义了对神经元输入的映射关系。<br><a id="more"></a></p><div align="center"><br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180507/k641bmB33m.png?imageslim"><br></div><h3 id="激活函数的定义"><a href="#激活函数的定义" class="headerlink" title="激活函数的定义"></a>激活函数的定义</h3><p>在ICML2016的一篇论文：Noisy Activation Functions中给出的了激活函数的定义：激活函数是实数到实数的映射，且几乎处处可导。激活函数一般具有以下性质：</p><ul><li>非线性：弥补线性模型的不足；</li><li>几乎处处可导：反向传播时需要计算激活函数的偏导数，所以要求激活函数除个别点外，处处可导；</li><li>计算简单</li><li>单调性：当激活函数是单调的时候，单层网络能够保证是凸函数；</li><li>输出值范围有限：当激活函数的输出值有限的时候，基于梯度的优化方法会更加稳定；因为特定的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况下，一般需要更小的learning rate。</li></ul><h3 id="激活函数的作用"><a href="#激活函数的作用" class="headerlink" title="激活函数的作用"></a>激活函数的作用</h3><ul><li>神经网络中的激活函数能够引入非线性因素，提高模型的表达能力；<br>网络中仅有线性模型的话，表达能力不够。比如一个多层的线性网络，其表达能力和单层的线性网络是相同的。网络中卷积层、池化层和全连接层都是线性的。所以，需要在网络中加入非线性的激活函数层。</li><li>一些激活函数能够起到特征组合的作用；<br>例如，对于Sigmoid函数$\sigma(x) = \frac {1}{1+e^(-x)}$，根据泰勒公式展开:$$<br>e^x = 1+ \frac {1}{1!}x + \frac {1}{2!}x^2 + \frac {1}{3!}x^3+O(x^3)<br>$$<br>对于输入特征为$x_1,x_2$，加权组合后如下：<br>$$<br>x = w_1x_1+w_2x_2<br>$$<br>将x带入到$e^x$泰勒展开的平方项，$$<br>x^2=(w_1x_1+w_2x_2)^2 = ((w_1x_1)^2+(w_2x_2)^2 + 2w_1x_1*w_2x_2)<br>$$<br>可以看出，平方项起到了特征两两组合的作用，更高阶的$x^3,x^4$等，则是更复杂的特征组合。</li></ul><h2 id="常见非线性激活函数"><a href="#常见非线性激活函数" class="headerlink" title="常见非线性激活函数"></a>常见非线性激活函数</h2><p>在介绍常见的激活函数之前，先介绍一下饱和(Saturated)的概念。</p><ul><li>左饱和：当函数h(x)满足，$\lim \limits_{x \to +\infty}h^{‘}(x)=0$;</li><li>右饱和：当函数h(x)满足，$\lim \limits_{x \to -\infty}h^{‘}(x)=0$;</li><li>饱和：当函数h(x)既满足左饱和又满足右饱和，称h(x)是饱和的;</li></ul><p>当激活函数是饱和的，对激活函数进行求导计算梯度时，计算出的梯度趋近于0，导致参数更新缓慢。</p><h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p>Sigmoid函数：</p><ul><li>定义：$\sigma(x) = \frac {1}{1+e^{-x}}$</li><li>值域：(0,1)</li><li>导数：$\sigma^{‘}(x) = \sigma(x)(1-\sigma(x))$<br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180507/hB715EhmHJ.png?imageslim" alt="mark"></li></ul><p>从数学上看，非线性的Sigmoid函数对中央区域的信号增益较大，对两侧区域的信号增益较小，在信号的特征空间映射上，有很好的效果。从神经科学上来看，中央神经区酷似神经元的兴奋态，两侧区酷似神经元的抑制状态，因而在神经网络学习方面，可以将重点特征推向中央区，将非重点特征推向两侧区。</p><p>Sigmoid的有以下优点：</p><ul><li>输出值域在(0,1)之间，可以被表示为概率；</li><li>输出范围有限，数据在传递的过程中不容易发散；</li><li>求导比较方便；</li></ul><p>Sigmoid的缺点如下：</p><ul><li>Sigmoid函数是饱和的，可能导致梯度消失(两个原因:(1)Sigmoid导数值较小；(2)Sigmoid是饱和的)，导致训练出现问题；</li><li>输出不以0为中心，可能导致收敛缓慢(待思考原因)；</li><li>指数计算，计算复杂度高；</li></ul><h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><p>Tanh函数的表达式为：</p><p>$$tanh(x)=\frac {e^x-e^{-x}}{e^x+e^{-x}}=2\sigma(2x) - 1$$<br>它将输入值映射到[-1,1]区间内，其函数图像为：<br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180507/3jhB57gBEi.png?imageslim" alt="mark"></p><p>它的导数为$tanh^{‘}(x)=1-tanh^2(x)$<br>Tanh函数是Sigmoid函数的一种变体；与Sigmoid不同的是，Tanh是0均值的。因此，在实际应用中，Tanh会比Sigmoid更好，但Tanh函数现在也很少使用，其优缺点总结如下：</p><ul><li>相比Sigmoid函数，收敛速度更快；</li><li>相比Sigmoid函数，其输出是以0为中心的；</li><li>没有解决由于饱和性产生的梯度消失问题；</li></ul><h3 id="ReLU-Rectified-Linear-Units"><a href="#ReLU-Rectified-Linear-Units" class="headerlink" title="ReLU(Rectified Linear Units)"></a>ReLU(Rectified Linear Units)</h3><p>ReLU函数为现在使用比较广泛的激活函数，其表达式为：<br>$$<br>f(x)=max(0,x)=\begin{cases}<br>             x, &amp;  if x&gt;0 \\<br>             0  &amp; if x\leq0<br>             \end{cases}<br>$$<br>其函数图像如下：<br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180507/2HBL5Fa5ld.png?imageslim" alt="mark"></p><p>导数图像如下：<br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180507/dHg6L8J47d.png?imageslim" alt="mark"></p><p><strong>ReLU的优点如下:</strong></p><ul><li>相比Sigmoid和Tanh，ReLU在SGD中收敛速度要相对快一些；</li><li>Sigmoid和Tanh涉及到指数运算，计算复杂度高，ReLU只需要一个阈值就可以得到激活值，加快正向传播的计算速度；</li><li>有效的缓解了梯度消失的问题；</li><li>提供了神经网络的稀疏表达能力；</li></ul><p><strong>ReLU的缺点如下：</strong></p><ul><li>ReLU的输出不是以0为中心的；</li><li>训练时，网络很脆弱，很容易出现很多神经元值为0，从而再也训练不动；</li></ul><h3 id="ReLU的变体"><a href="#ReLU的变体" class="headerlink" title="ReLU的变体"></a>ReLU的变体</h3><p>为了解决上面的问题，出现了一些变体，这些变体的主要思路是将x&gt;0的部分保持不变，$x\leq0$的部分不直接设置为0，设置为$\alpha x$，如下三种变体:</p><ul><li>L-ReLU(Leaky ReLU):$\alpha$固定为比较小的值，比如：0.01，0.05；</li><li>P-ReLU(Parametric ReLU):$\alpha$作为参数，自适应地从数据中学习得到；</li><li>R-ReLU(Randomized ReLU):先随机生成一个$\alpha$，然后在训练过程中再进行修正；</li></ul><h3 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h3><p>ELU的函数形式如下：<br>$$<br>f(x)=\begin{cases}<br>             x, &amp;  if x&gt;0 \\<br>             \alpha(e^x-1)  &amp; if x\leq0<br>             \end{cases}<br>$$</p><p>其函数图像如下：<br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180507/4aIakGg1G8.png?imageslim" alt="mark"></p><p>ELU也是为了解决ReLU存在的问题而提出的，它具有ReLU的基本所有优点，以及：</p><ul><li>不会有神经元死亡的问题；</li><li>输出的均值接近于0，zero-centered;</li><li>计算量稍大，理论上虽然好于ReLU，但在实际使用中，目前并没有好的证据证明ELU总是优于ReLU;</li></ul><h3 id="MaxOut"><a href="#MaxOut" class="headerlink" title="MaxOut"></a>MaxOut</h3><p>MaxOut函数定义如下：$$<br>y=f(x)=max_{j\in[1,k]}z_j \\<br>z_j = w_jx+b_j<br>$$<br>一个比较容易的介绍，如下图：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/180507/GFGj5LcC7a.png?imageslim" ,width="600" height="400"><br></div><p>假设w是二维的，那么有:<br>$$<br>f(x)=max(w_1^Tx+b_1,w_2^Tx+b_2)<br>$$<br>可以看出，ReLU及其变体都是它的一个变形(当$w_1,b_1=0的时候，就是ReLU$)</p><h2 id="激活函数使用建议"><a href="#激活函数使用建议" class="headerlink" title="激活函数使用建议"></a>激活函数使用建议</h2><ul><li>如果想让结果在(0,1)之间，使用Sigmoid(如LSTM的各种Gates);</li><li>如果想神经网络训练的很深，不要使用S型的激活函数；</li><li>如果使用ReLU，要注意初始化和Learning Rates的设置；</li><li>如果使用ReLU，出现很多神经元死亡的问题，且无法解决，可以尝试使用L-ReLU、P-ReLU等ReLU的变体；</li><li>最好不要使用Sigmoid，可以尝试使用Tanh;</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;激活函数简介&quot;&gt;&lt;a href=&quot;#激活函数简介&quot; class=&quot;headerlink&quot; title=&quot;激活函数简介&quot;&gt;&lt;/a&gt;激活函数简介&lt;/h2&gt;&lt;p&gt;神经网络是目前比较流行深度学习的基础，神经网络模型模拟人脑的神经元。人脑神经元接收一定的信号，对接收的信号进行一定的处理，并将处理后的结果传递到其他的神经元，数以亿计的神经元组成了人体复杂的结构。在神经网络的数学模型中，神经元节点，将输入进行加权求和，加权求和后再经过一个函数进行变换，然后输出。这个函数就是激活函数，神经元节点的激活函数定义了对神经元输入的映射关系。&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Machine Learning" scheme="https://ilewseu.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow 变量管理</title>
    <link href="https://ilewseu.github.io/2018/03/11/Tensorflow%E5%8F%98%E9%87%8F%E7%AE%A1%E7%90%86/"/>
    <id>https://ilewseu.github.io/2018/03/11/Tensorflow变量管理/</id>
    <published>2018-03-11T02:47:20.000Z</published>
    <updated>2018-03-11T05:37:11.102Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>摘自：《TensorFlow实战Google深度学框架》一书，5.3节。</p></blockquote><p>Tensorflow提供了通过变量名称来创建或者获取一个变量的机制。通过这个机制，在不同的函数中可以直接通过变量的名字来使用变量，而不需要将变量通过参数的形式到处传递。TensorFlow中通过变量名获取变量的机制主要是通过tf.get_variable和tf.variable_scope函数实现的。下面将分别介绍如何使用这两个函数。<br><a id="more"></a><br>通过tf.Variable()函数可以创建一个变量。除了tf.Variable()函数，TensorFlow还提供了tf.get_variable函数来创建或者获取变量。当tf.get_variable用于创建变量时，它和tf.Variable()的功能是基本等价的。下面的代码给出通过这两个函数创建同一个变量的示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 下面这两个定义是等价的</span></div><div class="line">v = tf.get_variable(<span class="string">"v"</span>,shape=[<span class="number">1</span>],initializer=tf.constant_initializer(<span class="number">1.0</span>))</div><div class="line">v = tf.Variable(tf.constant(<span class="number">1.0</span>, shape=[<span class="number">1</span>]),name=<span class="string">'v'</span>)</div></pre></td></tr></table></figure></p><p>从上面的代码可以看出，通过tf.Variable和tf.get_variable函数创建变量的过程基本上是一样的。tf.get_variable函数调用时提供的维度(shape)信息以及初始化方法(initializer)的参数和tf.Variable函数调用时提供的初始化过程中的参数也类似。TensorFlow中提供的initializer函数和随机数以及常量生成函数大部分是一一对应的。比如，在上面的样例程序中使用的常数初始化函数tf.constant_initializer和常数生成的函数tf.constant功能上是一致的。Tensorflow提供了7种不同的初始化函数，如下表所示：</p><table><thead><tr><th>初始化函数</th><th>功能</th><th>主要参数</th></tr></thead><tbody><tr><td>tf.constant_initializer</td><td>将变量初始化为给定常量</td><td>常量的取值</td></tr><tr><td>tf.random_normal_initializer</td><td>将变量初始化为满足正态分布的随机值</td><td>正态分布的均值和标准差</td></tr><tr><td>tf.truncated_normal_initializer</td><td>将变量初始化为满足正态分布的随机值，但如果随机出来的值<br>偏离平均值超过2个标准差，那么这个数将会被重新随机</td><td>正态分布的均值和标准差</td></tr><tr><td>tf.random_uniform_initializer</td><td>将变量初始化为满足均匀分布的随机值</td><td>最大值、最小值</td></tr><tr><td>tf.uniform_unit_scaling_initializer</td><td>将变量初始化为满足均匀分布但不影响输出数量级的随机值</td><td>factor(产生随机数时<br>乘以的系数)</td></tr><tr><td>tf.zeros_initializer</td><td>将被变量设置为0</td><td>变量维度</td></tr><tr><td>tf.ones_initializer</td><td>将变量设置为1</td><td>变量的维度</td></tr></tbody></table><p><strong>tf.get_variable函数与tf.Variable函数最大的区别在于指定变量名称的参数</strong>。对于tf.Variable函数， 变量名称是一个可选的参数，通过name=“v”的形式给出。但是对于tf.get_variable函数，变量名称是一个必填的参数。tf.get_variable会根据这个名字去创建或者获取变量。在上面的示例程序中，tf.get_variable首先会试图创建一个名字为v的参数，如果创建失败（比如已经有同名的参数），那么这个程序会报错。这是为了避免无意识的变量复用造成的错误。比如在定义神经网络参数时，第一层网络的权重已经叫weights了，如果创建第二层的神经网络时，如果参数名仍然叫weights，那么就会触发变量重用的错误。否则两层神经网络公用一个权重会出现一些比较难以发现的错误。<strong>如果需要通过tf.get_variable获取一个已经创建的变量，需要通过tf.variable_scope函数来生成一个上下文管理器，并明确指定在这个上下文管理器中，tf.get_variable将直接获取已经生成的变量。</strong>下面给出一段代码说明如何通过tf.variable_scope函数来控制tf.get_variable函数获取已经创建过的变量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 在名字为foo的命名空间内创建名字为v的变量</span></div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"foo"</span>):</div><div class="line">    v = tf.get_variable(<span class="string">"v"</span>, [<span class="number">1</span>], initializer=tf.constant_initializer(<span class="number">1.0</span>))</div><div class="line"></div><div class="line"><span class="comment"># 因为在命名空间foo中已经存在名为v的变量，所以下面的代码将会报错</span></div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"foo"</span>):</div><div class="line">    v = tf.get_variable(<span class="string">"v"</span>,[<span class="number">1</span>])</div><div class="line"></div><div class="line"><span class="comment"># 在生成上下文管理器时，将参数reuse设置为True。这样tf.get_vaiable函数将直接获取</span></div><div class="line"><span class="comment"># 已经声明的变量。</span></div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"foo"</span>,reuse=<span class="keyword">True</span>):</div><div class="line">    v1 = tf.get_variable(<span class="string">"v"</span>,[<span class="number">1</span>])</div><div class="line">    <span class="keyword">print</span> v==v1 <span class="comment">#输出为True，v和v1代表的是相同的变量</span></div><div class="line"></div><div class="line"><span class="comment"># 将参数reuse设置为True时，tf.variable_scope将只能获取已经创建过的变量。因为在命名</span></div><div class="line"><span class="comment"># 空间bar中还没有创建变量v，所以下面的代码将会报错</span></div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"bar"</span>,reuse=<span class="keyword">True</span>):</div><div class="line">    v = tf.get_variable(<span class="string">"v"</span>,[<span class="number">1</span>])</div></pre></td></tr></table></figure></p><p>上面的样例简单地说明了通过tf.variable_scope函数可以控制tf.get_variable函数的语义。<strong>当tf.variable_scope函数使用参数reuse=True生成上下文管理器时，这个上下文管理器内所有的tf.get_variable函数会直接获取已经创建的变量。如果变量没有被创建，则tf.get_variable将会报错；相反如果tf.variable_scope函数使用参数reuse=None或者reuse=False创建上下文管理器，tf.get_variable操作将创建新的变量。</strong>如果同名变量已经存在，则tf.get_variable函数将会报错。TensorFlow中tf.variable_scope函数是可以嵌套的。下面的程序说明了当tf.variable_scope函数嵌套时，reuse参数的取值时如何确定的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"root"</span>):</div><div class="line">    <span class="comment"># 可以通过tf.get_variable_scope().reuse函数来获取当前上下文管理器中reuse参数的取值</span></div><div class="line">    <span class="keyword">print</span> tf.get_variable_scope().reuse   <span class="comment">#输出False，即最外层reuse是False</span></div><div class="line"></div><div class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"foo"</span>,reuse=<span class="keyword">True</span>): <span class="comment"># 新建一个嵌套的上下文管理器，</span></div><div class="line">                                              <span class="comment"># 并指定reuse为True</span></div><div class="line">        <span class="keyword">print</span> tf.get_variable_scope().reuse   <span class="comment"># 输出为True</span></div><div class="line">        <span class="keyword">with</span> tf.variable_scope(<span class="string">"bar"</span>):        <span class="comment"># 新建一个嵌套的上下文管理器</span></div><div class="line">                                              <span class="comment"># 但不指定reuse的取值，和外层的保持一致</span></div><div class="line">            <span class="keyword">print</span> tf.get_variable_scope().reuse <span class="comment"># 输出为True</span></div><div class="line">    <span class="keyword">print</span> tf.get_variable_scope().reuse      <span class="comment"># 输出False，退出reuse设置为True</span></div><div class="line">                                             <span class="comment"># 的上下文之后，reuse的值又回到了False</span></div></pre></td></tr></table></figure><p>tf.variable_scope函数生成的上下文管理器也会创建一个TensorFlow中的命名空间，在命名空间内创建的变量名称都会带上这个命名空间名作为前缀。所以，tf.variable_scope函数除了控制tf.get_variable执行的功能之外，这个函数也提供了一个管理变量命名空间的方式。下面的代码显示如何通过tf.variable_scope来管理变量的名称。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">v1 = tf.get_variable(<span class="string">"v"</span>,[<span class="number">1</span>])</div><div class="line"><span class="keyword">print</span> v1.name    <span class="comment"># 输出v:0,"v"为变量名称，“：0”表示这个变量时生成变量这个运算的第一个结果</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"foo"</span>):</div><div class="line">    v2 = tf.get_variable(<span class="string">"v"</span>,[<span class="number">1</span>])</div><div class="line">    <span class="keyword">print</span> v2.name  <span class="comment"># 输出为foo/v:0。在tf.variable_scope中创建的变量，名称前面会</span></div><div class="line">                   <span class="comment"># 加入命名空间的名称，通过/来分隔命名空间的名称和变量的名称。</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"foo"</span>):</div><div class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"bar"</span>):</div><div class="line">        v3 = tf.get_variable(<span class="string">"v"</span>,[<span class="number">1</span>])</div><div class="line">        <span class="keyword">print</span> v3.name <span class="comment"># 输出为foo/bar/v:0。命名空间可以嵌套，同时变量的名称也会</span></div><div class="line">                      <span class="comment"># 加入所有命名空间的名称作为前缀。</span></div><div class="line">    v4 = tf.get_variable(<span class="string">"v1"</span>,[<span class="number">1</span>])</div><div class="line">    <span class="keyword">print</span> v4.name  <span class="comment"># 输出foo/v1:0。当命名空间退出之后，变量名称也就不会再被加入其前缀了。</span></div><div class="line"></div><div class="line"><span class="comment"># 创建一个名称为空的命名空间，并设置为reuse=True</span></div><div class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">""</span>, reuse=<span class="keyword">True</span>):</div><div class="line">    v5 = tf.get_variable(<span class="string">"foo/bar/v"</span>,[<span class="number">1</span>]) <span class="comment"># 可以直接通过带命名空间名称的变量名来</span></div><div class="line">                                          <span class="comment"># 获取其他命名空间下的变量</span></div><div class="line">    <span class="keyword">print</span> v5 == v3 <span class="comment"># 输出为True</span></div><div class="line">    v6 = tf.get_variable(<span class="string">"foo/v1"</span>,[<span class="number">1</span>])</div><div class="line">    <span class="keyword">print</span> v6 == v4 <span class="comment"># 输出为True</span></div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;摘自：《TensorFlow实战Google深度学框架》一书，5.3节。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tensorflow提供了通过变量名称来创建或者获取一个变量的机制。通过这个机制，在不同的函数中可以直接通过变量的名字来使用变量，而不需要将变量通过参数的形式到处传递。TensorFlow中通过变量名获取变量的机制主要是通过tf.get_variable和tf.variable_scope函数实现的。下面将分别介绍如何使用这两个函数。&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="TensorFlow" scheme="https://ilewseu.github.io/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Attention Model 注意力机制</title>
    <link href="https://ilewseu.github.io/2018/02/12/Attention%20Model%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
    <id>https://ilewseu.github.io/2018/02/12/Attention Model 注意力机制/</id>
    <published>2018-02-12T06:23:20.000Z</published>
    <updated>2018-02-13T15:12:11.778Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文是对:<a href="https://blog.heuritech.com/2016/01/20/attention-mechanism/" target="_blank" rel="external">https://blog.heuritech.com/2016/01/20/attention-mechanism/</a> 的翻译。这篇文章对Attention Model原理进行了一个比较清晰的阐述，所以记录一下。由于本人英语能力有限，翻译不周的地方，还请见谅。<br><a id="more"></a><br>在2015年，随着DeepLearning和AI的发展，神经网络中的注意力机制引起了许多研究者的兴趣。这篇博文的目的是从一个高的层次上对注意力机制进行解释，以及详细介绍attention的一些计算步骤。如果你要更多关于attention的公式或例子，文后的参考文献提供了一下，特别注意Cho et al[3]这篇文章。不幸的是，这些模型往往你自己实现不了，仅仅有一些开源的实现。</p></blockquote><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p>神经科学和计算神经科学中的neural processes已经广泛研究了注意力机制[1,2]。视觉注意力机制是一个特别值得研究的方向：许多动物专注于视觉输入的特定部分，去计算适当的反映。这个原理对神经计算有很大的影响，因为我们需要选择最相关的信息，而不是使用所有可用的信息，所有可用信息中有很大一部分与计算神经元反映无关。一个类似于视觉专注于输入的特定部分，也就是注意力机制已经用于深度学习、语音识别、翻译、推理以及视觉识别。</p><h2 id="Attention-for-Image-Captioning"><a href="#Attention-for-Image-Captioning" class="headerlink" title="Attention for Image Captioning"></a>Attention for Image Captioning</h2><p>我们通过介绍一个例子，去解释注意力机制。这个任务是我们想实现给图片加标题：对于给定的图片，根据图片中的内容给图片配上标题(说明/描述)。一个典型的image captioning系统会对图片进行编码，使用预训练的卷积神经网络产生一个隐状态h。然后，可以使用RNN对这个隐状态h进行解码，生成标题。这种方法已经被不少团队采用，包括[11]，如下图所示：</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/27GEF0IlE8.png?imageslim" alt="mark"></p><p>这种方法的问题是：当模型尝试去产生标题的下一个词时，这个词通常是描述图片的一部分。使用整张图片的表示h去调节每个词的生成，不能有效地为图像的不同部分产生不同的单词。这正是注意力机制有用的地方。<br>使用注意力机制，图片首先被划分成n个部分，然后我们使用CNN计算图像每个部分的表示$h_1,…,h_n$，也就是对n个部分的图像进行编码。当使用RNN产生一个新的词时，注意力机制使得系统只注意图片中相关的几个部分，所以解码仅仅使用了图片的特定的几个部分。如下图所示，我们可以看到标题的每个词都是用图像(白色部分)的一部分产生的。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/cIDeG9Jgl9.png?imageslim" alt="mark"></p><p>更多的例子如下图所示，我们可看到图片相关的部分产生标题中划线的单词。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/IiaGamlfj5.png?imageslim" alt="mark"></p><p>现在我们要解释注意力机制是怎么工作的，文献[3]详细介绍了基于注意力机制的Encoder-Decoder Network的实现。</p><h2 id="What-is-an-attention-model"><a href="#What-is-an-attention-model" class="headerlink" title="What is an attention model"></a>What is an attention model</h2><p>在一般情况下，什么是注意力机制？</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/K49GLi96C2.png?imageslim" alt="mark"></p><p>一个attention model通常包含n个参数$y_1,..,y_n$(在前面的例子中，$y_i$可以是$h_i$) ,和一个上下文c。它返回一个z向量，这个向量可以看成是对$y_i$的总结，关注与上下文c相关联的信息。更正式地说是，它返回的$y_i$的加权算术平均值，并且权重是根据$y_i$与给定上下文c的相关性来选择的。</p><p>在上面的例子中，上下文是刚开始产生的句子，$y_i$是图像的每个部分的表示($h_i$)，输出是对图像进行一定的过滤（例如：忽略图像中的某些部分）后的表示，通过过滤将当前生成的单词的重点放在感兴趣的部分。<br>注意力机制有一个有趣的特征：计算出的权重是可访问的并且可以被绘制出来。这正是我们之前展示的图片，如果权重越高，则对应部分的像素越白。</p><p>但是，这个黑盒子做了什么？下图能够清晰的表示Attention Model的原理：</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/mmcbj2eK5C.png?imageslim" alt="mark"></p><p>可能这个网络图看起来比较复杂，我们一步一步来解释这个图。<br>首先，我们能够看出 一个输入c，是上下文，$y_i$是我们正在研究的“数据的一部分”。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/591aa4eId3.png?imageslim" alt="mark"></p><p>然后，网络计算$m_1,…,m_n$通过一个tanh层。这意味着我们计算$y_i$和c的一个”聚合”。重要的一点是，每个$m_i$的计算都是在不考虑其他$y_j,j \neq i$的情况下计算出来的。它们是独立计算出来的。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/fejdk9cA73.png?imageslim" alt="mark"></p><p>$$m_i = tanh(W_{cm}c+W_{ym}y_i)$$</p><p>然后，我们计算每个weight使用softmax。softmax，就像他的名字一样，它的行为和argmax比较像，但是稍有不同。$argmax(x_1,…,x_n)=(0,..,0,1,0,..,0)$,在输出中只有一个1，告诉我们那个是最大值。但是，softmax的定义为：$softmax(x_1,…,x_n)=(\frac {e^{x_i}}{\sum_j e^{x_j}})_i$。如果其中有一个$x_i$比其他的都大，$softmax(x_1,…,x_n)将会非常接近argmax(x_1,…,x_n)$。<br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/g3JgH62d65.png?imageslim" alt="mark"></p><p>$$s_i 正比于 exp(w_m, m_i)\\\ \sum_i s_i=1$$<br>这里的$s_i$是通过softmax进行归一化后的值。因此，softmax可以被认为是“相关性”最大值的变量，根据上下文。<br>输出$z$是所有$y_i$的算术平均，每个权重值表示$y_i,..,y_n$和上下文c的相关性。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/43eLlm4gDb.png?imageslim" alt="mark"></p><p>$$z = \sum_i s_iy_i$$</p><h2 id="An-other-computation-of-“relevance”"><a href="#An-other-computation-of-“relevance”" class="headerlink" title="An other computation of “relevance”"></a>An other computation of “relevance”</h2><p>上面介绍的attention model是可以进行修改的。首先，tanh层可以被其他网络或函数代替。重要的是这个网络或函数可以综合c和$y_i$。比如可以只使用点乘操作计算c和$y_i$的内积，如下图所示：</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/8b2LBfc266.png?imageslim" alt="mark"></p><p>这个版本的比较容易理解。上面介绍的Attention是softly-choosing与上下文最相关的变量（$y_i$）。据我们所知，这两种系统似乎都能产生类似的结果。<br>另外一个比较重要的改进是hard attention。</p><h2 id="Soft-Attention-and-Hard-Attention"><a href="#Soft-Attention-and-Hard-Attention" class="headerlink" title="Soft Attention and Hard Attention"></a>Soft Attention and Hard Attention</h2><p>上面我们描述的机制称为Soft Attention，因为它是一个完全可微的确定性机制，可以插入到现有的系统中，梯度通过注意力机制进行传播，同时它们通过网络的其余部分进行传播。<br>Hard Attention是一个随机过程：系统不使用所有隐藏状态作为解码的输入，而是以概率$s_i$对隐藏状态$y_i$进行采样。为了进行梯度传播，使用蒙特卡洛方法进行抽样估计梯度。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/5c1A061BL6.png?imageslim" alt="mark"></p><p>这两个系统都有自己的优缺点，但是研究的趋势是集中于Soft Attention，因为梯度可以直接计算，并不是通过随机过程来估计的。</p><h2 id="Return-to-the-image-captioning"><a href="#Return-to-the-image-captioning" class="headerlink" title="Return to the image captioning"></a>Return to the image captioning</h2><p>现在，我们来理解一下image captioning 系统是怎样工作的。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/E6AGi93bJ9.png?imageslim" alt="mark"></p><p>从上面的图我们可以看到image captioning的典型模型，但是添加了一个新的关于attention model的层。当我们想要预测标题的下一个单词时，发生了什么？如果我们要预测第i个词，LSTM的隐藏状态是$h_i$。我们选择图像相关的部分通过把$h_i$作为上下文。然后，attention model的输出是$z_i$，这是被过滤的图像的表示，只有图像的相关部分被保留，用作LSTM的输入。然后，LSTM预测一个下一个词，并返回一个隐藏状态$h_{i+1}$。</p><h2 id="Learning-to-Align-in-Machine-Translation"><a href="#Learning-to-Align-in-Machine-Translation" class="headerlink" title="Learning to Align in Machine Translation"></a>Learning to Align in Machine Translation</h2><p>Bahdanau, et al[5]中的工作提出了一个神经翻译模型将句子从一种语言翻译成另一种语言，并引入注意力机制。在解释注意力机制之前，vanillan神经网络翻译模型使用了编码-解码(Encoder-Decoder)框架。编码器使用循环神经网络(RNN,通常GRU或LSTM)将用英语表示的句子进行编码，并产生隐藏状态h。这个隐藏状态h用于解码器RNN产生正确的法语的句子。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/JL6JJK2g25.png?imageslim" alt="mark"></p><p>编码器不产生与整个句子对应的单个隐藏状态，而是产生与一个词对应的隐藏状态$h_j$。每当解码器RNN产生一个单词时，取决于每个隐藏状态作为输入的贡献，通常是一个单独的参数（参见下图）。这个贡献参数使用Softmax进行计算：这意味着attention weights $a_j$在$\sum a_j=1$的约束下进行计算并且所有的隐藏状态$h_j$给解码器贡献的权重为$a_j$。<br>在我们的例子中，注意力机制是完全可微的，不需要额外的监督，它只是添加在现有的编码-解码框架的顶部。<br>这个过程可以看做是对齐，因为网络通常在每次生成输出词时都会学习集中于单个输入词。这就意味着大多数的注意力权重是0(黑)，而一个单一的被激活(白色)。下面的图像显示了翻译过程中的注意权重，它揭示了对齐方式，并使解释网络所学的内容成为可能（这通常是RNNs的问题！）。</p><p><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/fbb3Gee98c.png?imageslim" alt="mark"></p><h2 id="Attention-without-Recurrent-Neural-Networks"><a href="#Attention-without-Recurrent-Neural-Networks" class="headerlink" title="Attention without Recurrent Neural Networks"></a>Attention without Recurrent Neural Networks</h2><p>到现在为止，我们仅介绍了注意力机制在编码-解码框架下的工作。但是，当输入的顺序无关紧要时，可以考虑独立的隐藏状态$h_j$。这个在Raffel et Al[10]中进行了介绍，这里attention model是一个前向全连接的网络。同样的应用是Mermory Networks[6]（参见下一节）。</p><h2 id="From-Attention-to-Memory-Addressing"><a href="#From-Attention-to-Memory-Addressing" class="headerlink" title="From Attention to Memory Addressing"></a>From Attention to Memory Addressing</h2><p>NIPS 2015会议上提出了一个非常有趣的工作叫做 RAM for Reasoning、Attention and Memory。它的工作包含Attention，但是也包括Memory Networks[6],Neural Turing Machines[7]或 Differentiable Stack RNNS[8]以及其他的工作。这些模型都有共同之处，它们使用一种外部存储器的形式，这种存储器可以被读取（最终写入）。<br>比较和解释这些模型是超出了这个本文的范围, 但注意机制和记忆之间的联系是有趣的。例如，在Memory Networks中，我们认为外部存储器-一组事实或句子$x_i$和一个输入q。网络学习对记忆的寻址，这意味着选择哪个事实$x_i$去关注来产生答案。这对应了一个attention model在外部存储器上。In Memory Networks, the only difference is that the soft selection of the facts (blue Embedding A in the image below) is decorrelated from the weighted sum of the embeddings of the facts (pink embedding C in the image).（PS：实在读不懂了）。在Neural Turing Machine中，使用了一个Soft Attention机制。这些模型将会是下个博文讨论的对象。<br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180212/cHmIh83088.png?imageslim" alt="mark"></p><h2 id="Final-Word"><a href="#Final-Word" class="headerlink" title="Final Word"></a>Final Word</h2><p>注意力机制和其他完全可微寻址记忆系统是目前许多研究人员广泛研究而的热点。尽管它们仍然年轻, 在现实世界系统中没有实现, 但它们表明,它们可以处理在编码-解码框架下以前遗留的许多问题，它们可以被用来击败最先进的系统。<br>在Heuritech，几个月前，我们对注意力机制产生了兴趣，组织了一个小组，去实现带注意力机制的编码-解码器。虽然我们还没有在生产中使用注意机制,但我们设想它在高级文本理解中有一个重要的作用, 在某些推理是必要的, 以类似的方式，Hermann et al[9]中的工作和此类似。<br>在另一个单独的博客帖子中,我将详细阐述我们在研讨会上所学到的内容以及在RAM研讨会上提出的最新进展。<br>Léonard Blier et Charles Ollion</p><h2 id="Acknowledgments"><a href="#Acknowledgments" class="headerlink" title="Acknowledgments"></a>Acknowledgments</h2><p>在此感谢Mickael Eickenberg 和 Olivier Grisel的有益的讨论。</p><h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>[1] Itti, Laurent, Christof Koch, and Ernst Niebur. « A model of saliency-based visual attention for rapid scene analysis. » IEEE Transactions on Pattern Analysis &amp; Machine Intelligence 11 (1998): 1254-1259.</p><p>[2] Desimone, Robert, and John Duncan. « Neural mechanisms of selective visual attention. » Annual review of neuroscience 18.1 (1995): 193-222.</p><p>[3] Cho, Kyunghyun, Aaron Courville, and Yoshua Bengio. « Describing Multimedia Content using Attention-based Encoder–Decoder Networks. » arXiv preprint arXiv:1507.01053 (2015)</p><p>[4] Xu, Kelvin, et al. « Show, attend and tell: Neural image caption generation with visual attention. » arXiv preprint arXiv:1502.03044 (2015).</p><p>[5] Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. « Neural machine translation by jointly learning to align and translate. » arXiv preprint arXiv:1409.0473 (2014).</p><p>[6] Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. « End-to-end memory networks. » Advances in Neural Information Processing Systems. (2015).</p><p>[7] Graves, Alex, Greg Wayne, and Ivo Danihelka. « Neural Turing Machines. » arXiv preprint arXiv:1410.5401 (2014).</p><p>[8] Joulin, Armand, and Tomas Mikolov. « Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets. » arXiv preprint arXiv:1503.01007 (2015).</p><p>[9] Hermann, Karl Moritz, et al. « Teaching machines to read and comprehend. » Advances in Neural Information Processing Systems. 2015.</p><p>[10] Raffel, Colin, and Daniel PW Ellis. « Feed-Forward Networks with Attention Can Solve Some Long-Term Memory Problems. » arXiv preprint arXiv:1512.08756 (2015).</p><p>[11] Vinyals, Oriol, et al. « Show and tell: A neural image caption generator. » arXiv preprint arXiv:1411.4555 (2014).</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是对:&lt;a href=&quot;https://blog.heuritech.com/2016/01/20/attention-mechanism/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://blog.heuritech.com/2016/01/20/attention-mechanism/&lt;/a&gt; 的翻译。这篇文章对Attention Model原理进行了一个比较清晰的阐述，所以记录一下。由于本人英语能力有限，翻译不周的地方，还请见谅。&lt;br&gt;
    
    </summary>
    
      <category term="翻译文章" scheme="https://ilewseu.github.io/categories/%E7%BF%BB%E8%AF%91%E6%96%87%E7%AB%A0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="Attention Model" scheme="https://ilewseu.github.io/tags/Attention-Model/"/>
    
  </entry>
  
  <entry>
    <title>GRU神经网络</title>
    <link href="https://ilewseu.github.io/2018/01/20/GRU%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://ilewseu.github.io/2018/01/20/GRU神经网络/</id>
    <published>2018-01-20T05:58:20.000Z</published>
    <updated>2018-01-20T15:38:11.786Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GRU神经网络"><a href="#GRU神经网络" class="headerlink" title="GRU神经网络"></a>GRU神经网络</h2><p>GRU(Gated Recurrent Unit)是LSTM的一种变体，它对LSTM做了很多简化，同时却保持着和LSTM几乎相同的效果。因此，GRU最近变得非常流行。下图是GRU的网络架构图。<br><a id="more"></a><br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/180113/Ja3I15iABg.jpg?imageslim" alt="mark"><br>GRU对LSTM做了两个大得改动：</p><ul><li>将<strong>输入门、遗忘门和输出门</strong>改变为两个门：<strong>更新门（Update Gate)$z_t$</strong>和<strong>重置门(Reset Gate)$r_t$</strong>。</li><li><strong>将单元状态与输出合并为一个状态：h</strong>。</li></ul><p>根据上图的架构图可以得出GRU的前向计算公式：<br>$$\begin{aligned}<br>&amp;r_t = \sigma(W_r \cdot [h_{t-1},x_t])\\\\<br>&amp;z_t =\sigma(W_z \cdot [h_{t-1},x_t])\\\\<br>&amp;\hat {h_t}=tanh(W_{\hat {h}} \cdot [r_t \bigodot h_{t-1},x_t])\\\\<br>&amp;h_t =(1-z_t)\bigodot h_{t-1}+z_t \bigodot \hat {h_t}\\\\<br>&amp;y_t=\sigma(W_o \cdot h_t)<br>\end{aligned}$$</p><h2 id="GRU的反向传播梯度计算"><a href="#GRU的反向传播梯度计算" class="headerlink" title="GRU的反向传播梯度计算"></a>GRU的反向传播梯度计算</h2><p>GRU的参数更新方式同样是基于沿时间反向传播的算法（BPTT）,为了为了更清晰的推导GRU反向传播梯度计算，对上文的GRU前向计算公式进行一定的改写，实质上还是一样的，只不过是将参数分开写而已。具体如下：假设，对于t时刻，GRU的输出为$\hat {y_t}$，输入为$x_t$，前一时刻的状态为$s_{t-1}$，则可以得出如下的前向计算的公式：<br>$$\begin{aligned}<br>    &amp;z_t = \sigma(U_zx_t+W_zs_{t-1}+b_z)\\\\<br>    &amp;r_t = \sigma(U_r x_t+W_rs_{t-1}+b_r)\\\\<br>    &amp;h_t = tanh(U_hx_t+W_h(s_{t-1}\bigodot  r_t)+b_h)\\\\<br>    &amp;s_t = (1-z_t)\bigodot  h_t + z_t \bigodot  s_{t-1}\\\\<br>    &amp;\hat {y_t}=softmax(Vs_t+b_V)<br>\end{aligned}<br>$$<br>其中，$\bigodot$表示向量的点乘；$z_t$表示更新门；$r_t$表示重置门；$\hat {y_t}$表示t时刻的输出。<br>如果采用交叉熵损失函数，那么在t时刻的损失为$L_t$:$$<br>L_t =sumOfAllElements(-y_t\bigodot log(\hat {y_t}))<br>$$<br>为了训练GRU，需要把所有时刻的损失加在一起，并最小化损失$L=\sum_{t=1}^T L_t$:<br>$$argmin_{\Theta}L$$<br>其中，$\Theta={U_z,U_r,U_c,W_z,W_r,W_c,b_z,b_r,b_c,V,b_V}$。</p><p>这是一个非凸优化问题，通常采用随机梯度下降法去解决问题。因此，需要计算$\partial L/ \partial U_z,\partial L/ \partial U_r,\partial L/ \partial U_h,\partial L/ \partial W_z,\partial L/ \partial W_r,\partial L/ \partial W_h,\partial L/ \partial b_z,\partial L/ \partial b_r,\partial L/ \partial b_h,\partial L/ \partial V,\partial L/ \partial b_v$。计算上面的梯度，最好的方式是利用链式法则从输出到输入一步一步去计算，为了更好得看清输入、中间值以及输出之间的关系，画了一张GRU的计算图，如下图所示：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/180120/bHHG1j84eF.jpg?imageslim" alt="mark"><br></div><br>根据计算图，利用链式法则计算梯度，需要从上至下沿着边进行计算。如果节点X有多条出边和目标节点T相连，如果要计算$\partial T / \partial X$，需要分别计算每条边对X的梯度，并将梯度进行相加。</p><p>以计算$\frac {\partial L}{\partial U_z}$为例，其他的计算方式和其相似。因为$L=\sum_{t=1}^T L_t$，所以，$\frac {\partial L}{\partial U_z}=\sum_{t=1}^T \frac {\partial L_t}{\partial U_z}$，因此，可以先计算$\frac {\partial L_t}{\partial U_z}$，然后将不同时刻结果加起来就可以。</p><p>根据链式法则:$$\frac {\partial L_t}{\partial U_z} = \frac {\partial L_t}{\partial s_t} \frac{\partial s_t}{\partial U_z}    (公式1)<br>$$<br>公式1右边的第一个式子的计算如下：$$\frac {\partial L_t}{\partial s_t}=V(\hat {y_t}-y_t)    (公式2)<br>$$<br>对于$\frac {\partial z}{\partial U_z}$，一些人可能会直接进行如下的求导计算<br>$$<br>\frac {\overline{\partial s_t}}{\partial U_z}=((s_{t-1}-h_t)\bigodot z_t \bigodot (1-z_t))x_t^T     (公式3)<br>$$<br>在$s_t$的计算公式里有$1-z$和$z\bigodot s_{t-1}$两个公式都会影响到$\frac {\partial s_t}{\partial U_z}$。正确的方法是分别计算每条边的偏导数，并将它们相加，因此，需要引入$\frac {\partial s_t}{\partial s_{t-1}}$。但是，公式3只计算了部分的梯度，因此用$\frac {\overline{\partial s_t}}{\partial U_z}$表示。</p><p>因为$s_{t-1}$同样依赖于$U_z$，因此我们不能把$s_{t-1}$作为一个常量处理。$s_{t-1}$同样会受到$s_i,i=1,…,t-2$的影响，因此，需要将公式1进行扩展，如下：<br>$$\begin{aligned}<br>    \frac {\partial L_t}{\partial U_z} = &amp;\frac {\partial L_t}{\partial s_t} \frac{\partial s_t}{\partial U_z}\\\\<br>    =&amp;\frac {\partial L_t}{\partial s_t}\sum_{i=1}^t(\frac{\partial s_t}{\partial s_i}\frac{\overline {\partial s_i}}{\partial U_z})\\\\<br>    =&amp;\frac {\partial L_t}{\partial s_t}\sum_{i=1}^t ((\prod_{j=i}^{t-1} \frac {\partial s_{j+1}}{\partial s_j})\frac{\overline {\partial s_i}}{\partial U_z})<br>\end{aligned}     (公式4)<br>$$<br>其中，$\frac{\overline {\partial s_i}}{\partial U_z}$是$s_i$对$U_z$的梯度，其计算公式如公式3所示。<br>$\frac {\partial s_t}{\partial s_{t-1}}$的计算和$\frac {\partial s_t}{\partial z}$的计算相似。因为从$s_{t-1}$到$s_t$有四条边，直接或间接相连，通过$z_t,r_t和h_t$，因此，需要计算这四条边上的梯度，然后进行相加，计算公式如下：$$\begin{aligned}<br>\frac {\partial s_t}{\partial s_{t-1}}=&amp;\frac {\partial s_t}{\partial h_t} \frac {\partial h_t}{\partial s_{t-1}}+\frac{\partial s_t}{\partial z_t}\frac{\partial z_t}{\partial s_{t-1}} + \frac {\overline {\partial s_t}}{\partial s_{t-1}}\\\\<br>=&amp;\frac {\partial s_t}{\partial h_t}(\frac {\partial h_t}{\partial r_t}\frac {\partial r_t}{\partial s_{t-1}}+\frac {\overline {\partial h_t}}{\partial s_{t-1}}) + \frac {\partial s_t}{\partial z_t}\frac{\partial z_t}{\partial s_{t-1}}+\frac {\overline {\partial s_t}}{\partial s_{t-1}}<br>\end{aligned}    (公式5)$$<br>其中，$\frac {\overline {\partial s_t}}{\partial s_{t-1}}$是对$s_t$关于$s_{t-1}$的导数，并将$h_t,z_t$看做常量。同样，$\frac {\overline {\partial h_t}}{\partial s_{t-1}}$是$h_t$关于$s_{t-1}$的导数，将$r_t$看做常量。最终，可以得到:<br>$$ \frac {\partial s_t}{\partial s_{t-1}}=(1-z_t)(W_r^T((W_h^T(1-h\bigodot h))\bigodot s_{t-1}\bigodot r \bigodot (1-r))+((W_h^T(1-h \bigodot h))\bigodot r_t))+\\\\W_z^T((s_{t-1}-h_t)\bigodot z_t \bigodot (1-z_t))+z     (公式6)$$<br>到此为止，$\frac {\partial L}{\partial U_z}$的计算已经完成，而其余的参数的计算和它的计算方式类似，沿着计算图一步一步计算，这里就不一一计算了。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>A Tutorial On Backward Propagation Through Time (BPTT) In The Gated Recurrent Unit (GRU) RNN</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;GRU神经网络&quot;&gt;&lt;a href=&quot;#GRU神经网络&quot; class=&quot;headerlink&quot; title=&quot;GRU神经网络&quot;&gt;&lt;/a&gt;GRU神经网络&lt;/h2&gt;&lt;p&gt;GRU(Gated Recurrent Unit)是LSTM的一种变体，它对LSTM做了很多简化，同时却保持着和LSTM几乎相同的效果。因此，GRU最近变得非常流行。下图是GRU的网络架构图。&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="GRU" scheme="https://ilewseu.github.io/tags/GRU/"/>
    
  </entry>
  
  <entry>
    <title>LSTM参数更新推导</title>
    <link href="https://ilewseu.github.io/2018/01/06/LSTM%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0%E6%8E%A8%E5%AF%BC/"/>
    <id>https://ilewseu.github.io/2018/01/06/LSTM参数更新推导/</id>
    <published>2018-01-06T07:45:20.000Z</published>
    <updated>2018-01-20T15:22:34.868Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转自：<a href="https://zybuluo.com/hanbingtao/note/581764，对其进行一定的整理。" target="_blank" rel="external">https://zybuluo.com/hanbingtao/note/581764，对其进行一定的整理。</a></p></blockquote><h2 id="LSTM前向计算"><a href="#LSTM前向计算" class="headerlink" title="LSTM前向计算"></a>LSTM前向计算</h2><a id="more"></a><p>在<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">Understanding LSTM Networks</a>一文中，介绍了LSTM的基本原理。LSTM网络使用了门(gete)的概念，门实际上就是一层全连接，它的输入是一个向量，输出是一个0到1之间的实数向量。假设W是门的权重向量，b是偏置项，那么门可以表示为：$$<br>g(x) =\sigma(Wx+b)<br>$$<br>门的使用，就是用门的输出向量按元素乘以要控制的向量。因为门的输出是0到1之间的实数向量。所以，当门输出为0时，任何向量与之相乘都会得到0向量，这就相当于不能通过；当输出为1时，任何向量与之相乘都不会有任何改变，相当都通过。因为$\sigma$函数的值域是(0,1)，所以门的状态都是半开半闭的。</p><p>典型的LSTM的网络架构图如下图所示：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/180106/49m8miGdIC.jpg?imageslim" alt="mark"><br></div><br>相比RNN网络，LSTM新增加状态C，称为单元状态(cell state)，如下图所示：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/180106/adGab6A7GF.png?imageslim" alt="mark"></div></p><pre><code>图引自：https://zybuluo.com/hanbingtao/note/581764</code></pre><p><br>从图中可以看出，LSTM的输入有三个：<strong>当前时刻网络的输入$x_t$、上一时刻LSTM的输出值$h_{t-1}$以及上一时刻的单元状态$c_{t-1}$</strong>。LSTM的输出有两个：<strong>当前时刻LSTM输出值$h_t$和当前时刻的单元状态$c_t$</strong>。在这里x、h、c都是向量。</p><p>LSTM中引入了三个门：<strong>遗忘门(forget gate)、输入门(input gate)和输出门(output gate)</strong>。</p><ul><li><strong>遗忘门</strong>：它决定了上一时刻的单元状态$c_{t-1}$有多少保留到当前时刻$c_t$;</li><li><strong>输入门</strong>：它决定了当前时刻网络的输入$x_t$有多少保留到单元状态$c_t$。</li><li><strong>输出门</strong>：来控制单元状态$c_t$有多少输出到LSTM的当前输出值$h_t$。</li></ul><p><strong>遗忘门计算</strong><br>$$f_t = \sigma(W_f\cdot[h_{t-1},x_t]+b_f)        (公式1)$$<br>其中，$W_f$是遗忘门的权重矩阵，$[h_{t-1},x_t]$是表示把两个向量连接成一个更长的向量，$b_f$是遗忘门的偏置项，$\sigma$是sigmoid函数。事实上权重矩阵$W_f$是由两个矩阵拼接而成的，一个是$W_{fh}$，它对应着输入项$h_{t-1}$，一个是$W_{fx}$。$W_f$可以写为：$$<br>[W_f]\begin{bmatrix}h_{t-1}\\\\x_t\end{bmatrix}=\begin{bmatrix}<br>    W_{fh}&amp;W_{fx}<br>\end{bmatrix}\begin{bmatrix}h_{t-1}\\\\x_t\end{bmatrix}=W_{fh}h_{t-1}+W_{fx}x_t<br>$$</p><p><strong>输出门计算</strong><br>$$i_t=\sigma(W_i\cdot[h_{t-1},x_t]+b_i)    (公式2)$$</p><p><strong>单元状态$\hat{c_t}$</strong><br>$$\hat{c_t}=tanh(W_c\cdot[h_{t-1},x_t]+b_c)    (公式3)$$<br>单元状态$c_t$,它是有上一时刻的单元状态$c_{t-1}$按元素乘以遗忘门$f_t$，再用当前输入的单元状态$\hat{c_t}$按元素乘以输入门$i_t$，再将两个积加和产生的：<br>$$c_t = f_t \bigodot c_{t-1}+i_t \bigodot \hat{c_t}    (公式4)$$<br>其中$\bigodot$表示按位相乘。这样就把LSTM关于当前的记忆$\hat{c_t}$和长期的记忆$c_{t-1}$组合在一起，形成了新的状态单元$c_t$。由于遗忘门的控制，它可以保存很久很久之前的信息，由于输入门的控制，又可以避免当前无关紧要的内容进入记忆。下面看一下输出门，它控制了长期记忆对当前输出的影响：<br><strong>输出门</strong><br>$$o_t=\sigma(W_o\cdot[h_{t-1},x_t]+b_o)    (公式5)$$</p><p>LSTM最终的输出，是由输出门和单元状态共同确定的：<br>$$h_t = o_t \bigodot tanh(c_t)     (公式6)$$<br>从公式1到公式6就是LSTM的前向计算的全部公式。<br>LSTM前向传播的更新过程如下：</p><ol><li><strong>更新遗忘门的输出：</strong>$$f_t = \sigma(W_f\cdot[h_{t-1},x_t]+b_f)$$</li><li><strong>更新输入门的两部分输出:</strong>$$i_t=\sigma(W_i\cdot[h_{t-1},x_t]+b_i)\\\\\hat{c_t}=tanh(W_c\cdot[h_{t-1},x_t]+b_c)$$</li><li><strong>更新细胞状态:</strong>$$c_t = f_t \bigodot c_{t-1}+i_t \bigodot \hat{c_t}$$</li><li><strong>更新输出门状态:</strong>$$o_t=\sigma(W_o\cdot[h_{t-1},x_t]+b_o)\\\\h_t = o_t \bigodot tanh(c_t)$$</li><li><strong>更新当前序列输出</strong>:$$\hat {y_t}=\sigma(Vh_t+b_y)$$</li></ol><h2 id="LSTM反向传播"><a href="#LSTM反向传播" class="headerlink" title="LSTM反向传播"></a>LSTM反向传播</h2><p>LSTM的训练算法，仍然是反向传播算法，主要有三个步骤：</p><ol><li>前向计算每个神经元的输出值，对于LSTM来说，即$f_t、i_t、c_t、o_t、h_t$ 5组向量。</li><li>反向计算每个神经元的误差项$\delta$。与循环神网络一样，LSTM误差项的反向传播也是包括两个方向：一个是沿时间的反向传播，即从当前时刻t开始，计算每个时刻的误差项；一个是将误差项向上一层传播。</li><li>根据相应的误差项，计算每个权重的梯度。</li></ol><p>LSTM需要学习的参数共有8组，分别是：遗忘门的权重矩阵$W_f$和偏置项$b_f$、输入门的权重矩阵$W_i$和偏置项$b_i$、输出门的权重矩阵$W_o$和偏置项$b_o$以及计算单元状态的权重矩阵$W_c$和偏置项$b_c$。因为权重矩阵的两部分在反向传播中使用不同的公式，因此，权重矩阵$W_f$、$W_i$、$W_c$、$W_o$都将被写为分开的两个矩阵:$W_{fh}$、$W_{fx}$、$W_{ih}$、$W_{ix}$、$W_{ch}$、$W_{cx}$、$W_{oh}$、$W_{ox}$。</p><p>在t时刻，LSTM的输出值为$h_t$，定义t时刻的误差项为$\delta_t$为:$$<br>\delta_t = \frac {\partial E}{\partial h_t}$$</p><p>因为LSTM有四个加权输入，分别为$f_t、i_t、c_t、o_t、h_t$，定义这四个加权输入，以及他们对应的误差项。$$<br>net_{f,t} = W_f[h_{t-1},x_t]+b_f=W_{fh}h_{t-1}+W_{fx}x_t+b_f\\\\<br>net_{i,t} = W_i[h_{t-1},x_t]+b_i=W_{ih}h_{t-1}+W_{ix}x_t+b_i\\\\<br>net_{\hat{c},t} = W_c[h_{t-1},x_t]+b_f=W_{ch}h_{t-1}+W_{cx}x_t+b_c\\\\<br>net_{o,t} = W_o[h_{t-1},x_t]+b_o=W_{oh}h_{t-1}+W_{ox}x_t+b_o\\\\<br>\delta_{f,t}=\frac {\partial E}{\partial net_{f,t}}\\\\<br>\delta_{i,t}=\frac {\partial E}{\partial net_{i,t}}\\\\<br>\delta_{\hat{c},t}=\frac {\partial E}{\partial net_{\hat{c},t}}\\\\<br>\delta_{o,t}=\frac {\partial E}{\partial net_{o,t}}<br>$$</p><h3 id="误差项沿时间反向传递"><a href="#误差项沿时间反向传递" class="headerlink" title="误差项沿时间反向传递"></a>误差项沿时间反向传递</h3><p>沿时间反向传递误差项，就是要计算出t-1时刻的误差项$\delta_{t-1}$。<br>$$<br>\delta_{t-1}^T=\frac {\partial E}{\partial h_{t-1}}=\frac {\partial E}{\partial h_{t}}\frac {\partial h_t}{\partial h_{t-1}}=\delta_t^T\frac  {\partial h_t}{\partial h_{t-1}}<br>$$<br>其中，$\frac {\partial h_t}{\partial h_{t-1}}$是一个Jacobian矩阵。如果隐藏层h的维度是N的话，那么它就是一个N*N的矩阵。为了求出它，先列出$h_t$的计算公式，即公式6和公式4：<br>$$<br>h_t=o_t\bigodot tanh(c_t)\\\\c_t=f_t \bigodot c_{t-1}+i_t \bigodot \hat {c_t}<br>$$<br>可以看出，$o_t、f_t、i_t、\hat{c_t}$都是$h_{t-1}$的函数，那么利用全导数公式可得：$$<br>\delta_t^T\frac {\partial h_t}{\partial h_{t-1}}=\delta_t^T\frac {\partial h_t}{\partial o_t}\frac {\partial o_t}{\partial net_{o,t}}\frac {\partial net_{o,t}}{\partial h_{t-1}}+\delta_t^T\frac {\partial h_t}{\partial c_t}\frac {\partial c_t}{\partial f_t}\frac{\partial f_t}{\partial net_{f,t}}\frac {\partial net_{f,t}}{\partial h_{t-1}}+\delta_t^T\frac{\partial h_t}{\partial c_t}\frac {\partial c_t}{\partial i_t}\frac {\partial i_t}{\partial net_{i,t}}\frac {\partial net_{i,j}}{\partial h_{t-1}}\\\\=\delta_{o,t}^T\frac {\partial net_{o,t}}{\partial h_{t-1}}+\delta_{f,t}^T\frac {\partial net_{f,t}}{\partial h_{t-1}}+\delta_{i,t}^T\frac {\partial net_{i,t}}{\partial h_{t-1}}+\delta_{\hat{c_t},t}^T\frac{\partial net_{\hat{c_t},t}}{\partial h_{t-1}}\\\(公式7)<br>$$<br>下面要把公式7中的每个偏导数都求出来，根据公式6，我们可以求出：$$<br>\frac {\partial h_t}{\partial o_t}= diag[tanh(c_t)]\\\\<br>\frac {\partial h_t}{\partial c_t}= diag[o_t\bigodot(1-tanh(c_t)^2)]<br>$$<br>根据公式4，可以求出：$$<br>\frac {\partial c_t}{\partial f_t} = diag[c_{t-1}]\\\\<br>\frac {\partial c_t}{\partial i_t} = diag[\hat{c_t}]\\\\<br>\frac {\partial c_t}{\partial \hat{c_t}} =diag[i_t]<br>$$<br>因为：$$\begin{aligned}<br>    &amp;o_t = \sigma(net_{o,t})\\\\<br>&amp;net_{o,t} = W_{oh}h_{t-1}+W_{ox}x_t+b_o\\\ <br>&amp;f_t = \sigma(net_{f,t})\\\ <br>&amp;net_{f,t} = W_{ft}h_{t-1}+W_{fx}x_t+b_f\\\ <br>&amp;i_t = \sigma(net_{i,t})\\\\<br>&amp;net_{i,t}=W_{ih}h_{t-1}+W_{ix}x_t+b_i\\\ <br>&amp;\hat{c_t}=tanh(net_{\hat{c},t})\\\\<br>&amp;net_{\hat{c},t}=W_{ch}h_{t-1}+W_{cx}x_t+b_c<br>\end{aligned}<br>$$<br>很容易得出:<br>$$\begin{aligned}<br>&amp;\frac {\partial o_t}{\partial net_{o,t}}= diag[o_t\bigodot(1-o_t)]\\\\<br>&amp;\frac {\partial_{o,t}}{\partial h_{t-1}}=W_{oh}\\\\<br>&amp;\frac {\partial f_t}{\partial net_{f,t}}=diag[f_t\bigodot(1-f_t)]\\\\<br>&amp;\frac {\partial net_{f,t}}{\partial h_{t-1}}=W_{fh}\\\\<br>&amp;\frac {\partial i_t}{\partial net_{i,j}}=diag[i_t\bigodot(1-i_t)]\\\\<br>&amp;\frac {\partial net_{i,t}}{\partial h_{t-1}}=W_{ih}\\\\<br>&amp;\frac {\partial \hat{c_t}}{\partial net_{\hat{c},t}}=diag[1-\hat{c_t}^2]\\\\<br>&amp;\frac {\partial net_{\hat{c},t}}{\partial h_{t-1}}=W_{ch}<br>\end{aligned}<br>$$<br>将上述偏导数带入公式7，可以得到：$$<br>\delta_{t-1} = \delta_{o,t}^T\frac {\partial net_{o,t}}{\partial h_{t-1}}+\delta_{f,t}^T\frac {\partial net_{f,t}}{\partial h_{t-1}}+\delta_{i,t}^T\frac {\partial net_{i,t}}{\partial h_{t-1}}+\delta_{\hat{c},t}^T\frac {\partial net_{\hat{c},t}}{\partial h_{t-1}}=\delta_{o,t}^TW_{oh}+\delta_{f,t}^TW_{fh}+\delta_{i,t}^TW_{i,h}+\delta_{\hat{c},t}^TW_{ch}    (公式8)$$</p><p>根据$\delta_{o,t}、\delta_{f,t}、\delta_{i,t}、\delta_{\hat{c},t}$的定义，可知：<br>$$<br>\begin{aligned}<br>&amp;\delta_{o,t}^T = \delta_t^T\bigodot tanh(c_t)\bigodot o_t\bigodot(1-o_t)(公式9)\\\\<br>&amp;\delta_{f,t}^T =\delta_t^T \bigodot o_t\bigodot(1-tanh(c_t)^2)\bigodot c_{t-1}\bigodot f_t \bigodot (1-f_t)(公式10)\\\\<br>&amp;\delta_{i,t}^T = \delta_t^T \bigodot o_t \bigodot(1-tanh(c_t)^2)\bigodot \hat{c_t}\bigodot i_t \bigodot (1-i_t)(公式11)\\\\<br>&amp;\delta_{\hat{c},t}^T=\delta_t^T\bigodot o_t\bigodot(1-tanh(c_t)^2)\bigodot i_t\bigodot (1-\hat{c}^2)(公式12)<br>\end{aligned}<br>$$<br>公式8到公式12就是将误差沿时间反向传播的一个时刻的公式。有了它，我们可以写出将误差向前传递到任意时刻k的公式：$$<br>\delta_k^T = \prod_{j=k}^t-1\delta_{o,j}^TW_{oh}+\delta_{f,j}^TW_{fh}+\delta_{i,j}^TW_{ih}+\delta_{\hat{c},j}^TW_{ch}<br>$$</p><h3 id="将误差传递到上一层"><a href="#将误差传递到上一层" class="headerlink" title="将误差传递到上一层"></a>将误差传递到上一层</h3><p>假设当前层为第l层，定义第l-1层的误差项是误差函数l-1层加权输入的导数，即:$$<br>\delta_t^{l-1}=\frac {\partial E}{\partial net_t^{l-1}}<br>$$<br>LSTM的输入$x_t$由下面的公式计算：<br>$$<br>x_t^l = f^{l-1}(net_t^{l-1})<br>$$<br>上式中，$f^{l-1}$表示第l-1层的激活函数。<br>因为$net_{f,t}^l、net_{i,t}^l、net_{\hat{c},t}^l、net_{o,t}^l$都是$x_t$的函数，$x_t$又是$net_t^{l-1}$的函数，因此，要求出E对$net_t^{l-1}$的导数，就需要使用全导数公式：<br>$$\begin{aligned}<br>\frac {\partial E}{\partial net_t^{l-1}}<br>&amp;=\frac {\partial E}{\partial net_{f,t}^l}\frac {\partial net_{f,t}^l}{\partial x_t^l}\frac {\partial x_t^l}{\partial net_t^{l-1}}+\frac {\partial E}{\partial net_{i,t}^l}\frac{\partial net_{i,t}^l}{\partial x_t^l}\frac {\partial x_t^l}{\partial net_{i,t}^{l-1}}+\frac {\partial E}{\partial net_{\hat{c},t}^l}\frac{\partial net_{\hat{c},t}^l}{\partial x_t^l}\frac {\partial x_t^l}{\partial net_t^{l-1}}+\frac{\partial E}{\partial net_{o,t}^l} \frac{\partial net_{o,t}^l}{\partial x_t^l}\frac{\partial x_t^l}{\partial net_{o,t}^{l-1}}\\\\<br>&amp;=\delta_{f,t}^TW_{fx}\bigodot f^{\prime}(net_t^{l-1})+\delta_{i,t}^TW_{ix}\bigodot f^{\prime}(net_t^{l-1})+\delta_{\hat{c},t}^TW_{cx}\bigodot f^{\prime}(net_t^{l-1})+\delta_{o,t}^TW_{ox}\bigodot f^{\prime}(net_t^{l-1})\\\\&amp;=<br>(\delta_{f,t}^TW_{fx}+\delta_{i,t}^TW_{ix}+\delta_{\hat{c},t}^TW_{cx}+\delta_{o,t}^TW_{ox})\bigodot f^{\prime}(net_l^{l-1})<br>\end{aligned}(公式14)$$</p><p>公式14就是将误差传递到上一层的公式。</p><h3 id="权重梯度计算"><a href="#权重梯度计算" class="headerlink" title="权重梯度计算"></a>权重梯度计算</h3><p>对度$W_{fh}、W_{ih}、W_{ch}、W_{oh}$的权重梯度，我们知道我们知道它的梯度是各个时刻梯度之和，我们首先求出它们在t时刻的梯度，然后再求出他们最终的梯度。我们已经求得误差项$\delta_{o,t}、\delta_{f,t}、\delta_{i,t}、\delta_{\hat{c},t}$很容易求出t时刻$W_{fh}、W_{ih}、W_{ch}、W_{oh}$的梯度。$$<br>\begin{aligned}<br>   &amp;\frac{\partial E}{\partial W_{oh,t}}=\frac{\partial E}{\partial net_{o,t}}\frac{\partial net_{o,t}}{\partial W_{oh,t}}=\delta_{o,t}h_{t-1}^T\\\\<br>   &amp;\frac{\partial E}{\partial W_{fh,t}}=\frac{\partial E}{\partial net_{f,t}}\frac{\partial net_{f,t}}{\partial W_{fh,t}}=\delta_{f,t}h_{t-1}^T\\\\<br>   &amp;\frac{\partial E}{\partial W_{ih,t}}=\frac{\partial E}{\partial net_{i,t}}\frac{\partial net_{i,t}}{\partial W_{ih,t}}=\delta_{i,t}h_{t-1}^T\\\\<br>   &amp;\frac{\partial E}{\partial W_{ch,t}}=\frac{\partial E}{\partial net_{\hat{c},t}}\frac{\partial net_{\hat{c},t}}{\partial W_{ch,t}}=\delta_{\hat{c},t}h_{t-1}^T<br>\end{aligned}<br>$$<br>将各个时刻的梯度加在一起，就能得到最终的梯度：$$<br>\begin{aligned}<br>&amp;\frac{\partial E}{\partial W_{oh}}=\sum_{j=1}^t\delta_{o,j}h_{j-1}^T\\\\<br>&amp;\frac{\partial E}{\partial W_{fh}}=\sum_{j=1}^t\delta_{f,j}h_{j-1}^T\\\\<br>&amp;\frac{\partial E}{\partial W_{ih}}=\sum_{j=1}^t\delta_{i,j}h_{j-1}^T\\\\<br>&amp;\frac{\partial E}{\partial W_{ch}}=\sum_{j=1}^t\delta_{\hat{c},j}h_{j-1}^T\\\\<br>\end{aligned}<br>$$<br>对于偏置项$b_f、b_i、b_c、b_o$的梯度，也是将各个时刻的梯度加在一起，下面是各个时刻的偏置梯度:<br>$$\begin{aligned}<br>&amp;\frac{\partial E}{\partial b_{o,t}}=\frac {\partial E}{\partial net_{o,t}}\frac{\partial net_{o,t}}{\partial b_{o,t}}=\delta_{o,t}\\\\<br>&amp;\frac{\partial E}{\partial b_{f,t}}=\frac {\partial E}{\partial net_{f,t}}\frac{\partial net_{f,t}}{\partial b_{f,t}}=\delta_{f,t}\\\\<br>&amp;\frac{\partial E}{\partial b_{i,t}}=\frac {\partial E}{\partial net_{i,t}}\frac{\partial net_{i,t}}{\partial b_{i,t}}=\delta_{i,t}\\\\<br>&amp;\frac{\partial E}{\partial b_{c,t}}=\frac {\partial E}{\partial net_{\hat{c},t}}\frac{\partial net_{\hat{c},t}}{\partial b_{c,t}}=\delta_{\hat{c},t}<br>\end{aligned}<br>$$<br>下面是最终的偏置项的梯度，即将各个时刻的偏置项梯度加在一起：<br>$$<br>\begin{aligned}<br>&amp;\frac {\partial E}{\partial b_o}=\sum_{j=1}^t\delta_{o,j}\\\\<br>&amp;\frac {\partial E}{\partial b_i}=\sum_{j=1}^t\delta_{i,j}\\\\<br>&amp;\frac {\partial E}{\partial b_f}=\sum_{j=1}^t\delta_{f,j}\\\\<br>&amp;\frac {\partial E}{\partial b_c}=\sum_{j=1}^t\delta_{\hat{c},j}<br>\end{aligned}<br>$$<br>对于$W_{fx}、W_{ix}、W_{cx}、W_{ox}$的权重梯度，只需要根据相应的误差项直接计算即可:<br>$$\begin{aligned}<br>&amp;\frac {\partial E}{\partial W_{ox}}=\frac{\partial E}{\partial net_{o,t}}\frac{\partial net_{o,t}}{\partial W_{ox}}=\delta_{o,t}x_t^T\\\\<br>&amp;\frac {\partial E}{\partial W_{fx}}=\frac{\partial E}{\partial net_{f,t}}\frac{\partial net_{f,t}}{\partial W_{fx}}=\delta_{f,t}x_t^T\\\\<br>&amp;\frac {\partial E}{\partial W_{ix}}=\frac{\partial E}{\partial net_{i,t}}\frac{\partial net_{i,t}}{\partial W_{ix}}=\delta_{i,t}x_t^T\\\\<br>&amp;\frac {\partial E}{\partial W_{cx}}=\frac{\partial E}{\partial net_{\hat{c},t}}\frac{\partial net_{\hat{c},t}}{\partial W_{cx}}=\delta_{\hat{c},t}x_t^T\\\\<br>\end{aligned}<br>$$</p><p>&lt;–end–&gt;</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转自：&lt;a href=&quot;https://zybuluo.com/hanbingtao/note/581764，对其进行一定的整理。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zybuluo.com/hanbingtao/note/581764，对其进行一定的整理。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;LSTM前向计算&quot;&gt;&lt;a href=&quot;#LSTM前向计算&quot; class=&quot;headerlink&quot; title=&quot;LSTM前向计算&quot;&gt;&lt;/a&gt;LSTM前向计算&lt;/h2&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="LSTM" scheme="https://ilewseu.github.io/tags/LSTM/"/>
    
      <category term="GRU" scheme="https://ilewseu.github.io/tags/GRU/"/>
    
  </entry>
  
  <entry>
    <title>理解LSTM</title>
    <link href="https://ilewseu.github.io/2017/12/31/%E7%90%86%E8%A7%A3LSTM/"/>
    <id>https://ilewseu.github.io/2017/12/31/理解LSTM/</id>
    <published>2017-12-31T09:35:20.000Z</published>
    <updated>2018-01-01T05:49:12.227Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文是<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/的译文，这篇文章对LSTM的原理讲解的非常清楚，故存下来。" target="_blank" rel="external">http://colah.github.io/posts/2015-08-Understanding-LSTMs/的译文，这篇文章对LSTM的原理讲解的非常清楚，故存下来。</a></p></blockquote><h2 id="Recurrent-Neural-Networks"><a href="#Recurrent-Neural-Networks" class="headerlink" title="Recurrent Neural Networks"></a>Recurrent Neural Networks</h2><p>人类并非每一秒都从头开始思考问题。当你阅读这篇文章时，你是基于之前的单词来理解，每个单词。你并不会把所有的内容都抛弃掉，然后从头开始理解。你的思考具有持久性。<br><a id="more"></a><br>传统的神经网络并不能做到这一点，这似乎是其一个主要的缺点。例如，想象你要把一部电影里面的时间点正在发生的事情进行分类。传统神经网络并不知道怎样才能把关于之前事件的推理运用到之后的事件中去。RNN神经网络解决了这个问题。它们是一种具有循环的网络，具有保持信息的能力。如下图所示：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/Bmh8aD2DdA.jpg?imageslim" alt="mark"><br></div><br>如上图所示，神经网络的模块A输入为$x_i$，输出为$h_t$。模块A的循环结构使得信息从网络的上一步传到了下一步。这个循环使得RNN看起来有点神秘。然而，如果你仔细想想就会发现它与普通的神经网络并没有太大不同。RNN可以被认为是相同网络的多重复制结构，每一个网络把消息传给其继承者。如果我们把循环体展开就是这样，如下图所示：<br><div align="center"><br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/iK11DGDA83.jpg?imageslim" alt="mark"><br></div><p>这种链接属性表明，RNN与序列之间有着紧密的连续。这也是运用这类数据最自然的结构。当然它们已经得到了应用。过去几年中，RNNs已经被成功用于各式各样的问题中：语音识别、语言建模、翻译、图像标注..等等。RNNs取得的各种瞩目成果可以参考Andrej Karpathy的博客：The Unreasonable Effectiveness of Recurrent Neural Networks。确实效果让人非常吃惊。</p><p>取得这项成功的一个要素是LSTMs，这是一种非常特殊的周期神经网络，对于许多任务，比标准版要有效得多。几乎所有基于RNN的好成果都使用了它们。本文将着重介绍LSTMs。</p><h2 id="长期依赖问题-The-Problem-of-Long-Term-Dependencies"><a href="#长期依赖问题-The-Problem-of-Long-Term-Dependencies" class="headerlink" title="长期依赖问题(The Problem of Long-Term Dependencies)"></a>长期依赖问题(The Problem of Long-Term Dependencies)</h2><p>RNNs的一个想法是，它们可能会能够将之前的信息连接到现在的任务之中。例如，用视频前一帧的信息可以用于理解当前帧的信息。如果RNNs能够做到这些，那么将会非常有用。但是它们可以吗？ 这要看情况。</p><p>有时候，我们处理当前任务仅需要查看当前信息。例如，设想用一个语言模型基于当前单词尝试着去预测下一个单词。如果我们尝试着预测”the clouds are in the”的最后一个单词，我们并不需要任何额外的信息，很显然下一个但是sky。这样的话，如果目标预测的点与其他相关信息的点之间的间隔较小，RNNs可以学习利用过去的信息。</p><p>但是，也有时候我们需要更多的上下文信息。设想预测这句话的最后一个单词：”I grew up in France… I speak fluent <strong>French</strong>“。最近的信息表明下一个单词似乎是一种语言的名字，但是如果我们希望缩小确定语言类型的范围，我们需要更早之前作为France 的上下文。而且需要预测的点与其相关点之间的间隔非常有可能变得很大，如图所示：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/3La0B0C0iK.jpg?imageslim" alt="mark"><br></div><br>不幸的是，随着间隔增长，RNNs变得难以学习连接之间的关系，如下图所示：<br><br><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/d9IAjAB7IL.jpg?imageslim" alt="mark"><br></div><p>理论上来说，RNNs绝对能够处理这种『长期依赖』。人们可以小心选取参数来解决这种类型的小模型。悲剧的是，事实上，RNNs似乎并不能学习出来这些参数。这个问题已经在<a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" target="_blank" rel="external">Hochreiter (1991) German</a>与<a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="external">Bengio, et al. (1994)</a>,中被深入讨论，他们发现了为何RNNs不起作用的一些基本原因。幸运的是，LSTMs可以解决这个问题!</p><div></div><h2 id="LSTM网络"><a href="#LSTM网络" class="headerlink" title="LSTM网络"></a>LSTM网络</h2><p>长短时间记忆网络(Long Short Term Memory networks, LSTMs)，是一种特殊的RNN，它能够学习长时间依赖。它们由<a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf" target="_blank" rel="external">Hochreiter &amp; Schmidhuber (1997)</a>，后来由很多让人加以改进和推广。它们在大量的问题上都取得了巨大的成功，现在已经被广泛应用。</p><p>LSTMs是专门设计用来避免长期依赖问题的。记忆长期信息是LSTMs的默认行为，而不是它们努力学习的东西！所有RNN都具有链式的重复模块神经网络。在标准的RNNs中，这种重复模块具有非常简单的结构，比如是一个tanh层，如下图所示：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/BF8kcb785A.jpg?imageslim" alt="mark"><br></div><br>LSTMs同样具有链式结构，但是其重复模块却有着不同的结构。不同于单独的神经网络层，它具有4个以特殊方式相互影响的神经网络层，如图所示：<br><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/6IlDEAkI3L.jpg?imageslim" alt="mark"><br></div><br>不要担心接下来涉及到的细节。我们将会一步步讲解LSTM的示意图。下面是我们将要用到的符号，如图所示：<br><div><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/GC9cecCGhg.jpg?imageslim" alt="mark"><br></div><p>在上图中，每一条线代表一个完整的向量，从一个节点的输出到另一个节点的输入。粉红色圆形代表了逐点操作。例如，向量求和；黄色方框代表学习出的神经网络层；聚拢的线代表了串联，而分开的线代表了内容复制去了不同的地方。</p><h3 id="LSTMs背后的核心思想"><a href="#LSTMs背后的核心思想" class="headerlink" title="LSTMs背后的核心思想"></a>LSTMs背后的核心思想</h3><p>LSTMs的关键在于细胞状态，在图中以水平线表示。<br>细胞状态就像一个传送带。它顺着整个链条从头到尾运行，中间只有少许线性的交互。信息很容易顺着它流动而保持不变。如图所示：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/92f48mcjDG.jpg?imageslim" alt="mark"><br></div><p>LSTM通过称之为门(gates)的结构来对细胞状态增加或删除信息。门是选择性的让信息通过的方式。它们的输出有一个sigmoid层和逐点乘积操作，如图所示：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/Lek8DbbiFC.jpg?imageslim" alt="mark"><br></div><br>Sigmoid 层的输出在0到1之间，定义了各成分被放行通过的程度。0值意味着『不让任何东西过去』；1值意味着『让所有东西通过』。LSTM具有3种门，用于保护和控制细胞状态。<br><div> </div><h3 id="逐步讲解LSTM"><a href="#逐步讲解LSTM" class="headerlink" title="逐步讲解LSTM"></a>逐步讲解LSTM</h3><p>LSTM的第一步是决定我们要从细胞中抛弃何种信息。这个决定是由叫做『遗忘门』的sigmoid层决定的。它以$h_{t-1}$和$x_i$为输入，在$C_{t-1}$细胞输出一个介于0和1之间的数。其中，1代表『完全保留』，0代表『完全遗忘』。</p><p>让我们回到之前那个语言预测模型的例子，这个模型尝试着根据之前的单词学习预测下一个单词。在这个问题中，细胞状态可能包括了现在的主语的性别，因此能够使用正确的代词。当我们见到一个新的主语时，我们希望它能够忘记之前主语的性别。如下图所示：</p><div align="center"><img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/cG7AbK6EEC.jpg?imageslim" alt="mark"></div><br>下一步是决定细胞要存储何种信息。它有2个组成部分，首先一各叫做『输入门层』的sigmoid层决定我们将要更新哪些值。其次，一个tanh层创建一个新的候选向量$\hat{C}_t$，它可以加在状态之中。在下一步我们将结合两者来生成状态的更新。在语言模型的例子中，我们希望把新主语的性别加入到状态之中，从而取代我们打算遗忘的旧主语的性别，如下图所示：<br><div><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/Hce780KF2L.jpg?imageslim" alt="mark"><br></div><br>现在我们可以将旧细胞状态$C_{t-1}$更新为$C_t$了。之前的步骤已经决定了该怎么做，我们现在实际操作一下。我们把旧状态乘以$f_t$，用以遗忘之前我们决定忘记的信息。然后我们加上$i_t*\hat{C}_t$。这是新的候选值，根据我们决定更新状态的程度来作为缩放系数。<br><br>在语言模型中，这里就是我们真正丢弃关于旧主语性信息以及添加新信息的地方，如下图所示：<br><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/BC8GaK4Fjc.jpg?imageslim" alt="mark"><br></div><br>最终，我们可以决定输出哪些内容。输出取决于我们的细胞状态，但是以一个过滤后的版本。首先，我们使用sigmoid层来决定我们要输出细胞状态的哪些部分。然后，把用tanh处理细胞状态（将状态值映射到-1至1之间）。最后，将其与sigmoid门的输出值相乘，从而我们能够输出我们决定输出的值。如下图所示：<br><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/f2b7k0070c.jpg?imageslim" alt="mark"><br></div><br>对于语言模型，在预测下一个单词的例子中，当它输入一个主语，它可能会希望输出相关的动词。例如，当主语时单数或复数时，它可能会以相应形式的输出。<br><div></div><h3 id="各种LSTM的变化形式"><a href="#各种LSTM的变化形式" class="headerlink" title="各种LSTM的变化形式"></a>各种LSTM的变化形式</h3><p>目前，我所描述的都是普通的LSTM，然而并非所有的LSTM都是一样的。事实上，似乎每一篇使用LSTMs的文章都有细微的差别。这些差别很小，但是值得一提。</p><p>其中一个流行的LSTM变化形式是由<a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="external">Gers &amp; Schmidhuber (2000)</a>提出的，增加了『窥视孔连接（peephole connections）』。如下图所示：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/8e4JBf654L.jpg?imageslim" alt="mark"><br></div><br>在上图中，所有的门都加上了窥视孔，但是许多论文中只在其中一些装了窥视孔。<br>另一个变种是使用了配对遗忘与输入门。与之前分别决定遗忘与添加信息不同，我们同时决定两者。只有当我们需要输入一些内容的时候我们才需要忘记。只有当早前信息被忘记之后我们才会输入。如图所示：<br><div><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/H16C53f5IC.jpg?imageslim" alt="mark"><br></div><p>LSTM 一个更加不错的变种是 Gated Recurrent Unit（GRU），是由<a href="https://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="external">Cho, et al. (2014)</a>提出的。这个模型将输入门与和遗忘门结合成了一个单独的『更新门』。而且同时还合并了细胞状态和隐含状态，同时也做了一下其他的修改。因此这个模型比标准LSTM模型要简单，并且越来越收到欢迎。如下图所示：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171231/F2C472DeBH.jpg?imageslim" alt="mark"><br></div><br>这些仅仅只是LSTM的少数几个著名变种。还有很多其他的种类，例如由<a href="https://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="external">Yao, et al. (2015)</a> 提出的Depth Gated RNNs 。以及处理长期依赖问题的完全不同的手段，如<a href="https://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="external">Koutnik, et al. (2014)</a>提出的Clockwork RNNs。</p><p>那种变种是最好的？这些不同重要吗？<a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="external">Greff, et al. (2015)</a>将各种著名的变种做了比较，发现其实基本上是差不多的。<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="external">Jozefowicz, et al. (2015)</a>测试了超过一万种RNN结构，发现了一些在某些任务上表现良好的模型。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>最开始我提到的杰出成就都是使用的是RNNs。本质上所有的这些成果都是使用了LSTMs。在大多数任务中，确实它们的表现非常优秀。</p><p>以公式的形式写下来，LSTMs看起来非常令人胆怯。然而本文的逐步讲解使得LSTM变得平易近人了。</p><p>LSTMs 是我们使用RNNs的重要一步。我们很自然地想到：还有下一个重要的一大步吗？研究者的普遍观点是：『有！下一大步就是「注意力」。』其基本思想就是让RNN的每一步从更大范围的信息中选取。例如，假设你为图片打标签，它可能会为它输出的每一个词语选取图片的一部分作为输入。事实上，<a href="http://arxiv.org/pdf/1502.03044v2.pdf" target="_blank" rel="external">Xu, et al. (2015)</a>就是这么做的——如果你想探索『注意力』的话，这是个有趣的引子！已经有大量使用『注意力』得到的良好成果，而且似乎更多的陈果也将要出现……</p><p>『注意力』并非是RNN研究中唯一一个激动人心的方向。例如，<a href="http://arxiv.org/pdf/1507.01526v1.pdf" target="_blank" rel="external">Kalchbrenner, et al. (2015)</a>做出的Grid LSTMs 似乎很有前途。在生成模型中使用RNNs－例如<a href="http://arxiv.org/pdf/1502.04623.pdf" target="_blank" rel="external">Gregor, et al. (2015)</a>，<a href="http://arxiv.org/pdf/1506.02216v3.pdf" target="_blank" rel="external">Chung, et al. (2015)</a>以及<a href="http://arxiv.org/pdf/1411.7610v3.pdf" target="_blank" rel="external">Bayer &amp; Osendorfer (2015)</a>－似乎也很有趣。过去几年是RNN激动人心的阶段，未来几年将会更加如此！</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是&lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/的译文，这篇文章对LSTM的原理讲解的非常清楚，故存下来。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://colah.github.io/posts/2015-08-Understanding-LSTMs/的译文，这篇文章对LSTM的原理讲解的非常清楚，故存下来。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Recurrent-Neural-Networks&quot;&gt;&lt;a href=&quot;#Recurrent-Neural-Networks&quot; class=&quot;headerlink&quot; title=&quot;Recurrent Neural Networks&quot;&gt;&lt;/a&gt;Recurrent Neural Networks&lt;/h2&gt;&lt;p&gt;人类并非每一秒都从头开始思考问题。当你阅读这篇文章时，你是基于之前的单词来理解，每个单词。你并不会把所有的内容都抛弃掉，然后从头开始理解。你的思考具有持久性。&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="LSTM" scheme="https://ilewseu.github.io/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>循环神经网络RNN 梯度推导(BPTT)</title>
    <link href="https://ilewseu.github.io/2017/12/30/RNN%E7%AE%80%E5%8D%95%E6%8E%A8%E5%AF%BC/"/>
    <id>https://ilewseu.github.io/2017/12/30/RNN简单推导/</id>
    <published>2017-12-30T03:28:20.000Z</published>
    <updated>2018-02-09T15:19:21.535Z</updated>
    
    <content type="html"><![CDATA[<h2 id="循环神经网络简介"><a href="#循环神经网络简介" class="headerlink" title="循环神经网络简介"></a>循环神经网络简介</h2><p>循环神经网络(Recurrent Neural Network,RNN)，是一种sequence model，它的思想就是使用序列信息。<strong>在前馈、卷积神经网络中，认为输入（和输出）彼此之间是互相独立的。但是对很多任务而言，这种处理方式很不合理。同时，在前馈、卷积神经网络中，输入和输出的维数都是固定的，不能任意改变，且无法处理变长的序列数据</strong>。<a id="more"></a>循环神经网络，它对于序列中的每个元素都执行相同的任务，输出依赖于之前的计算。另一种思考循环神经网络的方法是，它们有一个记忆，记忆可以捕获迄今为止已经计算过的信息。理论上循环神经网络可以利用任意长度的序列信息。但是，在实际应用中，由于梯度传播的原因，它们仅能利用有限步长。循环神经网络的网络结构图如下：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171230/HEIa45LFfD.jpg?imageslim" alt="mark"><br></div><p>在上图的网络中，网络在t时刻接收到输入$x_t$之后，隐藏层的值是$s_t$，输出值是$o_t$。$h_t$的值不仅依赖于$x_t$，还取决于$s_{t-1}$。循环神经网络的计算方法如下：$$<br>o_t = g(V_{h_t})                      (公式1)\\\\<br>s_t = f(Ux_t+Ws_{t-1})    (公式2)<br>$$</p><p>其中，公式1是<strong>输出层</strong>的计算公式，输出层可以是一个全连接层，<strong>V</strong>是输出层的权重矩阵，<strong>g</strong>是相应的激活函数。公式2是<strong>隐藏层</strong>的计算公式，它是循环层。<strong>U</strong>是输入x的权重矩阵，<strong>W</strong>是上一层的输出值$s_{t-1}$作为这一次的输入的权重矩阵，<strong>f</strong>是激活函数。</p><p>可以看出，循环层和全连接层的区别就是多了一个权重矩阵W。如果把公式2反复带到公式1，我们可以得到：<br>$$<br>\begin{aligned}<br>o_t &amp;= g(Vs_t)\\\\<br>&amp;=Vf(Vs_t)\\\\<br>&amp;=Vf(Ux_t+Ws_{t-1})\\\\<br>&amp;=Vf(Ux_t+Wf(Ux_{t-1}+Ws_{t-2}))\\\\<br>&amp;=Vf(Ux_t+Wf(Ux_{t-1}+Wf(Ux_{t-2}+Ws_{t-3})))\\\\<br>&amp;=Vf(Ux_t+Wf(Ux_{t-1}+Wf(Ux_{t-2}+Wf(Ux_{t-3}+…))))<br>\end {aligned}<br>$$</p><p>从上面可以看出，循环神经网络的输出值$o_t$，是受前面的历次输入值$x_t、x_{t-1}、x_{t-2}、…$影响的，这就是为什么循环神经网络可以往前看任意多个输入值的原因。<br><strong>循环神经网络的隐藏层的输出可以用于预测词汇/标签等符号的分布，隐藏层状态保留了到目前为止的历史信息。</strong></p><h2 id="循环神经网络的训练算法BPTT介绍"><a href="#循环神经网络的训练算法BPTT介绍" class="headerlink" title="循环神经网络的训练算法BPTT介绍"></a>循环神经网络的训练算法BPTT介绍</h2><p>循环神网络的训练算法是Backpropagation Through Time,BPTT算法，其基本原理和反向传播算法是一样的，只不过反向传播算法是按照层进行反向传播，BPTT是按照时间t进行反向传播。对于下图所示的循环神经网络：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171230/A0ih479fhh.jpg?imageslim" alt="mark"><br></div><br>这个图和上面的图所示的架构没有区别，只不过是把隐藏层的状态用$h_t$表示，t时刻的输出用$y_t$表示。$$<br>         h_t = f(Uh_{t-1}+Wx_t+b)\\\\y_t=softmax(Vh_t)<br>$$<br>假设循环神经网络在每个时刻t都有一个监督信息，损失为$J_t$，则整个序列的损失为$J=\sum_{t=1}^T J_t$。$$<br>J_t = -y_tlogy_t\\\\<br>    J = -\sum_{t=1}^T y_tlogy_t<br>$$</p><p><strong>1、J关于V的梯度计算</strong></p><p>$$<br>\frac {\partial J}{\partial V} = \frac {\partial}{\partial V} \sum_{t=1}^T J_t=\sum_{t=1}^T \frac {\partial J_t}{\partial V}<br>$$<br>令$$y_t = softmax(z_t)\\\ z_t = Vh_t$$，则$\frac {\partial J_t}{\partial V}$的计算公式如下：</p><p>$$<br>\frac {\partial J_t}{\partial V} = \frac {\partial J_t}{\partial y_t}\frac {\partial y_t}{\partial V}=\frac {\partial J_t}{\partial y_t} \frac {\partial y_t}{\partial z_t} \frac {\partial z_t}{\partial V}<br>$$</p><p><strong>2、损失J关于U的梯度计算</strong></p><p>$$<br>\frac {\partial J}{\partial U} = \frac {\partial}{\partial U} \sum_{t=1}^T \frac {\partial J_t}{\partial U}=\sum_{t=1}^T \frac {\partial h_t}{\partial U} \frac {\partial J_t}{\partial h_t}<br>$$<br>其中，$h_t$是关于U和$h_{t-1}$的函数，而$h_{t-1}$又是关于U和$h_{t-2}$的函数。</p><p>用链式法则可以得到：<br>$$\frac {\partial J}{\partial U} = \sum_{t=1}^T\sum_{k=1}^t \frac {\partial h_k}{\partial U} \frac {\partial h_t}{\partial h_k} \frac {\partial y_t}{\partial h_t}\frac {\partial J_t}{\partial y_t}\\\\<br>h_t = f(Uh_{t-1} + Wx_t+b)$$<br>其中，<br>$$<br>\frac {\partial h_t}{\partial h_k} = \prod_{i=k+1}^{t} \frac {\partial h_i}{\partial h_{i-1}} = \prod_{i=k+1}^t U^Tdiag[f^{\prime}(h_{i-1})]<br>$$</p><p>则J对U的梯度为：<br>$$<br>\frac {\partial J}{\partial U} = \sum_{t=1}^T \sum_{k=1}^t \frac {\partial h_k}{\partial U}(\prod_{i=k+1}^t U^T diag[f^{\prime}(h_{i-1})])\frac {\partial y_t}{\partial h_t}\frac {\partial J_t}{\partial y_t}<br>$$</p><p><strong>3、损失J关于W的梯度计算</strong></p><p>$$\frac {\partial J}{\partial W} = \frac {\partial}{\partial W}\sum_{t=1}^T J_t=\sum_{t=1}^T \frac {\partial J_t}{\partial W}=\sum_{t=1}^T \frac {\partial h_t}{\partial W} \frac {\partial J_t}{\partial h_t}$$</p><p>用链式法则可以得到：<br>$$\frac {\partial J}{\partial W}=\sum_{t=1}^T \sum_{k=1}^t \frac{\partial h_k}{\partial W}\frac{\partial h_t}{\partial h_k}\frac {\partial y_t}{\partial h_t} \frac {\partial J_t}{\partial y_t}\\\\<br>h_t = f(Uh_{t-1} + Wx_t+b)$$</p><p>其中，<br>$$<br>\frac {\partial h_t}{\partial h_k} = \prod_{i=k+1}^{t} \frac {\partial h_i}{\partial h_{i-1}} = \prod_{i=k+1}^t U^Tdiag[f^{\prime}(h_{i-1})]<br>$$<br>则，对W的梯度为：<br>$$<br>\frac {\partial J}{\partial W} = \sum_{t=1}^T\sum_{k=1}^t \frac {\partial h_k}{\partial W}(\prod_{i=k+1}^t U^Tdiag[f^{\prime}(h_{i-1})])\frac {\partial y_t}{\partial h_t}\frac {\partial J_t}{\partial y_t}<br>$$</p><p>如果定义$\gamma=||U^T diag(f^{\prime}(h_{i-1})||$，则在上面公式中的括号里面$\gamma^{t-k}$。如果$\gamma &gt; 1$，则当$t-k \rightarrow \infty$时，$\gamma^{t-k} \rightarrow \infty$，会造成系统的不稳定，也就是所谓的梯度爆炸问题；相反，如果$\gamma &lt; 1$，$t-k \rightarrow \infty$，$\gamma^{t-k} \rightarrow 0$，会出现和深度前馈神经网络类似的梯度消失的问题。</p><p>因此，虽然简单循环网络可从理论上可以建立长时间间隔的状态之间的依赖关系，但是由于梯度爆炸或消失的存在，实际上只能学习到短期的依赖关系，这就是所谓的长期依赖问题。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;循环神经网络简介&quot;&gt;&lt;a href=&quot;#循环神经网络简介&quot; class=&quot;headerlink&quot; title=&quot;循环神经网络简介&quot;&gt;&lt;/a&gt;循环神经网络简介&lt;/h2&gt;&lt;p&gt;循环神经网络(Recurrent Neural Network,RNN)，是一种sequence model，它的思想就是使用序列信息。&lt;strong&gt;在前馈、卷积神经网络中，认为输入（和输出）彼此之间是互相独立的。但是对很多任务而言，这种处理方式很不合理。同时，在前馈、卷积神经网络中，输入和输出的维数都是固定的，不能任意改变，且无法处理变长的序列数据&lt;/strong&gt;。
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="CNN" scheme="https://ilewseu.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络学习笔记</title>
    <link href="https://ilewseu.github.io/2017/12/23/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://ilewseu.github.io/2017/12/23/卷积神经网络学习笔记/</id>
    <published>2017-12-23T11:48:20.000Z</published>
    <updated>2018-01-01T05:50:41.359Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文是对近期学习的卷积神经网络相关知识的简单记录和梳理。</p></blockquote><h2 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h2><p>卷积神经网络(Convolution Neural Network，CNN或ConvNet)是一种前馈神经网络。卷积神经网络是受生物学上<strong>感受野</strong>(Receptive Field)的机制提出来的。一个神经元的感受野是指特定区域，只有这个区域内的刺激才能够激活该神经元。<br><a id="more"></a></p><blockquote><p>感受野，主要是指听觉、视觉等神经系统中一些神经元的特性，即神经元只接受其所支配的刺激区域内的信号。在视觉神经系统中，视觉皮层中的神经细胞的输出依赖于视网膜上的光感受器。视网膜上的光感受器受刺激兴奋时，将神经冲动信号传到视觉皮层，但不是所有的视觉皮层中的神经元都会接受这些信号。一个神经元的感受野指视网膜上的特定区域，只有这个区域内的刺激才能够激活该神经元。</p></blockquote><p>卷积神经网络最早是主要处理图像信息。如果用全连接前馈神经网络来处理图像时，会存在以下两个问题：</p><ul><li><strong>参数太多</strong>：如果图像的输入大小为100x100x3，在使用全连接前馈神经网络中，第一个隐藏层的每个神经元到输入层都有100x100x3=30,000个相互独立的连接，每个连接都对应一个权重参数。随着隐藏层神经元数量增多，参数的规模也会增加。这会导致整个神经网络的训练效率会非常低下，也会很容易出现过拟合。</li><li><strong>局部不变性特征</strong>： 自然图像中的物体都具有局部特征不变性，比如在尺度缩放、平移、旋转等操作不影响其语义信息。而全连接前馈神经网络很难提取这些局部不变性，一般需要进行数据增强来提高性能。</li></ul><p>目前的卷积神经网络一般是由卷积层、汇聚层和全连接层交叉堆叠而成的前馈神经网络，使用反向传播算法进行训练。卷积神经网络有三个结构上的特性：<strong>局部连接、权重共享以及子采样</strong>。这些特性使得卷积神经网络具有一定程度上的平移、缩放和旋转不变性。和前馈神经网络相比，卷积神经网络的参数更少。</p><h2 id="卷积运算"><a href="#卷积运算" class="headerlink" title="卷积运算"></a>卷积运算</h2><h3 id="卷积介绍"><a href="#卷积介绍" class="headerlink" title="卷积介绍"></a>卷积介绍</h3><p>卷积(convolution)，是数学分析中一种重要的运算。在信号处理或图像中，经常使用一维卷积或二维卷积。<br><strong>一维卷积</strong>，一维卷积常用在信号处理中，用于计算信号的延迟累积。假设一个信号发生器每个时刻t产生一个信号$x_t$,其信息的衰减率为$f_k$，即在k-1个时间步长后，信息变为原来的$f_k$倍。假设$f_1=1,f_2=1/2,f_3=1/4$，那么在时刻t收到的信号为$y_t$为当前时刻产生的信息和以前时刻延迟信息的叠加，$$<br>y_t = 1\times x_t + 1/2 \times x_{t-1} + 1/4 \times x_{t-2} \\\\<br>=f_1 \times x_t + f_2 \times x_{t-1} + f_3 \times x_{t-2}<br>$$<br>我们把$f_1,f_2…$称为滤波器(filter)或卷积核(convolution kernel)。假设滤波器的长度为m，它和一个信号序列$x_1,x_2…$的卷积为：$$<br>y_t = \sum_{k-1}^m f_k \cdot x_{t-k+1}<br>$$<br>信号序列<strong>x</strong>和滤波器<strong>w</strong>的卷积定义为：$$<br>y = w \bigotimes x<br>$$<br>一般情况下，滤波器的长度m远小于信号序列的长度n。当$f_k=1/m$时，卷积相当于移动平均。下图是一个一维卷积的例子：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171223/8b34KGFaEd.jpg?imageslim" alt="mark"><br></div><p><strong>二维卷积</strong>，卷积也经常用于图像处理中。因为图像是一个二维结构，需要将一维卷积进行扩展。给定一个图像$X \in R^{M \times N}$和滤波器$W \in R^{M \times N }$，一般m&lt;&lt;M，n&lt;&lt;N，其卷积为：$$<br>y_{ij} = \sum_{u=1}^m \sum_{v=1}^n w_{uv}\cdot x_{i-u+1,j-v+1}    (公式1)<br>$$</p><h3 id="卷积的类型"><a href="#卷积的类型" class="headerlink" title="卷积的类型"></a>卷积的类型</h3><p>根据在输入信号两端的补0的情况可以将卷积分为：<strong>窄卷积、宽卷积和等长卷积</strong>。</p><p><strong>一维卷积</strong></p><ul><li><strong>窄卷积</strong>，在信号两端不补0，输出信号长度为n-m+1；</li><li><strong>宽卷积</strong>，信号两端各补m-1个0，输出信号长度为n+m-1；</li><li><strong>等长卷积</strong>，信号两端各补(m-1)/2个0， 输出信号长度为n;</li></ul><p><strong>二维卷积</strong></p><ul><li><strong>窄卷积</strong>，信号四周不补0，输出信号长度为M-m+1*N-n+1;</li><li><strong>宽卷积</strong>，信号四周补0，输出长度为M+m-1*N+n-1;</li><li><strong>等长卷积</strong>，信号四周补0，输出长度为M*N;</li></ul><h3 id="卷积神经网络中的卷积"><a href="#卷积神经网络中的卷积" class="headerlink" title="卷积神经网络中的卷积"></a>卷积神经网络中的卷积</h3><p>在机器学和图像处理领域，卷积主要的功能是在一个图像上滑动一个卷积核，通过卷积核操作得到一组新的特征。在计算卷积的过程中，需要进行卷积的翻转。在具体的实现上，一般会以互相关操作来代替卷积，从而会减少一些不必要的操作或开销。<strong>互相关</strong>(cross-correlation)是一个衡量两个序列相关性的函数，通常是用滑动窗口的点积计算来实现。给定一个图像$x\in R^{M \times N}$和卷积核$W\in R^{m\times n}$，它们的互相关为：$$<br>y_{ij}=\sum_{u=1}^m \sum_{v=1}^n w_{uv} \cdot x_{i+u-1,j+v-1}<br>$$<br>和公式1相比，互相关和卷积的主要区别在于卷积核仅仅是否进行翻转。因此，互相关也可以称为不翻转卷积。</p><blockquote><p>翻转，就是从两个维度(从上到下、从左到右)颠倒次序，即旋转180度。</p></blockquote><p>在神经网络中使用卷积是为了进行特征抽取，卷积核是否进行翻转和其特征的抽取的能力无关。特别是当卷积核是可学习的参数时，卷积核互相关是等价的。因此，为了实现上的方便，卷积神经网络中的卷积实际上用互相关操作来代替卷积，可以将互相关表示为$$<br>Y=W \bigotimes X<br>$$<br>其中，$Y\in R^{M-m+1,N-n+1}$为输出矩阵。</p><p>互相关运算，即常用的卷积神经网络中的卷积操作示例如下图所示：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171223/E8hkhejggf.gif" alt="mark"><br></div><h3 id="卷积运算的性质"><a href="#卷积运算的性质" class="headerlink" title="卷积运算的性质"></a>卷积运算的性质</h3><p>卷积具有很多很好的性质，下面就介绍一下二维卷积的数学性质，同样适用于一维卷积。</p><p><strong>交换性</strong></p><p>如果不限制两个卷积信号的长度，卷积是具有交换性的，即$x \bigotimes y=y\bigotimes x$。</p><p>当输入信息和卷积核有固定长度时，它们的宽卷积依然具有交换性。</p><p>对于两维的图像$x\in R^{M \times N}$和卷积核$W\in R^{m\times n}$，对图像X的两个维度进行零填充，两端各补m-1和n-1个零，得到全填充的图像$\hat{X} \in R^{(M+2m-2) \times (N+2n-2)}$</p><p>图像X和卷积核W的宽卷积定义为：$$<br>\hat{Y}=W\hat{\bigotimes}X<br>$$<br>其中，$\hat{\bigotimes}$ 为宽卷积操作。<br>宽卷积具有交换性，即：$$<br>W\hat{\bigotimes}X=X\hat{\bigotimes}W<br>$$</p><p><strong>导数</strong></p><p>假设$Y=W\bigotimes X$，其中$x\in R^{M \times N}$，$W\in R^{m\times n}$，函数$f(Y)\in R$为一个标量函数，则：$$<br>\frac {\partial f(Y)}{\partial w_{uv}}=\sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1}\frac{\partial y_{ij}}{\partial w_{uv}}\frac {\partial f(Y)}{\partial y_{ij}}\\\\<br>=\sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1}x_{i+u-1,j+v-1}\frac {\partial f(Y)}{\partial y_{ij}}\\\\=\sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1}\frac {\partial f(Y)}{\partial y_{ij}}x_{u+i-1,v+j-1}<br>$$<br>可以看到，f(Y)关于W的偏导数为X和$\frac {\partial f(Y)}{\partial Y}$的卷积$$<br>\frac {\partial f(Y)}{\partial (W)} = \frac {\partial f(Y)}{\partial Y} \bigotimes X     (公式2)<br>$$<br>同理可以得到：$$<br>\frac {\partial f(Y)}{\partial x_{st}} = \sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1} \frac {\partial y_{ij}}{\partial x_{st}} \frac {\partial f(Y)}{\partial {y_{ij}}}\\\ = \sum_{i=1}^{M-m+1}\sum_{j=1}^{N-n+1} w_{s-i+1,t-j+1}\frac {\partial f(Y)}{\partial y_{ij}}     (公式3)<br>$$<br>其中，当(s-i+1)<1时，或(s-i+1)>m，或(t-j+1)<1，或(t-j+1)>n时，$w_{s-i+1,t-j+1}$，相当于对W进行了p=(M-m,N-n)的零填充。</1，或(t-j+1)></1时，或(s-i+1)></p><p>可以看到，f(Y)关于X的偏导数为W和$\frac {\partial f(Y)}{\partial Y}$的宽卷积。公式3中的卷积是真正的卷积，而不是互相关，为了一致性，我们用互相关的“卷积”，即：$$<br>\frac {\partial f(Y)}{\partial X} = rot180(\frac {\partial f(Y)}{\partial Y}) \hat {\bigotimes}W \\\\=rot180(W) \hat {\bigotimes} \frac {\partial f(Y)}{\partial Y}<br>$$</p><h2 id="卷积神经网络结构"><a href="#卷积神经网络结构" class="headerlink" title="卷积神经网络结构"></a>卷积神经网络结构</h2><p>首先，看一下典型的卷积神经网络的结构：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171223/0a5d261ald.png?imageslim" alt="mark"><br><br>    图片引自：<a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="external">https://www.zybuluo.com/hanbingtao/note/485480</a><br></div><br>如上图所示，一个卷积神经网络由若干<strong>卷积层、Pooling层、全连接层</strong>组成。通过设置不同的卷积层、Pooling层以及全连接层，可以构建不同的卷积神经网络结构，它常用的架构模式为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Input -&gt; [[卷积层]*N-&gt;Pooling ?] * M -&gt; [全连接层]*K</div></pre></td></tr></table></figure><br><br>也就是N个卷积层叠加，然后(可选)叠加一个Pooling层，重复这个结构M次，最后叠加K个全连接层。下面介绍每个层的作用。<br><div></div><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>全连接前馈神经网络中，第l-1层的$n^{(l-1)}$个神经元和第l层的$n^{(l)}$个神经元的连接采用的是全连接的方式，则权重矩阵有$n^{(l)}\times n^{(l-1)}$个参数，当l-1层和l层的神经元过多时，权重矩阵的参数非常多，训练的效率会非常低。</p><p>如果采用卷积来代替全连接，第l层的净输入$z^{(l)}$为第l-1层激活值$a^{(l-1)}$和滤波器$w^{(l)}$的卷积，即：$$<br>z^{(l)} = w^{(l)} \bigotimes a^{(l-1)} + b^{(l)}      (公式4)<br>$$<br>其中，滤波器$w^{(l)}$为权重向量，$b^{(l)}\in R^{(n^{l-1})}$为偏置。</p><p>根据卷积的定义，卷积层具有如下两个性质：</p><ul><li><p><strong>局部连接</strong> 在卷积层中的每一个神经元都和下一层某个局部窗口内的神经元相连，构成一个局部连接网络。如下图所示，卷积层和下一层之间的连接数大大减少，由原来的$n^{(l)}\times n^{(l-1)}$个连接变为$n^{(l)} \times m$个连接，m为滤波器的大小。</p><div align="center"><br>  <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171223/0mjIc9fDE5.jpg?imageslim" alt="mark"><br></div></li><li><p><strong>权重共享</strong>  从公式4可以看出，作为参数的滤波器$w^{(l)}$对于第l层的所有的神经元都是相同的。从上图也可以看出，所有同颜色连接上的权重是相同的。</p></li></ul><p>卷积层的主要作用是提取一个局部区域的特征，不同的卷积核相当于不同的特征提取器。上面介绍的卷积层的神经元和全连接都是一维结构。对于常见的图像为二维结构，因此为了更充分的利用图像的局部信息，通常将神经元组织为三维结构，其大小为$宽度M \times 高度N \times 深度D$，有D个$M\times N$的特征映射构成。</p><p><strong>特征映射（Feature Map)</strong> 为了增强卷积层的表示能力，我们可以使用K个不同的滤波器来得到K组不同的输出。每组输出都共享一个滤波器。如果我们把滤波器看成是一个特征提取器，每一组输出都可以看成是输入图像经过一个特征抽取后得到的特征。因此，在卷积神经网络中每一组输出也叫作一组<strong>特征映射</strong>。</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171223/CBbj606Kdd.jpg?imageslim" alt="mark"><br><br>    图片引自： <a href="https://nndl.github.io/" target="_blank" rel="external">https://nndl.github.io/</a> 卷积神经网络<br></div><p>在输入层，特征映射就是图像本身，如果图像是灰度图像，就是一个特征映射，深度为D=1；如果是彩色图像，分别有RGB三个颜色通道的特征映射，输入深度D=3。</p><p>假设一个卷积层的结构如下：</p><ul><li>输入特征映射组：$X \in R^{M \times N \times D}$为三维张量(tensor)，每个切片为矩阵$X^d \in R^{M \times N}$为一个输入特征映射，1&lt;=d&lt;=D；</li><li>输出特征映射组：$Y \in R^{M^{\prime}\times N^{\prime} \times P^{\prime}}$为三维张量，其中每个切片矩阵$Y^p \in R^{M^{\prime}\times N^{\prime}}，$1&lt;=p&lt;=P；</li><li>卷积核：$W \in R^{m\times n \times D \times P}$为四维张量，其中每个切片矩阵$W^{p,d}\in R^{m \times n}$为一个两维卷积核，1&lt;=d&lt;=D，1&lt;=p&lt;=P;</li></ul><p>为了计算输出特征映射$Y^p$，用卷积核$W^{p,1},W^{p,2},…,W^{p,D}$分别对输入特征$X^1,X^2,…,X^D$进行卷积，然后将卷积结果相加，并加上一个标量偏置b得到卷积层的净输入$Z^P$，再经过非线性激活函数得到最终的输出特征映射$Y^p$。$$<br>Z^p = W^p \bigotimes X + b^p = \sum_{d=i}^D W^{p,d} \bigotimes X^d + b^p\\\\<br>Y^p = f(Z^p)<br>$$</p><p>其中，$W^p \in R^{m \times n \times D}$为三维卷积核，f(.)为非线性激活函数，一般用ReLU函数。整个计算的过程如下图所示。如果希望卷积层输出P个特征映射，可以将上述计算过程重复P次，得到P个输出特征映射，$Y^1,Y^2,…,Y^P$。</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171223/AE2h0aHFgl.jpg?imageslim" alt="mark"><br><br>    图片引自： <a href="https://nndl.github.io/" target="_blank" rel="external">https://nndl.github.io/</a> 卷积神经网络<br></div><p>在输入为$X \in R^{M \times N \times D}$，输出为$Y \in R^{M^{\prime}\times N^{\prime} \times P^{\prime}}$的卷积层中，每一个输入特征映射都需要D个滤波器以及一个偏置。假设每个滤波器的大小为$m \times n$，那么共需要$P \times D \times (m \times n)+P$个参数。</p><h3 id="Pooling层"><a href="#Pooling层" class="headerlink" title="Pooling层"></a>Pooling层</h3><p>汇聚层(Pooling Layer)，也叫子采样层(subsampling layer)，作用就是进行特征选择，降低特征数量，从而减少参数的数量。卷积层虽然可以减少网络中连接的数量，但特征映射组中的神经元个数没有显著减少。如果后面接一个分类器，分类器的输入维数依然很高，很容易出现过拟合。为了解决这个问题，可以在卷积层之后加一个汇聚层，从而降低特征的维数，避免过拟合。</p><p>对于卷积层得到的一个特征映射$X^{(l)}$，我们可以将$X^{(l)}$划分为很多区域$R_K,k=1,2…,K$。区域$R_k$可以重叠，也可以不重叠，则采样层的输出有：$$<br>X^{(l+1)} = f(W^{(l+1)}\cdot down(R_k)+b^{(l+1)})<br>$$<br>其中，$w^{(l+1)}$和$b^{(l+1)}$分别是可训练的权重和偏置参数。于是，可以简化成如下公式：$$<br>X^{(l+1)} = f(W^{(l+1)}\cdot down(X^{(l)})+b^{(l+1)})<br>$$<br>其中，$down(X^{(l)})$是指子采样后的特征映射。</p><p>常见的采样方式如下：</p><ul><li><p>最大值采样（Maximum Pooling） </p><p>  $pool_{max}(R_k) = max_{i\in R_k}a_i$</p></li><li><p>最小值采样（Minimum Pooling）<br>  $pool_{min}(R_k) = min_{i\in R_k}a_i$</p></li><li><p>平均值采样（Average pooling）<br>  $pool_{ave}(R_k) = \frac {1}{|R_k|}\sum_{i\in R_k}^{|R_k|} a_i$</p></li><li><p>TopK采样</p><p>  $pool_k(R_k) = topk_{i \in R_k}a_i$</p></li></ul><p>下图为最大值采样的一个示例：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171223/c6AaDDg9d1.jpg?imageslim" alt="mark"><br><br><br></div><p>典型的汇聚层是将每个特征映射划分为2X2的大小的不重叠的区域，然后使用最大汇聚的方式进行下采样。汇聚层也可以看做是一个特殊的卷积层，卷积核的大小为$m\times m$，步长为$s \times s$，卷积核为max函数或者mean函数。过大的采样区域会急剧减少神经元的数量，造成过多的信息损失。</p><h2 id="卷积神经网络参数学习"><a href="#卷积神经网络参数学习" class="headerlink" title="卷积神经网络参数学习"></a>卷积神经网络参数学习</h2><p>在卷积神经网络中，参数为卷积核中的权重以及偏置。和前馈神经网络类似，卷积神经网络也可以通过误差反向传播算法来进行参数学习。</p><p>在全连接前馈神经网络中，梯度主要通过每一层的误差项$\delta$进行反向传播，并进一步计算每层参数的梯度。在卷积神经网络中，主要有两种不同功能的神经层：<strong>卷积层和汇聚层</strong>。 </p><p>对第l层为卷积层，第l-1层的输入特征为$X^{(l-1)} \in R^{M \times N \times D}$，通过卷积计算得到第l层的特征净输入为$Z^{(l)}\in R^{M^{\prime} \times N^{\prime} \times P}$，第l层的第p个特征净输入为：$$<br>Z^{(l,p)} = \sum_i^D W^{(l,p,d)} \bigotimes X^{(l-1,d)} + b^{(l,p)}<br>$$<br>其中，$W^{(l,p,d)}$和$b^{(l,p)}$为卷积核及偏置。第l层中共有$P \times D$个卷积核和P个偏置，可以分别使用链式法则来计算器梯度。$$<br>\frac {\partial L(Y,\hat{Y})}{\partial W^{(l,p,d)}} = \frac {\partial L(Y,\hat{Y})}{\partial Z^{(l,p)}} \bigotimes X^{(l-1, d)}\\\\=\delta^{l,p} \bigotimes X^{(l-1,d)}<br>$$<br>其中，$\delta^{(l,p)}$为损失函数关于第l层的第p个特征映射净输入$Z^{(p,l)}$的偏导数。</p><p>同理可以得到，损失函数关于第l层第p个偏置$b^{(l,p)}$的梯度为：<br>$$<br>\frac {\partial L(Y,\hat {Y})}{\partial b^{(l,p)}} = \sum_{i,j}[\delta^{(l,p)}]_{i,j}.<br>$$<br>因此，卷积网络的每层参数的梯度也依赖于其所在层的误差项$\delta^{(l,p)}$。卷积层和汇聚层中，误差项的计算有所不同，因此，需要分别计算误差项。</p><p><strong>汇聚层</strong></p><p>当第l+1层为汇聚层时，因为汇聚层是下采样操作，l+1层的每个神经元的误差项$\delta$对应于第l层的相应特征的一个区域。l层的第p个特征映射中的每个神经元都有一条边和l+1层的第p个特征映射中的一个神经元相连。根据链式法则，第l层的一个特征映射的误差项$\delta^{(l,p)}$，只需要将l+1层对应的特征映射误差项$\delta^{(l+1, p)}$进行上采样，再和l层的特征映射的激活值偏导数逐元素相乘就得到了$\delta^{(l,p)}$。 </p><p>第l层的第p个特征映射的误差项$\delta^{(l,p)}$的具体推导如下：$$<br>\delta^{(l,p)} = \frac {\partial L(Y,\hat{Y})}{\partial Z^{(l,p)}}\\\\<br>=\frac {\partial X^{(l,p)}}{\partial Z^{(l,p)}} \cdot \frac {\partial Z^{(l+1,p)}}{\partial X^{(l,p)}} \cdot frac {\partial L(Y,\hat {Y})}{\partial Z^{(l+1, p)}}\\\\=f_l^\prime(Z^{(l,p)}) \bigodot up(\delta^{(l+1, k)})<br>$$<br>其中，$f_l^\prime(Z^{(l,p)})$为第l层使用的激活函数导数，up为上采样函数，与汇聚层中使用的下采样操作刚好相反。如果下采样是最大汇聚，误差项$\delta^{(l+1, k)}$中的每个值将会直接传递到上一层对应区域中最大值所对应的神经元，该区域中其他神经元的误差项都设为0,。如果采用平均采样，误差项$\delta^{(l+1, k)}$中的每个值都会被平均分配到上一层对应的区域中的所有神经元上。</p><p><strong>卷积层</strong></p><p>当第l+1层为卷积层时，假设特征映射净输入为$Z^{(l+1)} \in R^{M^\prime \times N^\prime \times K}$，其中第k个特征映射的净输入为：$$<br>Z^{(l+1,k)} = \sum_{p=1}^P W^{(l+1,k,p)} \bigotimes X^{(l,p)} + b^{(l+1, k)}<br>$$</p><p>其中，$W^{(l+1,k,p)}$和$b^{(l+1, k)}$为第l+1层的卷积核及偏置。第l+1层中共有$K\times P$个卷积核和K个偏置。第l层的第p个特征映射为误差项$\delta^{(l,p)}$的具体推导如下：<br>$$<br>\delta^{(l,p)} = \frac {\partial L(Y,\hat{Y})}{\partial Z^{(l,p)}}<br>\\\\<br>=\frac {\partial X^{(l,p)}}{\partial Z^{l,p}}\cdot \frac {\partial L(Y,\hat{Y})}{\partial X^{(l,p)}}\\\\=f_l^\prime(Z^{(l)}) \bigodot \sum_{k=1}^K (rot180(W^{(l+1,k,p)}) \hat{\bigotimes} \frac {\partial L(Y,\hat{Y})}{\partial Z^{(l+1, k)}})\\\\=f_l^\prime(Z^{(l)}) \bigodot \sum_{k=1}^K(rot180(W^{(l+1,k,p)}) \hat{\bigotimes} \delta^{(l=1,k)})<br>$$</p><p>其中，$\hat{\bigotimes}$为宽卷积。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://nndl.github.io/" target="_blank" rel="external">https://nndl.github.io/</a> 卷积神经网络</li><li><a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="external">https://www.zybuluo.com/hanbingtao/note/485480</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是对近期学习的卷积神经网络相关知识的简单记录和梳理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;卷积神经网络简介&quot;&gt;&lt;a href=&quot;#卷积神经网络简介&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络简介&quot;&gt;&lt;/a&gt;卷积神经网络简介&lt;/h2&gt;&lt;p&gt;卷积神经网络(Convolution Neural Network，CNN或ConvNet)是一种前馈神经网络。卷积神经网络是受生物学上&lt;strong&gt;感受野&lt;/strong&gt;(Receptive Field)的机制提出来的。一个神经元的感受野是指特定区域，只有这个区域内的刺激才能够激活该神经元。&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="https://ilewseu.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="CNN" scheme="https://ilewseu.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>前馈神经网络反向传播推导</title>
    <link href="https://ilewseu.github.io/2017/12/17/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%8E%A8%E5%AF%BC/"/>
    <id>https://ilewseu.github.io/2017/12/17/前馈神经网络反向传播推导/</id>
    <published>2017-12-17T12:08:08.000Z</published>
    <updated>2017-12-24T09:03:31.194Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前馈神经网络前向传播"><a href="#前馈神经网络前向传播" class="headerlink" title="前馈神经网络前向传播"></a>前馈神经网络前向传播</h2><a id="more"></a><p>一个三层的前馈神经网络如下图所示：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171216/Jb3maf249i.png?imageslim" alt="mark"><br></div><br>对于第二层的输出$a_1^2,a_2^2,a_3^2$,有：<br>$$<br>a_1^2 = \sigma(z_1^2)=\sigma(w_{11}^2x_1+w_{12}^2x_2+w_{13}^2x_3+b_1^2)\\\\<br>a_2^2 = \sigma(z_2^2)=\sigma(w_{21}^2x_1+w_{22}^2x_2+w_{23}^2x_3+b_3^2)\\\\<br>a_3^2 = \sigma(z_3^2)=\sigma(w_{31}^2x_1+w_{32}^2x_2+w_{33}^2x_3+b_3^2)<br>$$<br>对于第三层的输出$a_1^3$，有：<br>$$a_1^3 = \sigma(z_1^3)=\sigma(w_{11}^3x_1+w_{12}^3x_2+w_{13}^3x_3+b_1^3)$$</p><p>用下面的符号来描述一个前馈神经网络：</p><ul><li>L:表示神经网络的层数；</li><li>$n^l$：表示第l层神经元的个数；</li><li>$f_l(.)$:表示第l层神经元的激活函数；</li><li>$W^{(l)}\in R^{n^l\times n^{l-1}}$:表示第l-1层到第l层的权重矩阵；</li><li>$b^{(l)\in R^{n^l}}$：表示第l-1层到第l层的偏置；</li><li>$z^{(l)\in R^{n^l}}$:表示第l层神经元的净输入；</li><li>$a^{(l)\in R^{n^l}}$:表示第l层神经元的输出（激活值）；</li><li>$W_{ij}^{(l)}$:表示第l-1层第j个输入到第l层第i个神经元的权重；</li></ul><p>前馈神经网络通过下面的公式进行信息传播：<br>$$<br>z^{(l)} = W^{(l)}\cdot a^{(l-1)} + b^{(l)} \\\\<br>a^{(l)} = f_l(z^{(l)})<br>$$<br>上面的公式可以合并为：$$<br>z^{(l)} = W^{(l)}\cdot f_{l-1}(z^{(l-1)}) + b^{(l)}<br>$$</p><p>这样，前馈神经网络可以通过逐层的信息传递，得到网络最后的输出$a^{(L)}$。整个网络可以看作一个复合函数$\phi(x;W,b)$,将输入x作为第1层的输入$a^{(0)}$，将第L层的输出作为$a^{(L)}$作为输出。<br>$$x=a^{(0)}\rightarrow z^{(l)} \rightarrow a^{(1)}\rightarrow z^{(2)}\rightarrow … \rightarrow a^{(L-1)} \rightarrow z^{(L)} \rightarrow a^{(L-1)}=\phi(x;W,b)$$</p><h2 id="反向传播推导"><a href="#反向传播推导" class="headerlink" title="反向传播推导"></a>反向传播推导</h2><p>假设损失函数是$L(y,\hat{y})$，对第l层中的参数$W^{(l)}$和$b^{(l)}$计算偏导数。因为$<br>\frac {\partial L(y,\hat{y})}{\partial W^{(l)}}$的计算涉及到矩阵的微分，十分繁琐，可以先计算偏导数$\frac {\partial L(y,\hat{y})}{\partial W_{ij}^{(l)}}$。根据链式法则：$$<br>\frac {\partial L(y,\hat{y})}{\partial W_{ij}^{(l)}} =\left(\frac {\partial z^{(l)}}{\partial W_{ij}^{(l)}}\right)^T\frac {\partial L(y,\hat{y})}{\partial z^{(l)}}   （1）<br>\\\\<br>\frac {\partial L(y,\hat{y})}{\partial b^{(l)}} =\left(\frac {\partial z^{(l)}}{\partial b^{(l)}}\right)^T\frac {\partial L(y,\hat{y})}{\partial z^{(l)}}     (2)<br>$$<br>公式(1)和(2)都是为目标函数关于第l层神经元$z^{(l)}$的偏导数，称为<strong>误差项</strong>，因此可以共用。我们只需要计算三个偏导数，分别为$\frac {\partial z^{(l)}}{\partial W_{ij}^{(l)}},\frac {\partial L(y,\hat{y})}{\partial b^{(l)}}和\frac {\partial L(y,\hat{y})}{\partial z^{(l)}}$</p><p><strong>1、计算偏导数$\frac {\partial z^{(l)} }{\partial W_{ij}^{(l)}}$</strong></p><p>因为$z^{(l)}和W_{ij}^{(l)}$的函数关系为$z^{(l)}=W^{(l)}a^{(l-1)}+b^{(l)}$，因此，偏导数：<br>$$<br>\frac {\partial z^{(l)}}{\partial W_{ij}^{(l)}}=\frac {\partial (W^{(l)}a^{(l-1)}+b^{(l)})}{\partial W_{ij}^{(l)}}= a_j^{(l-1)}<br>$$<br>其中，$W_{i:}^{(l)}$为权重矩阵$W^{(l)}$的第i行</p><p><strong>2、计算偏导数</strong>$\frac {\partial z^{l}}{\partial b^{(l)}}$</p><p>因为$z^{(l)}$和$b^{(l)}$的函数关系为$z^{(l)} = W^{(l)}a^{(l-1)}+b^{(l)}$，因此偏导数：<br>$$<br>\frac {\partial z^{l}}{\partial b^{(l)}}=I_{n^l}<br>$$<br>为$n^l\times n^l$的单位矩阵。</p><p><strong>3、计算偏导数</strong>$\frac {\partial L(y,\hat{y})}{\partial z{(l)}}$</p><p>用$\delta^{(l)}$来定义第l层的神经元误差项：<br>$$<br>\delta^{(l)} = \frac {\partial L(y,\hat{y})}{\partial z^{(l)}} \in R^{n^l}<br>$$<br>误差项$\delta^{l}$表示第l层的神经元对最终的误差的影响，也反映了最终的输出对第l层的神经元对最终误差的敏感程度。</p><p>根据$z^{(l+1)}=W^{(l+1)}a^{(l)} + b^{(l+1)}$，有：<br>$$<br>\frac {\partial z^{(l+1)}}{\partial a^{(l)}} = (W^{(l+1)})^T<br>$$<br>根据$a^{(l)}=f(z^{(l)})$，其中，$f_l(.)$为按位计算的函数，因此有：<br>$$<br>\frac {\partial a^{(l)}}{\partial z^{(l)}} = \frac {\partial f_l(z^{(l)})}{\partial z^{l}} = diag(f_l^{\prime}(z^{(l)}))<br>$$<br>因此，根据链式法则，第l层的误差项为：<br>$$<br>\delta^{(l)} = \frac {\partial L(y, \hat{y})}{\partial z^{(l)}}\\\\<br>=\frac {\partial a^{(l)}}{\partial z^{(l)}}\cdot\frac{\partial z^{(l+1)}}{\partial a^{(l)}}\cdot \frac {\partial L(y, \hat{y})}{\partial z^{(l+1)}}\\\\=diag(f_l^{\prime}(z^{(l)}))\bigodot ((W^{(l+1)})^T\delta^{(l+1)})  (3)<br>$$<br>其中，$\bigodot$是向量的点积运算，表示每个元素相乘。</p><p>从公式3可以看出，第l层的误差项可以通过第l+1层的误差项计算，这就是反向传播。<strong>反向传播算法的含义是：第l层的一个神经元的误差项是所有与该神经元相连的第l+1层神经元误差项的权重和，然后再乘上该神经元激活函数的梯度。</strong></p><p>在计算出三个偏导数之后，可以得到最终的偏导数：<br>$$<br>\frac {\partial L(y,\hat{y})}{\partial W_{ij}^{(l)}} = \delta_i^{(l)}a_j^{(l-1)}<br>$$<br>进一步，$L(y,\hat{y})$关于第l层的权重$W^{(l)}$的梯度为：<br>$$<br>\frac {\partial L(y,\hat{y})}{\partial W^{(l)}} = \delta^{(l)}a^{(l-1)}<br>$$<br>同理可得，$L(y,\hat{y})$关于第l层偏置$b^(l)$的梯度为：<br>$$<br>\frac {\partial L(y,\hat{y})}{\partial b^{(l)}} = \delta^{(l)}<br>$$<br>基于随机梯度下降的反向传播算法如下：</p><p><div><br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/171216/Dg5jm8Hjg0.jpg?imageslim" alt="mark"><br></div><br>图片引自：<a href="https://github.com/nndl/nndl.github.io，chap-前馈神经网络.pdf。" target="_blank" rel="external">https://github.com/nndl/nndl.github.io，chap-前馈神经网络.pdf。</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前馈神经网络前向传播&quot;&gt;&lt;a href=&quot;#前馈神经网络前向传播&quot; class=&quot;headerlink&quot; title=&quot;前馈神经网络前向传播&quot;&gt;&lt;/a&gt;前馈神经网络前向传播&lt;/h2&gt;
    
    </summary>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>CNN学习的相关资料</title>
    <link href="https://ilewseu.github.io/2017/12/17/CNN%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%9B%B8%E5%85%B3%E5%8D%9A%E5%AE%A2/"/>
    <id>https://ilewseu.github.io/2017/12/17/CNN学习的相关博客/</id>
    <published>2017-12-17T11:48:20.000Z</published>
    <updated>2017-12-17T06:27:08.258Z</updated>
    
    <content type="html"><![CDATA[<h2 id="对卷积的理解"><a href="#对卷积的理解" class="headerlink" title="对卷积的理解"></a>对卷积的理解</h2><ul><li><a href="http://mengqi92.github.io/2015/10/06/convolution/" target="_blank" rel="external">http://mengqi92.github.io/2015/10/06/convolution/</a></li><li><a href="http://www.cnblogs.com/freeblues/p/5738987.html" target="_blank" rel="external">http://www.cnblogs.com/freeblues/p/5738987.html</a></li><li><a href="http://blog.csdn.net/bitcarmanlee/article/details/54729807" target="_blank" rel="external">http://blog.csdn.net/bitcarmanlee/article/details/54729807</a><a id="more"></a></li></ul><h2 id="卷积神经网络的原理及推导"><a href="#卷积神经网络的原理及推导" class="headerlink" title="卷积神经网络的原理及推导"></a>卷积神经网络的原理及推导</h2><ul><li>反向传播的推导：<a href="https://zhuanlan.zhihu.com/p/22473137" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/22473137</a></li><li>pinard:<a href="http://www.cnblogs.com/pinard/p/6483207.html" target="_blank" rel="external">http://www.cnblogs.com/pinard/p/6483207.html</a></li><li>zybuluo:<a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="external">https://www.zybuluo.com/hanbingtao/note/485480</a></li><li>一文读懂卷积神经网络CNN：<a href="http://www.sohu.com/a/126742834_473283" target="_blank" rel="external">http://www.sohu.com/a/126742834_473283</a></li><li>CS231N翻译：<a href="https://zhuanlan.zhihu.com/p/21930884" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/21930884</a></li><li>charlote:<a href="http://www.cnblogs.com/charlotte77/p/7759802.html" target="_blank" rel="external">http://www.cnblogs.com/charlotte77/p/7759802.html</a></li><li>卷积神经网络全面解析:<a href="http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi" target="_blank" rel="external">http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi</a></li><li>tornadomeet:<a href="http://www.cnblogs.com/tornadomeet/p/3468450.html" target="_blank" rel="external">http://www.cnblogs.com/tornadomeet/p/3468450.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;对卷积的理解&quot;&gt;&lt;a href=&quot;#对卷积的理解&quot; class=&quot;headerlink&quot; title=&quot;对卷积的理解&quot;&gt;&lt;/a&gt;对卷积的理解&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://mengqi92.github.io/2015/10/06/convolution/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://mengqi92.github.io/2015/10/06/convolution/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/freeblues/p/5738987.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.cnblogs.com/freeblues/p/5738987.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/bitcarmanlee/article/details/54729807&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/bitcarmanlee/article/details/54729807&lt;/a&gt;
    
    </summary>
    
      <category term="记录" scheme="https://ilewseu.github.io/categories/%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="CNN" scheme="https://ilewseu.github.io/tags/CNN/"/>
    
      <category term="资料" scheme="https://ilewseu.github.io/tags/%E8%B5%84%E6%96%99/"/>
    
  </entry>
  
  <entry>
    <title>CS231n课程笔记(9)  ConvNet notes</title>
    <link href="https://ilewseu.github.io/2017/12/16/CS231n%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E7%AC%AC9%E8%AF%BE-ConvNet-notes/"/>
    <id>https://ilewseu.github.io/2017/12/16/CS231n课程笔记-第9课-ConvNet-notes/</id>
    <published>2017-12-16T14:17:23.000Z</published>
    <updated>2017-12-16T16:53:04.888Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转载自：<a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit，原文为：http://cs231n.github.io/convolutional-networks/，并进行一定的修改。" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit，原文为：http://cs231n.github.io/convolutional-networks/，并进行一定的修改。</a></p></blockquote><p><strong>目录</strong><br><a id="more"></a></p><ul><li>结构概述</li><li>用来构建卷积神经网络的各种层<ul><li>卷积层</li><li>汇聚层</li><li>归一化层</li><li>全连接层</li><li>将全连接层转化成卷积层</li></ul></li><li>卷积神经网络的结构<ul><li>层的排列规律</li><li>层的尺寸设置规律</li><li>案例学习（LeNet/AlexNet/ZFNet/GoogLeNet/VGGNet）</li><li>计算上的考量</li></ul></li><li>拓展资源</li></ul><h2 id="卷积神经网络-CNNs-ConvNets"><a href="#卷积神经网络-CNNs-ConvNets" class="headerlink" title="卷积神经网络(CNNs/ConvNets)"></a>卷积神经网络(CNNs/ConvNets)</h2><p>卷积神经网络和上一章讲的常规神经网络非常相似：它们都是由神经元组成，神经元中有局域学习能力的权重和偏差。每个神经元都得到一些输入数据，进行内积运算后再进行激活函数运算。整个网络依旧是一个可导的评分函数：该函数的输入是原始的图像像素，输出的是不同类别的评分。在最后一层（往往是全连接层），网络依旧有一个损失函数（比如SVM或者softmax）,并且在神经网络中我们的各种技巧和要点依旧适用于卷积神经网络。</p><p>那么有哪些地方变化了呢？卷积神经网络的结构基于一个假设，即输入数据是图像，基于该假设，我们就向结构中添加了一些特有的性质。这些特有属性使得前向传播函数实现起来更高效，并且大幅度降低了网络中参数的数量。</p><h2 id="结构概述"><a href="#结构概述" class="headerlink" title="结构概述"></a>结构概述</h2><p>回顾：常规神经网络。在上一章中，神经网络的输入是一个向量，然后在一些列的隐层中对它做变换。每个隐层是由若干的神经元组成，每个神经元都与前一层中的所有神经元连接。但是在一个隐藏层中，神经元相互独立不进行任何连接。最后的全连接层被称为“输出层”，在分类问题中，它输出的值被看做是不同类别的评分值。</p><p>常规神经网络对于大尺寸图像效果不尽人意。在CIFAR-10中，图像的尺寸是32x32x3（宽高均为32像素，3个颜色通道），因此，对应的的常规神经网络的第一个隐层中，每一个单独的全连接神经元就有32x32x3=3072个权重。这个数量看起来还可以接受，但是很显然这个全连接的结构不适用于更大尺寸的图像。举例说来，一个尺寸为200x200x3的图像，会让神经元包含200x200x3=120,000个权重值。而网络中肯定不止一个神经元，那么参数的量就会快速增加！显而易见，这种全连接方式效率低下，大量的参数也很快会导致网络过拟合。</p><p><strong>神经元的三维排列</strong>。卷积神经网络针对输入全部是图像的情况，将结构调整得更加合理，获得了不小的优势。与常规神经网络不同，卷积神经网络的各层中的神经元是3维排列的：<strong>宽度、高度和深度</strong>（这里的<strong>深度</strong>指的是激活数据体的第三个维度，而不是整个网络的深度，整个网络的深度指的是网络的层数）。举个例子，CIFAR-10中的图像是作为卷积神经网络的输入，该数据体的维度是32x32x3（宽度，高度和深度）。我们将看到，层中的神经元将只与前一层中的一小块区域连接，而不是采取全连接方式。对于用来分类CIFAR-10中的图像的卷积网络，其最后的输出层的维度是1x1x10，因为在卷积神经网络结构的最后部分将会把全尺寸的图像压缩为包含分类评分的一个向量，向量是在深度方向排列的。下面是例子：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171216/aBcKm9G2Lf.jpg?imageslim" alt="mark"><br></div>左边是一个3层的神经网络。右边是一个卷积神经网络，图例中网络将它的神经元都排列成3个维度（宽、高和深度）。卷积神经网络的每一层都将3D的输入数据变化为神经元3D的激活数据并输出。在这个例子中，红色的输入层装的是图像，所以它的宽度和高度就是图像的宽度和高度，它的深度是3（代表了红、绿、蓝3种颜色通道）。<br><div></div><h2 id="用来构建卷积神经网络的各种层"><a href="#用来构建卷积神经网络的各种层" class="headerlink" title="用来构建卷积神经网络的各种层"></a>用来构建卷积神经网络的各种层</h2><p>一个简单的卷积神经网是由各种层按照顺序排列组成，网络中的每个层使用一个可以微分的函数将激活数据从一个层传递到另一个层。卷积神经网络主要由三种类型的层构成：卷积层、汇聚层和全连接层（全连接层和常规的神经网络中的一样）。通过将这些层叠加起来，就可以构建一个完整的卷积神经网络。</p><p>网络结构的例子：这仅仅是一个概述，下面会有更详细的介绍。一个用于CIFAP-10图像数据分类的卷积神经网络的结构可以是[输入层-卷积层-ReLU层-汇聚层-全连接层]。细节如下：</p><ul><li>输入[32*3]存有图像的原始像素值，本例中，图像宽高均为32，有3个颜色通道。</li><li>卷积层中，神经元与输入层中的一个局部区域相连，每个神经元都计算自己与输入层相连的小区域与自己权重的内积。卷积层会计算所有的神经元的输出。如果我们使用12个滤波器（也叫核），得到的输出数据体的维度就是[32<em>32</em>12]。</li><li>ReLU层将会逐个元素地进行激活函数操作，比如使用以0为阈值的max(0,x)作为激活函数。该层对数据尺寸没有改变，还是[32x32x12]。</li><li>汇聚层在在空间维度（宽度和高度）上进行降采样（downsampling）操作，数据尺寸变为[16x16x12]。</li><li>全连接层将会计算分类评分，数据尺寸变为[1x1x10]，其中10个数字对应的就是CIFAR-10中10个类别的分类评分值。正如其名，全连接层与常规神经网络一样，其中每个神经元都与前一层中所有神经元相连接。</li></ul><p>由此看来，卷积神经网络一层一层地将图像从原始像素值变换成最终的分类评分值。其中有的层含有参数，有的没有。具体说来，卷积层和全连接层（CONV/FC）对输入执行变换操作的时候，不仅会用到激活函数，还会用到很多参数（神经元的突触权值和偏差）。而ReLU层和汇聚层则是进行一个固定不变的函数操作。卷积层和全连接层中的参数会随着梯度下降被训练，这样卷积神经网络计算出的分类评分就能和训练集中的每个图像的标签吻合了。</p><p><strong>小结</strong></p><ul><li>简单案例中卷积神经网络的结构，就是一系列的层将输入数据变换为输出数据（比如分类评分）。</li><li>卷积神经网络结构中有几种不同类型的层（目前最流行的有卷积层、全连接层、ReLU层和汇聚层）。</li><li>每个层的输入是3D数据，然后使用一个可导的函数将其变换为3D的输出数据。</li><li>有的层有参数，有的没有（卷积层和全连接层有，ReLU层和汇聚层没有）。</li><li>有的层有额外的参数，有的没有（卷积层、全连接层和汇聚层有，ReLU层没有）。</li></ul><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层是构建卷积神经网络的核心层，它产生了网络中的大部分的计算量。</p><p><strong>概述和直观介绍</strong>：首先讨论的是，在没有大脑和生物意义上的神经元之类的比喻下，卷积层到底在计算什么。<strong>卷积层的参数是有一些可学习的滤波器集合构成的。</strong>每个滤波器在空间上（宽度和高度）都比较小，但是深度和输入数据一致。举例来说，卷积神经网络第一层的一个典型的滤波器的尺寸可以是5x5x3（宽高都是5像素，深度是3是因为图像应为颜色通道，所以有3的深度）。在前向传播的时候，让每个滤波器都在输入数据的宽度和高度上滑动（更精确地说是卷积），然后计算整个滤波器和输入数据任一处的内积。当滤波器沿着输入数据的宽度和高度滑过后，会生成一个2维的激活图（activation map），激活图给出了在每个空间位置处滤波器的反应。<strong>直观地来说，网络会让滤波器学习到当它看到某些类型的视觉特征时就激活，具体的视觉特征可能是某些方位上的边界，或者在第一层上某些颜色的斑点，甚至可以是网络更高层上的蜂巢状或者车轮状图案。</strong></p><p>在每个卷积层上，我们会有一整个集合的滤波器（比如12个），每个都会生成一个不同的二维激活图。将这些激活映射在深度方向上层叠起来就生成了输出数据。</p><p><strong>以大脑做比喻</strong>：如果你喜欢用大脑和生物神经元来做比喻，那么输出的3D数据中的每个数据项可以被看做是神经元的一个输出，而该神经元只观察输入数据中的一小部分，并且和空间上左右两边的所有神经元共享参数（因为这些数字都是使用同一个滤波器得到的结果）。现在开始讨论神经元的连接，它们在空间中的排列，以及它们参数共享的模式。</p><p><strong>局部连接</strong>：在处理图像这样的高维度输入时，让每个神经元都与前一层中的所有神经元进行全连接是不现实的。相反，我们让每个神经元只与输入数据的一个局部区域连接。该连接的空间大小叫做神经元的感受野（receptive field），它的尺寸是一个超参数（其实就是滤波器的空间尺寸）。在深度方向上，这个连接的大小总是和输入量的深度相等。需要再次强调的是，我们对待空间维度（宽和高）与深度维度是不同的：连接在空间（宽高）上是局部的，但是在深度上总是和输入数据的深度一致。</p><p>例1：假设输入的数据体尺寸为<a href="比如CIFAR-10的RGB图像">32x32x3</a>，如果滤波器是5x5，那么卷积层中的每个神经元有输入数据体中[5x5x3]区域的权重，共5x5x3=75个权重（还要加一个偏差参数）。注意这个连接在深度维度上的大小必须为3，和输入数据体的深度一致。</p><p>例2：假设输入数据体的尺寸是[16x16x20]，感受野尺寸是3x3，那么卷积层中每个神经元和输入数据体就有3x3x20=180个连接。再次提示：在空间上连接是局部的（3x3），但是在深度上是和输入数据体一致的（20）。</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171216/F4hfh6IIBE.jpg?imageslim" alt="mark"><br></div><br><strong>左边</strong>：红色的是输入数据体（比如CIFAR-10中的图像），蓝色的部分是第一个卷积层中的神经元。卷积层中的每个神经元都只是与输入数据体的一个局部在空间上相连，但是与输入数据体的所有深度维度全部相连（所有颜色通道）。在深度方向上有多个神经元（本例中5个），它们都接受输入数据的同一块区域（感受野相同）。至于深度列的讨论在下文中有。<br><br><strong>右边</strong>：神经网络章节中介绍的神经元保持不变，它们还是计算权重和输入的内积，然后进行激活函数运算，只是它们的连接被限制在一个局部空间。<br><br><strong>空间排列</strong>：上文讲解了卷积层中每个神经元与输入数据体之间的连接方式，但是尚未讨论输出数据体中神经元的数量，以及他们的排列方式。3个超参数控制着输出数据体的尺寸：深度(depth)、步长(stride)和零填充(zero-padding)。下面是对它们的讨论：<br><br>1. 首先，输出数据体的深度是一个超参数：它和使用的滤波器的数量一致，而每个滤波器在输入数据中寻找一些不同的东西。举例来说，如果第一个卷积层的输入是原始图像，那么在深度维度上的不同神经元将可能被不同方向的边界、或者是颜色斑点激活。我们将这些沿着深度方向排列、感受野相同的神经元集合称为<strong>深度列</strong>，也有人使用纤维(fibre)来称呼它们。<br>2. 其次，在滑动滤波器的时候，必须指定步长。当步长为1，滤波器每次移动1个像素。当步长为2（或者不常用的3，或者更多，这些在实际中很少使用），滤波器滑动时每次移动2个像素。这个操作会让输出数据体在空间上变小。<br>3. 在下文可以看到，有时候将输入数据体用0在边缘处进行填充是很方便的。这个零填充（zero-padding）的尺寸是一个超参数。零填充有一个良好性质，即可以控制输出数据体的空间尺寸（最常用的是用来保持输入数据体在空间上的尺寸，这样输入和输出的宽高都相等）。<br><br>输出数据体在空间上的尺寸可以通过输入数据体尺寸(W)，卷积层中神经元的感受野尺寸(F)、步长(S)和零填充的数量(P)的函数来计算（假设输入数组的空间形状是正方形，即高度和宽度相等）输出数据体的空间尺寸为(W-F+2P)/S+1。比如输入是7x7，滤波器是3x3，步长为1，填充为0，那么就能得到一个5x5的输出。如果步长为2，输出就是3x3。下面是例子：<br><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171216/6fKc6kceA4.jpg?imageslim" alt="mark"><br></div><br>空间排列的图示。在本例中只有一个空间维度（x轴），神经元的感受野尺寸F=3，输入尺寸W=5，零填充P=1。左边：神经元使用的步长S=1，所以输出尺寸是(5-3+2)/1+1=5。右边：神经元的步长S=2，则输出尺寸是(5-3+2)/2+1=3。注意当步长S=3时是无法使用的，因为它无法整齐地穿过数据体。从等式上来说，因为(5-3+2)=4是不能被3整除的。<br><br>本例中，神经元的权重是[1,0,-1]，显示在图的右上角，偏差值为0。这些权重是被所有黄色的神经元共享的（参数共享的内容看下文相关内容）。<br><br><strong>使用零值填充</strong>：在上面的左边的例子中，注意输入维度是5，输出维度也是5。之所以如此，是因为感受野是3并且使用了1的零填充。如果不使用零填充，则输出数据体的空间维度就只有3，因为这就是滤波器整齐滑过并覆盖原始数据需要的数目。一般来说，当步长S=1时，零填充的值是P=（F-1）/2，这样就能保证输入和输出数据体有相同的空间尺寸。这样做非常常见，在介绍卷积神经网络的结构的时候我们会详细讨论其原因。<br><br><strong>步长的限制</strong>：注意这些空间排列的超参数之间是相互限制的。举例说来，当输入尺寸W=10，不使用零填充则P=0，滤波器尺寸F=3，这样步长S=2就行不通，因为(W-F+2P)/S+1=(10-3+0)/2+1=4.5，结果不是整数，这就是说神经元不能整齐对称地滑过输入数据体。因此，这些超参数的设定就被认为是无效的，一个卷积神经网络库可能会报出一个错误，或者修改零填充值来让设置合理，或者修改输入数据体尺寸来让设置合理，或者其他什么措施。在后面的卷积神经网络结构小节中，读者可以看到合理地设置网络的尺寸让所有的维度都能正常工作，这件事可是相当让人头痛的。而使用零填充和遵守其他一些设计策略将会有效解决这个问题。<br><br>真实案例：Krizhevsky构架赢得了2012年的ImageNet挑战，其输入图像的尺寸是[227x227x3]。在第一个卷积层，神经元使用的感受野尺寸F=11，步长S=4，不使用零填充P=0。因为(227-11)/4+1=55，卷积层的深度K=96，则卷积层的输出数据体尺寸为[55x55x96]。55x55x96个神经元中，每个都和输入数据体中一个尺寸为[11x11x3]的区域全连接。在深度列上的96个神经元都是与输入数据体中同一个[11x11x3]区域连接，但是权重不同。有一个有趣的细节，在原论文中，说的输入图像尺寸是224x224，这是肯定错误的，因为(224-11)/4+1的结果不是整数。这件事在卷积神经网络的历史上让很多人迷惑，而这个错误到底是怎么发生的没人知道。我的猜测是Alex忘记在论文中指出自己使用了尺寸为3的额外的零填充。<br><br><strong>参数共享</strong>=290,400个神经元，每个有11x11x3=364个参数和1个偏差。将这些合起来就是290400x364：在卷积层中使用参数共享是用来控制参数的数量。就用上面的例子，在第一个卷积层就有55x55x96=105,705,600个参数。单单第一层就有这么多参数，显然这个数目是非常大的。<br>作一个合理的假设：如果一个特征在计算某个空间位置(x,y)的时候有用，那么它在计算另一个不同位置(x2,y2)的时候也有用。基于这个假设，可以显著地减少参数数量。换言之，就是将深度维度上一个单独的2维切片看做深度切片（depth slice），比如一个数据体尺寸为[55x55x96]的就有96个深度切片，每个尺寸为[55x55]。在每个深度切片上的神经元都使用同样的权重和偏差。在这样的参数共享下，例子中的第一个卷积层就只有96个不同的权重集了，一个权重集对应一个深度切片，共有96x11x11x3=34,848个不同的权重，或34,944个参数（+96个偏差）。在每个深度切片中的55x55个权重使用的都是同样的参数。在反向传播的时候，都要计算每个神经元对它的权重的梯度，但是需要把同一个深度切片上的所有神经元对权重的梯度累加，这样就得到了对共享权重的梯度。这样，每个切片只更新一个权重集。<br><br>注意，如果在一个深度切片中的所有权重都使用同一个权重向量，那么卷积层的前向传播在每个深度切片中可以看做是在计算神经元权重和输入数据体的卷积（这就是“卷积层”名字由来）。这也是为什么总是将这些权重集合称为滤波器（filter）（或卷积核（kernel）），因为它们和输入进行了卷积。<br><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171216/3mG935H4Ie.jpg?imageslim" alt="mark"><br></div><br>Krizhevsky等学习到的滤波器例子。这96个滤波器尺寸都是[11x11x3]，在一个深度切片中，每个滤波器都被55x55个神经元共享。注意参数共享的假设是有道理的：如果在图像某些地方探测到一个水平的边界是很重要的，那么在其他一些地方也同样是有用的，这是因为图像结构具有平移不变性。所以，在卷积层的输出数据体的55x55个不同位置中，就没有必要重新学习探测一个水平边界了。<br><br>注意有时候参数共享假设可能没有意义，特别是当卷积神经网络的输入图像是一些明确的中心结构时候。这时候我们就应该期望在图片的不同位置学习到完全不同的特征。一个具体的例子就是输入图像是人脸，人脸一般都处于图片中心。你可能期望不同的特征，比如眼睛特征或者头发特征可能（也应该）会在图片的不同位置被学习。在这个例子中，通常就放松参数共享的限制，将层称为<strong>局部连接层（Locally-Connected Layer）</strong>。<br><br>Numpy的例子：为了让讨论更加的具体，我们用代码来展示上述思路。假设输入数据体是numpy数组X。那么：一个位于(x,y)的深度列，将会是X[x,y,:]；在深度为d处的切片，或激活图应该是X[:,:,d]。<br>卷积层例子：假设输入数据体的尺寸X.shape:(11,11,4)，不使用零填充（P=0），滤波器的尺寸是F=5，步长S=2。那么输出数据体的空间尺寸就是(11-5)/2+1=4，即输出数据体的宽度和高度都是4。那么在输出数据体中的激活映射（称其为V）看起来就是下面这样（在这个例子中，只有部分元素被计算）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0</div><div class="line">V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0</div><div class="line">V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0</div><div class="line">V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0</div></pre></td></tr></table></figure><br><br>在numpy中，<em>操作是进行数组间的逐元素相乘。权重向量W0是该神经元的权重，b0是其偏差。在这里，W0被假设尺寸是W0.shape: (5,5,4)，因为滤波器的宽高是5，输入数据量的深度是4。注意在每一个点，计算点积的方式和之前的常规神经网络是一样的。同时，计算内积的时候使用的是同一个权重和偏差（因为参数共享），在宽度方向的数字每次上升2（因为步长为2）。要构建输出数据体中的第二张激活图，代码应该是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1</div><div class="line">V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1</div><div class="line">V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1</div><div class="line">V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1</div><div class="line">V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 （在y方向上）</div><div class="line">V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 （或两个方向上同时）</div></pre></td></tr></table></figure><br><br>我们访问的是V的深度维度上的第二层（即index1），因为是在计算第二个激活图，所以这次试用的参数集就是W1了。在上面的例子中，为了简洁略去了卷积层对于输出数组V中其他部分的操作。还有，要记得这些卷积操作通常后面接的是ReLU层，对激活图中的每个元素做激活函数运算，这里没有显示。<br><br><strong>小结</strong><br><br>- 输入数据体的尺寸为：$W_1xH_1xD_1$<br>- 4个超参数:滤波器的数量K;滤波器的空间尺寸F;步长S;零填充数量P<br>- 输出数据的尺寸为：$W_2xH_2xD_2$，其中：<br>    - $W_2 = (W_1 - F + 2P)/S+1$;<br>    - $H_2 = (H_1 - F + 2P)/S+1$(宽度和高度的计算方法相同);<br>    - $D_2=K$<br>-  由于参数共享，每个滤波器包含$F\cdot F\cdot D_1$个权重，卷积层一共有$F\cdot F\cdot D_1\cdot K$个权重和K个偏置。<br>-  在输出数据体中，第d个深度的切片(空间尺寸是$W_2xH_2$)，用第d个滤波器和输入数据进行有效卷积运算的结果（使用步长S），最后在加上第d个偏差。<br>对这些超参数，常见的设置是F=2，S=1，P=1。同时设置这些超参数也有一些约定俗成的惯例和经验，可以在下面的卷积神经网络结构章节中查看。<br><br><em>*卷积层演示</em></em>：下面是一个卷积层的运行演示。因为3D数据难以可视化，所以所有的数据（输入数据体是蓝色，权重数据体是红色，输出数据体是绿色）都采取将深度切片按照列的方式排列展现。输入数据体的尺寸是$W_1=5,H_1=5,D_1=3$，卷积层参数K=2,F=3,S=2,P=1。就是说，有2个滤波器，滤波器的尺寸是$3\cdot 3$，它们的步长是2.因此，输出数据体的空间尺寸是(5-3+2)/2+1=3。注意输入数据体使用了零填充P=1，所以输入数据体外边缘一圈都是0。下面的例子在绿色的输出激活数据上循环演示，展示了其中每个元素都是先通过蓝色的输入数据和红色的滤波器逐元素相乘，然后求其总和，最后加上偏差得来。<br><div><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171216/jmKmGIi9Ja.jpg?imageslim" alt="mark"><br></div><p><strong>矩阵乘法实现</strong>：卷积运算本质上就是在滤波器和输入数据的局部区域间做点积。卷积层的常用实现方式就是利用这一点，将卷积层的前向传播变成一个巨大的矩阵乘法：</p><ol><li>输入图像的局部区域被im2col操作拉伸为列。比如，如果输入是[227x227x3]，要与尺寸为11x11x3的滤波器以步长为4进行卷积，就取输入中的[11x11x3]数据块，然后将其拉伸为长度为11x11x3=363的列向量。重复进行这一过程，因为步长为4，所以输出的宽高为(227-11)/4+1=55，所以得到im2col操作的输出矩阵X_col的尺寸是[363x3025]，其中每列是拉伸的感受野，共有55x55=3,025个。注意因为感受野之间有重叠，所以输入数据体中的数字在不同的列中可能有重复。</li><li>卷积层的权重也同样被拉伸成行。举例，如果有96个尺寸为[11x11x3]的滤波器，就生成一个矩阵W_row，尺寸为[96x363]。</li><li>现在卷积的结果和进行一个大矩阵乘np.dot(W_row, X_col)是等价的了，能得到每个滤波器和每个感受野间的点积。在我们的例子中，这个操作的输出是[96x3025]，给出了每个滤波器在每个位置的点积输出。</li><li>结果最后必须被重新变为合理的输出尺寸[55x55x96]。</li></ol><p>这个方法的缺点就是占用内存太多，因为在输入数据体中的某些值在X_col中被复制了多次。但是，其优点是矩阵乘法有非常多的高效实现方式，我们都可以使用（比如常用的BLAS API）。还有，同样的im2col思路可以用在汇聚操作中。<br><strong>反向传播</strong>：卷积操作的反向传播（同时对于数据和权重）还是一个卷积（但是是和空间上翻转的滤波器）。使用一个1维的例子比较容易演示。</p><p><strong>1x1卷积</strong>：一些论文中使用了1x1的卷积，这个方法最早是在论文Network in Network中出现。人们刚开始看见这个1x1卷积的时候比较困惑，尤其是那些具有信号处理专业背景的人。因为信号是2维的，所以1x1卷积就没有意义。但是，在卷积神经网络中不是这样，因为这里是对3个维度进行操作，滤波器和输入数据体的深度是一样的。比如，如果输入是[32x32x3]，那么1x1卷积就是在高效地进行3维点积（因为输入深度是3个通道）。</p><p><strong>扩张卷积：</strong>最近一个研究（Fisher Yu和Vladlen Koltun的论文）给卷积层引入了一个新的叫扩张（dilation）的超参数。到目前为止，我们只讨论了卷积层滤波器是连续的情况。但是，让滤波器中元素之间有间隙也是可以的，这就叫做扩张。举例，在某个维度上滤波器w的尺寸是3，那么计算输入x的方式是：w[0]<em>x[0] + w[1]</em>x[1] + w[2]<em>x[2]，此时扩张为0。如果扩张为1，那么计算为： w[0]</em>x[0] + w[1]<em>x[2] + w[2]</em>x[4]。换句话说，操作中存在1的间隙。在某些设置中，扩张卷积与正常卷积结合起来非常有用，因为在很少的层数内更快地汇集输入图片的大尺度特征。比如，如果上下重叠2个3x3的卷积层，那么第二个卷积层的神经元的感受野是输入数据体中5x5的区域（可以成这些神经元的有效感受野是5x5）。如果我们对卷积进行扩张，那么这个有效感受野就会迅速增长。</p><h3 id="汇聚层"><a href="#汇聚层" class="headerlink" title="汇聚层"></a>汇聚层</h3><p>通常，在连续的卷积层之间会周期性地插入一个汇聚层。**它的作用是逐渐降低数据体的空间尺寸，这样的话就能减少网络中参数的数量，使得计算资源耗费变少，也能有效控制过拟合。汇聚层使用MAX操作，对输入数据体的每一个深度切片独立进行操作，改变它的空间尺寸。最常见的形式是汇聚层使用尺寸2x2的滤波器，以步长为2来对每个深度切片进行降采样，将其中75%的激活信息都丢掉。每个MAX操作是从4个数字中取最大值（也就是在深度切片中某个2x2的区域）。深度保持不变。汇聚层的一些公式：</p><ul><li>输入数据体尺寸$W_1\cdot H_1\cdot D_1$</li><li>有两个超参数：<ul><li>空间大小F</li><li>步长S</li></ul></li><li>输出数据体尺寸$W_2\cdot H_2\cdot D_2$，其中<ul><li>$W_2=(W_1-F)/S+1$</li><li>$H_2=(H_1-F)/S+1$</li><li>$D_2=D_1$</li></ul></li><li>因为对输入进行的是固定函数计算，所以没有引入参数。</li><li>在汇聚层中很少使用零填充。</li></ul><p>在实践中，最大汇聚层通常只有两种形式：一种是F=3,S=2，也叫重叠汇聚（overlapping pooling），另一个更常用的是F=2,S=2。对更大感受野进行汇聚需要的汇聚尺寸也更大，而且往往对网络有破坏性。</p><p><strong>普通汇聚（General Pooling）</strong>：除了最大汇聚，汇聚单元还可以使用其他的函数，比如平均汇聚（average pooling）或L-2范式汇聚（L2-norm pooling）。平均汇聚历史上比较常用，但是现在已经很少使用了。因为实践证明，最大汇聚的效果比平均汇聚要好。</p><p><div><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171216/6Ca9idlJK8.jpg?imageslim" alt="mark"><br></div><br>汇聚层在输入数据体的每个深度切片上，独立地对其进行空间上的降采样。左边：本例中，输入数据体尺寸[224x224x64]被降采样到了[112x112x64]，采取的滤波器尺寸是2，步长为2，而深度不变。右边：最常用的降采样操作是取最大值，也就是最大汇聚，这里步长为2，每个取最大值操作是从4个数字中选取（即2x2的方块区域中）。</p><p><strong>反向传播</strong>：回顾一下反向传播的内容，其中max(x,y)函数的反向传播可以简单理解为将梯度只沿着最大的数回传。因此，在向前传播经过汇聚层的时候，通常会把池中最大的索引记录下来，这样在反向传播的时候梯度的路由就很高效。</p><p><strong>不使用汇聚层</strong>：很多人不喜欢汇聚操作，认为可以不使用它。比如在Striving for Simplicity: The All Convolutional Net一文中，提出使用一种只有重复的卷积层组成的结构，抛弃汇聚层。通过在卷积层中使用更大的步长来降低数据体的尺寸。有发现认为，在训练一个良好的生成模型时，弃用汇聚层也是很重要的。比如变化自编码器（VAEs：variational autoencoders）和生成性对抗网络（GANs：generative adversarial networks）。现在看起来，未来的卷积网络结构中，可能会很少使用甚至不使用汇聚层。</p><h3 id="归一化层"><a href="#归一化层" class="headerlink" title="归一化层"></a>归一化层</h3><p>在卷积神经网络中的结果，提出很多不同类型的归一化层，有时候是为了实现生物大脑中观测到的抑制机制。但是，这些层渐渐都不再流行，因为实践证明它们的效果即使存在，也是极有限的。对于不同类型的归一化层，可以看看Alex Krizhevsky的关于cuda-convnet library API的讨论。</p><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>在全连接层中，神经元对于前一层中的所有激活数据是全部连接的，这个常规神经网络中一样。它们的激活可以先用矩阵乘法，再加上偏差。更多细节请查看神经网络章节。</p><h3 id="把全连接层转化层卷积层"><a href="#把全连接层转化层卷积层" class="headerlink" title="把全连接层转化层卷积层"></a>把全连接层转化层卷积层</h3><p>全连接层和卷积层之间唯一的不同就是卷积层中的神经元只与输入数据中的一个局部区域连接，并且在卷积列中的神经元共享参数。然而在两类层中，神经元都是计算点积，所有它们的函数形式是一样的。因此，将此两者相互转化是可能的：</p><ul><li>对于任一个卷积层，都存在一个能实现和它一样的前向传播函数的全连接层。权重矩阵是一个巨大的矩阵，除了某些特定块（这是因为有局部连接），其余部分都是零。而在其中大部分块中，元素都是相等的（因为参数共享）。</li><li>相反，任何全连接层都可以被转化为卷积层。比如，一个K=4096的全连接层，输入数据体的尺寸是$7\times 7\times 512$，这个全连接层可以被等效地看做一个F=7,P=0,S=1,K=4096的卷积层。换句话说，就是将滤波器的尺寸设置为和输入数据体的尺寸一致了。因为只有一个单独的深度列覆盖并滑过输入数据体，所以输出将变成$1\times 1\times$ 4096，这个结果就和使用初始的那个全连接层一样了。</li></ul><p><strong>全连接层转化为卷积层：</strong>在这两种变换中，将全连接层转化为卷积层在实际运用中更加有用。假设一个卷积神经网络的输入是$224\times224\times3$的图像，一系列的卷积层和汇聚层将图像数据变为尺寸为7x7x512的激活数据体（在AlexNet中就是这样，通过使用5个汇聚层来对输入数据进行空间上的降采样，每次尺寸下降一半，所以最终空间尺寸为224/2/2/2/2/2=7）。从这里可以看到，AlexNet使用了两个尺寸为4096的全连接层，最后一个有1000个神经元的全连接层用于计算分类评分。我们可以将这3个全连接层中的任意一个转化为卷积层：</p><ul><li>针对第一个连接区域是[7x7x512]的全连接层，令其滤波器尺寸为F=7，这样输出数据体就为[1x1x4096]了。</li><li>针对第二个全连接层，令其滤波器尺寸为F=1，这样输出数据体为[1x1x4096]。</li><li>对最后一个全连接层也做类似的，令其F=1，最终输出为[1x1x1000]。</li></ul><p>实际操作中，每次这样的变换都需要把全连接层的权重W重塑成卷积层的滤波器。那么这样的转化有什么作用呢？它在下面的情况下可以更高效：让卷积网络在一张更大的输入图片上滑动（译者注：即把一张更大的图片的不同区域都分别带入到卷积网络，得到每个区域的得分），得到多个输出，这样的转化可以让我们在单个向前传播的过程中完成上述的操作。</p><p>举个例子，如果我们想让224x224尺寸的浮窗，以步长为32在384x384的图片上滑动，把每个经停的位置都带入卷积网络，最后得到6x6个位置的类别得分。上述的把全连接层转换成卷积层的做法会更简便。如果224x224的输入图片经过卷积层和汇聚层之后得到了[7x7x512]的数组，那么，384x384的大图片直接经过同样的卷积层和汇聚层之后会得到[12x12x512]的数组（因为途径5个汇聚层，尺寸变为384/2/2/2/2/2 = 12）。然后再经过上面由3个全连接层转化得到的3个卷积层，最终得到[6x6x1000]的输出（因为(12 - 7)/1 + 1 = 6）。这个结果正是浮窗在原图经停的6x6个位置的得分！</p><blockquote><p>面对384x384的图像，让（含全连接层）的初始卷积神经网络以32像素的步长独立对图像中的224x224块进行多次评价，其效果和使用把全连接层变换为卷积层后的卷积神经网络进行一次前向传播是一样的。</p></blockquote><p>自然，相较于使用被转化前的原始卷积神经网络对所有36个位置进行迭代计算，使用转化后的卷积神经网络进行一次前向传播计算要高效得多，因为36次计算都在共享计算资源。这一技巧在实践中经常使用，一次来获得更好的结果。比如，通常将一张图像尺寸变得更大，然后使用变换后的卷积神经网络来对空间上很多不同位置进行评价得到分类评分，然后在求这些分值的平均值。</p><p>最后，如果我们想用步长小于32的浮窗怎么办？用多次的向前传播就可以解决。比如我们想用步长为16的浮窗。那么先使用原图在转化后的卷积网络执行向前传播，然后分别沿宽度，沿高度，最后同时沿宽度和高度，把原始图片分别平移16个像素，然后把这些平移之后的图分别带入卷积网络。</p><h2 id="卷积神经网络的结构"><a href="#卷积神经网络的结构" class="headerlink" title="卷积神经网络的结构"></a>卷积神经网络的结构</h2><p>卷积神经网络通常是由三种层构成：卷积层，汇聚层（除非特别说明，一般就是最大值汇聚）和全连接层（简称FC）。ReLU激活函数也应该算是是一层，它逐元素地进行激活函数操作。在本节中将讨论在卷积神经网络中这些层通常是如何组合在一起的。</p><h3 id="层的排列规律"><a href="#层的排列规律" class="headerlink" title="层的排列规律"></a>层的排列规律</h3><p>卷积神经网络最常见的形式就是将一些卷积层和ReLU层放在一起，其后紧跟汇聚层，然后重复如此直到图像在空间上被缩小到一个足够小的尺寸，在某个地方过渡成成全连接层也较为常见。最后的全连接层得到输出，比如分类评分等。换句话说，最常见的卷积神经网络结构如下：<br><strong>INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]*M -&gt; [FC -&gt; RELU]*K -&gt; FC</strong><br>其中*指的是重复次数，POOL?指的是一个可选的汇聚层。其中N &gt;=0,通常N&lt;=3,M&gt;=0,K&gt;=0,通常K&lt;3。例如，下面是一些常见的网络结构规律：</p><ul><li>INPUT -&gt; FC,实现一个线性分类器，此处N = M = K = 0。</li><li>INPUT -&gt; CONV -&gt; RELU -&gt; FC</li><li>INPUT -&gt; [CONV -&gt; RELU -&gt; POOL]*2 -&gt; FC -&gt; RELU -&gt; F- C。此处在每个汇聚层之间有一个卷积层。</li><li>INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL]<em>3 -&gt; [FC -&gt; RELU]</em>2 -&gt; FC。此处每个汇聚层前有两个卷积层，这个思路适用于更大更深的网络，因为在执行具有破坏性的汇聚操作前，多重的卷积层可以从输入数据中学习到更多的复杂特征。</li></ul><p><strong>几个小滤波器卷积层的组合比一个大滤波器卷积层好</strong>：假设你一层一层地重叠了3个3x3的卷积层（层与层之间有非线性激活函数）。在这个排列下，第一个卷积层中的每个神经元都对输入数据体有一个3x3的视野。第二个卷积层上的神经元对第一个卷积层有一个3x3的视野，也就是对输入数据体有5x5的视野。同样，在第三个卷积层上的神经元对第二个卷积层有3x3的视野，也就是对输入数据体有7x7的视野。假设不采用这3个3x3的卷积层，二是使用一个单独的有7x7的感受野的卷积层，那么所有神经元的感受野也是7x7，但是就有一些缺点。首先，多个卷积层与非线性的激活层交替的结构，比单一卷积层的结构更能提取出深层的更好的特征。其次，假设所有的数据有C个通道，那么单独的7x7卷积层将会包含C\times (7\times 7\times C)=49C^2个参数，而3个3x3的卷积层的组合仅有3\times (C\times (3\times 3\times C))=27C^2个参数。直观说来，最好选择带有小滤波器的卷积层组合，而不是用一个带有大的滤波器的卷积层。前者可以表达出输入数据中更多个强力特征，使用的参数也更少。唯一的不足是，在进行反向传播时，中间的卷积层可能会导致占用更多的内存。</p><p>最新进展：传统的将层按照线性进行排列的方法已经受到了挑战，挑战来自谷歌的Inception结构和微软亚洲研究院的残差网络（Residual Net）结构。这两个网络（下文案例学习小节中有细节）的特征更加复杂，连接结构也不同。</p><h3 id="层的尺寸设置规律"><a href="#层的尺寸设置规律" class="headerlink" title="层的尺寸设置规律"></a>层的尺寸设置规律</h3><p>到现在为止，我们都没有提及卷积神经网络中每层的超参数的使用。现在先介绍设置结构尺寸的一般性规则，然后根据这些规则进行讨论：<br><strong>输入层</strong><br>（包含图像的）应该能被2整除很多次。常用数字包括32（比如CIFAR-10），64，96（比如STL-10）或224（比如ImageNet卷积神经网络），384和512。</p><p><strong>卷积层</strong><br>应该使用小尺寸滤波器（比如3x3或最多5x5），使用步长S=1。还有一点非常重要，就是对输入数据进行零填充，这样卷积层就不会改变输入数据在空间维度上的尺寸。比如，当F=3，那就使用P=1来保持输入尺寸。当F=5,P=2，一般对于任意F，当P=(F-1)/2的时候能保持输入尺寸。如果必须使用更大的滤波器尺寸（比如7x7之类），通常只用在第一个面对原始图像的卷积层上。</p><p><strong>汇聚层</strong><br>负责对输入数据的空间维度进行降采样。最常用的设置是用用2x2感受野（即F=2）的最大值汇聚，步长为2（S=2）。注意这一操作将会把输入数据中75%的激活数据丢弃（因为对宽度和高度都进行了2的降采样）。另一个不那么常用的设置是使用3x3的感受野，步长为2。最大值汇聚的感受野尺寸很少有超过3的，因为汇聚操作过于激烈，易造成数据信息丢失，这通常会导致算法性能变差。</p><p><strong>减少尺寸设置的问题</strong><br>上文中展示的两种设置是很好的，因为所有的卷积层都能保持其输入数据的空间尺寸，汇聚层只负责对数据体从空间维度进行降采样。如果使用的步长大于1并且不对卷积层的输入数据使用零填充，那么就必须非常仔细地监督输入数据体通过整个卷积神经网络结构的过程，确认所有的步长和滤波器都尺寸互相吻合，卷积神经网络的结构美妙对称地联系在一起。</p><p><strong>为什么在卷积层使用1的步长？</strong><br>在实际应用中，更小的步长效果更好。上文也已经提过，步长为1可以让空间维度的降采样全部由汇聚层负责，卷积层只负责对输入数据体的深度进行变换。</p><p><strong>为何使用零填充？</strong><br>使用零填充除了前面提到的可以让卷积层的输出数据保持和输入数据在空间维度的不变，还可以提高算法性能。如果卷积层值进行卷积而不进行零填充，那么数据体的尺寸就会略微减小，那么图像边缘的信息就会过快地损失掉。</p><p><strong>因为内存限制所做的妥协</strong>：在某些案例（尤其是早期的卷积神经网络结构）中，基于前面的各种规则，内存的使用量迅速飙升。例如，使用64个尺寸为3x3的滤波器对224x224x3的图像进行卷积，零填充为1，得到的激活数据体尺寸是[224x224x64]。这个数量就是一千万的激活数据，或者就是72MB的内存（每张图就是这么多，激活函数和梯度都是）。因为GPU通常因为内存导致性能瓶颈，所以做出一些妥协是必须的。在实践中，人们倾向于在网络的第一个卷积层做出妥协。例如，可以妥协可能是在第一个卷积层使用步长为2，尺寸为7x7的滤波器（比如在ZFnet中）。在AlexNet中，滤波器的尺寸的11x11，步长为4。</p><h3 id="案例学习"><a href="#案例学习" class="headerlink" title="案例学习"></a>案例学习</h3><p>下面是卷积神经网络领域中比较有名的几种结构：</p><ul><li>LeNet： 第一个成功的卷积神经网络应用，是Yann LeCun在上世纪90年代实现的。当然，最著名还是被应用在识别数字和邮政编码等的LeNet结构。<br>AlexNet：AlexNet卷积神经网络在计算机视觉领域中受到欢迎，它由Alex Krizhevsky，Ilya Sutskever和Geoff Hinton实现。AlexNet在2012年的ImageNet ILSVRC 竞赛中夺冠，性能远远超出第二名（16%的top5错误率，第二名是26%的top5错误率）。这个网络的结构和LeNet非常类似，但是更深更大，并且使用了层叠的卷积层来获取特征（之前通常是只用一个卷积层并且在其后马上跟着一个汇聚层）。</li><li>ZF Net：Matthew Zeiler和Rob Fergus发明的网络在ILSVRC 2013比赛中夺冠，它被称为 ZFNet（Zeiler &amp; Fergus Net的简称）。它通过修改结构中的超参数来实现对AlexNet的改良，具体说来就是增加了中间卷积层的尺寸，让第一层的步长和滤波器尺寸更小。</li><li>GoogLeNet：ILSVRC 2014的胜利者是谷歌的Szeged等实现的卷积神经网络。它主要的贡献就是实现了一个奠基模块，它能够显著地减少网络中参数的数量（AlexNet中有60M，该网络中只有4M）。还有，这个论文中没有使用卷积神经网络顶部使用全连接层，而是使用了一个平均汇聚，把大量不是很重要的参数都去除掉了。GooLeNet还有几种改进的版本，最新的一个是Inception-v4。</li><li>VGGNet：ILSVRC 2014的第二名是Karen Simonyan和 Andrew Zisserman实现的卷积神经网络，现在称其为VGGNet。它主要的贡献是展示出网络的深度是算法优良性能的关键部分。他们最好的网络包含了16个卷积/全连接层。网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的汇聚。他们的预训练模型是可以在网络上获得并在Caffe中使用的。VGGNet不好的一点是它耗费更多计算资源，并且使用了更多的参数，导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。后来发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量。</li><li>ResNet：残差网络（Residual Network）是ILSVRC2015的胜利者，由何恺明等实现。它使用了特殊的跳跃链接，大量使用了批量归一化（batch normalization）。这个结构同样在最后没有使用全连接层。读者可以查看何恺明的的演讲（视频，PPT），以及一些使用Torch重现网络的实验。ResNet当前最好的卷积神经网络模型（2016年五月）。何开明等最近的工作是对原始结构做一些优化，可以看论文Identity Mappings in Deep Residual Networks，2016年3月发表。</li></ul><h3 id="计算上的考量"><a href="#计算上的考量" class="headerlink" title="计算上的考量"></a>计算上的考量</h3><p>在构建卷积神经网络结构时，最大的瓶颈是内存瓶颈。大部分现代GPU的内存是3/4/6GB，最好的GPU大约有12GB的内存。要注意三种内存占用来源：</p><ul><li><strong>来自中间数据体尺寸</strong>：卷积神经网络中的每一层中都有激活数据体的原始数值，以及损失函数对它们的梯度（和激活数据体尺寸一致）。通常，大部分激活数据都是在网络中靠前的层中（比如第一个卷积层）。在训练时，这些数据需要放在内存中，因为反向传播的时候还会用到。但是在测试时可以聪明点：让网络在测试运行时候每层都只存储当前的激活数据，然后丢弃前面层的激活数据，这样就能减少巨大的激活数据量。</li><li><strong>来自参数尺寸</strong>：即整个网络的参数的数量，在反向传播时它们的梯度值，以及使用momentum、Adagrad或RMSProp等方法进行最优化时的每一步计算缓存。因此，存储参数向量的内存通常需要在参数向量的容量基础上乘以3或者更多。</li><li>卷积神经网络实现还有各种零散的内存占用，比如成批的训练数据，扩充的数据等等。</li></ul><p>一旦对于所有这些数值的数量有了一个大略估计（包含激活数据，梯度和各种杂项），数量应该转化为以GB为计量单位。把这个值乘以4，得到原始的字节数（因为每个浮点数占用4个字节，如果是双精度浮点数那就是占用8个字节），然后多次除以1024分别得到占用内存的KB，MB，最后是GB计量。如果你的网络工作得不好，一个常用的方法是降低批尺寸（batch size），因为绝大多数的内存都是被激活数据消耗掉了。</p><h2 id="拓展资源"><a href="#拓展资源" class="headerlink" title="拓展资源"></a>拓展资源</h2><p>和实践相关的拓展资源：</p><ul><li>Soumith benchmarks for CONV performance</li><li>ConvNetJS CIFAR-10 demo 可以让你在服务器上实时地调试卷积神经网络的结构，观察计算结果。</li><li>Caffe，一个流行的卷积神经网络库。</li><li>State of the art ResNets in Torch7</li></ul><p>———————- end —————————</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转载自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit，原文为：http://cs231n.github.io/convolutional-networks/，并进行一定的修改。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit，原文为：http://cs231n.github.io/convolutional-networks/，并进行一定的修改。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="课程笔记" scheme="https://ilewseu.github.io/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="cs231n" scheme="https://ilewseu.github.io/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>CS231n课程笔记(8)  Neural Nets Notes 3</title>
    <link href="https://ilewseu.github.io/2017/12/13/CS231n%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E7%AC%AC8%E8%AF%BE-Neural-Nets-Notes-3/"/>
    <id>https://ilewseu.github.io/2017/12/13/CS231n课程笔记-第8课-Neural-Nets-Notes-3/</id>
    <published>2017-12-13T14:17:23.000Z</published>
    <updated>2017-12-16T16:07:10.963Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转载自：<a href="https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit，原文为：http://cs231n.github.io/neural-networks-3/，并进行一定的修改。" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit，原文为：http://cs231n.github.io/neural-networks-3/，并进行一定的修改。</a></p></blockquote><p><strong>目录</strong><br><a id="more"></a></p><ul><li>梯度检查</li><li>合理性（Sanity）检查</li><li>检查学习过程<ul><li>损失函数</li><li>训练集与验证集准确率</li><li>权重：更新比例</li><li>每层的激活数据与梯度分布</li><li>可视化</li></ul></li><li>参数更新<ul><li>一阶（随机梯度下降）方法，动量方法，Nestrov动量方法</li><li>学习率退火</li><li>二阶方法</li><li>逐参数适应学习率方法（Adagrad，RMSProp）</li></ul></li><li>参数调优</li><li>评价<ul><li>模型集成</li></ul></li><li>总结</li></ul><h2 id="梯度检查"><a href="#梯度检查" class="headerlink" title="梯度检查"></a>梯度检查</h2><p>理论上将进行梯度检查很简单，就是简单地把解析梯度和数值计算梯度进行比较。然而从实际操作层面上来说，这个过程更加复杂且容易出错。下面是一些提示、技巧和需要仔细注意的事情。<br><strong>使用中心化公式</strong>，在使用有限差值近似来计算数值梯度的时候，常见的公式是：$$<br>\frac {df(x)}{dx}=\frac {f(x+h) - f(x)}{h}(bad, do not use)<br>$$<br>其中，h是一个很小的数字，在实践中，近似为1e-5。在实践中证明，使用中心化公式效果更好：$$<br>\frac {df(x)}{dx}=\frac {f(x+h) - f(x-h)}{2h}(use instead)<br>$$<br>该公式在检查梯度的每个维度的时候，会要求计算两次损失函数（所以计算资源的耗费也是两倍），但是梯度的近似值会准确很多。要理解这一点，对f(x+h)和f(x-h)使用泰勒展开，可以看到第一个公式的误差近似O(h)，第二个公式的误差近似$O(h^2)$（是个二阶近似）。</p><p><strong>使用相对误差来比较，</strong>比较数值梯度$f_n^’$和解析梯度$f_a^’$的细节有哪些？如何得知此两者不匹配？你可能会倾向于监测它们的差的绝对值$|f_a^’-f_n^’|$或者差的平方值，然后定义该值如果超过某个规定阈值，就判断梯度实现失败。然而该思路是有问题的。想想，假设这个差值是1e-4，如果两个梯度值在1.0左右，这个差值看起来就很合适，可以认为两个梯度是匹配的。然而如果梯度值是1e-5或者更低，那么1e-4就是非常大的差距，梯度实现肯定就是失败的了。因此，使用相对误差总是更合适一些：$$<br>\frac {|f_a^’-f_n^’|}{max(|f_a^’|,|f_n^’|)}<br>$$<br>上式考虑了差值占两个梯度绝对值的比例。注意通常相对误差公式只包含两个式子中的一个（任意一个均可），但是我更倾向取两个式子的最大值或者取两个式子的和。这样做是为了防止在其中一个式子为0时，公式分母为0（这种情况，在ReLU中是经常发生的）。然而，还必须注意两个式子都为零且通过梯度检查的情况。在实践中：</p><ul><li>相对误差&gt;1e-2:通常就意味着梯度可能出错;</li><li>1e-2&gt;相对误差&gt;1e-4:要对这个值感到不舒服才行;</li><li>1e-4&gt;相对误差：这个值的相对误差对于有不可导点的目标函数是OK的。但如果目标函数中没有kink（使用tanh和softmax），那么相对误差值还是太高;</li><li>1e-7或者更小：好结果，可以高兴一把了。</li></ul><p>要知道的是网络的深度越深，相对误差就越高。所以，如果你是在对一个10层网络的输入数据做梯度检查，那么1e-2的相对误差值可能就OK了，因为误差一直在累积。相反，如果一个可微函数的相对误差值是1e-2，那么通常说明梯度实现不正确。</p><p><strong>使用双精度</strong>：一个常见的错误是使用单精度浮点数来进行梯度检查，这样会导致即使梯度实现正确，相对误差值也会很高。在我的经验而言，出现过使用单精度浮点数时相对误差为1e-2，换成双精度浮点数时，就降低为1e-8的情况。</p><p><strong>保持在浮点数的有效范围</strong>，建议通读《What Every Computer Scientist Should Konw About Floating-Point Artthmetic》一文，该文将阐明你可能犯的错误，促使你写下更加细心的代码。例如，在神经网络中，在一个批量的数据上对损失函数进行归一化是很常见的。但是，如果每个数据点的梯度很小，然后又用数据点的数量去除，就使得数值更小，这反过来会导致更多的数值问题。这就是我为什么总是会把原始的解析梯度和数值梯度数据打印出来，确保用来比较的数字的值不是过小（通常绝对值小于1e-10就绝对让人担心）。如果确实过小，可以使用一个常数暂时将损失函数的数值范围扩展到一个更“好”的范围，在这个范围中浮点数变得更加致密。比较理想的是1.0的数量级上，即当浮点数指数为0时。</p><p><strong>目标函数的不可导点（kinks)</strong>，在进行梯度检查时，一个导致不准确的原因是不可导点问题。不可导点是指目标函数不可导的部分，由ReLU（max(0,x)）等函数，或SVM损失，Maxout神经元等引入。考虑当x=-1e6的时，对ReLU函数进行梯度检查。因为x<0，所以解析梯度在该点的梯度为0。然而，在这里数值梯度会突然计算出一个非零的梯度值，因为f(x+h)可能越过了不可导点(例如：如果h>1e-6)，导致了一个非零的结果。你可能会认为这是一个极端的案例，但实际上这种情况很常见。例如，一个用CIFAR-10训练的SVM中，因为有50,000个样本，且根据目标函数每个样本产生9个式子，所以包含有450,000个max(0,x)式子。而一个用SVM进行分类的神经网络因为采用了ReLU，还会有更多的不可导点。</0，所以解析梯度在该点的梯度为0。然而，在这里数值梯度会突然计算出一个非零的梯度值，因为f(x+h)可能越过了不可导点(例如：如果h></p><p>注意，在计算损失的过程中是可以知道不可导点有没有被越过的。在具有max(x,y)形式的函数中持续跟踪所有“赢家”的身份，就可以实现这一点。其实就是看在前向传播时，到底x和y谁更大。如果在计算f(x+h)和f(x-h)的时候，至少有一个“赢家”的身份变了，那就说明不可导点被越过了，数值梯度会不准确。</p><p><strong>使用少量数据点</strong>，解决上面的不可导点问题的一个办法是使用更少的数据点。因为含有不可导点的损失函数(例如：因为使用了ReLU或者边缘损失等函数)的数据点越少，不可导点就越少，所以在计算有限差值近似时越过不可导点的几率就越小。还有，如果你的梯度检查对2-3个数据点都有效，那么基本上对整个批量数据进行梯度检查也是没问题的。所以使用很少量的数据点，能让梯度检查更迅速高效。</p><p><strong>谨慎设置步长h</strong>，在实践中h并不是越小越好，因为当h特别小的时候，就可能会遇到数值精度问题。有时候如果梯度检查无法进行，可以试试将h调到1e-4或者1e-6，然后突然梯度检查就可能恢复正常。</p><p><strong>在操作的特性模式中梯度检查</strong>，有一点必须要认识到：梯度检查是在参数空间中的一个特定（往往还是随机的）的单独点进行的。即使是在该点上梯度检查成功了，也不能马上确保全局上梯度的实现都是正确的。还有，一个随机的初始化可能不是参数空间最优代表性的点，这可能导致进入某种病态的情况，即梯度看起来是正确实现了，实际上并没有。例如，SVM使用小数值权重初始化，就会把一些接近于0的得分分配给所有的数据点，而梯度将会在所有的数据点上展现出某种模式。一个不正确实现的梯度也许依然能够产生出这种模式，但是不能泛化到更具代表性的操作模式，比如在一些的得分比另一些得分更大的情况下就不行。因此为了安全起见，最好让网络学习（“预热”）一小段时间，等到损失函数开始下降的之后再进行梯度检查。在第一次迭代就进行梯度检查的危险就在于，此时可能正处在不正常的边界情况，从而掩盖了梯度没有正确实现的事实。</p><p><strong>不要让正则化吞没数据</strong>，通常损失函数是数据损失和正则化损失的和，需要注意的危险是正则化损失可能吞没掉数据损失，在这种情况下梯度主要来源于正则化部分（正则化部分的梯度表达式通常简单很多）。这样就会掩盖掉数据损失梯度的不正确实现。因此，推荐关掉正则化对数据损失做单独检查，然后对正则化做单独检查。对于正则化的单独检查可以是修改代码，去掉其中数据损失的部分，也可以提高正则化的强度，确认其效果在梯度检查中是无法忽略的，这样不正确的实现就会被观察到了。</p><p><strong>记得关闭随机失活（Dropout）和数据扩张（augmentation）</strong>,在进行梯度检查时，记得关闭网络中任何不确定的效果的操作，比如随机失活，随机数据扩展等。不然它们会在计算数值梯度的时候导致巨大误差。关闭这些操作不好的一点是无法对它们进行梯度检查（例如随机失活的反向传播实现可能有错误）。因此，一个更好的解决方案就是在计算f(x+h)和f(x-h)前强制增加一个特定的随机种子，在计算解析梯度时也同样如此。</p><p><strong>检查少量的维度</strong>，在实际中，梯度可以有上百万的参数，在这种情况下只能检查其中一些维度，然后假设其他维度是正确的。注意：确认在所有不同的参数中都抽取一部分来梯度检查。在某些应用中，为了方便，人们将所有的参数放到一个巨大的参数向量中。在这种情况下，例如偏置就可能只占用整个向量中的很小一部分，所以不要随机的从向量中取维度，一定要把这种情况考虑到，确保所有的参数都收到了正确的梯度。</p><h2 id="学习之前：合理性检查的提示与技巧"><a href="#学习之前：合理性检查的提示与技巧" class="headerlink" title="学习之前：合理性检查的提示与技巧"></a>学习之前：合理性检查的提示与技巧</h2><p>在进行费时费力的最优化之前，最好进行一些合理性检查：</p><ul><li><strong>寻找特定情况的正确损失值</strong>，在使用小参数进行初始化时，确保得到的损失值与期望一致。最好先单独检查数据损失（让正则化强度为0）。例如，对于一个跑CIFAR-10的Softmax分类器，一般期望它的初始损失值是2.302，这是因为初始时预计每个类别的概率是0.1（因为有10个类别），然后Softmax损失值正确分类的负对数概率：-ln(0.1)=2.302。对于Weston Watkins SVM，假设所有的边界都被越过（因为所有的分值都近似为零），所以损失值是9（因为对于每个错误分类，边界值是1）。如果没看到这些损失值，那么初始化中就可能有问题。</li><li>第二个合理性检查：提高正则化强度时导致损失值变大。</li><li><strong>对小数据子集过拟合</strong>， 最后也是最重要的一步，在整个数据集进行训练之前，尝试在一个很小的数据集上进行训练（比如20个数据），然后确保能到达0的损失值。进行这个实验的时候，最好让正则化强度为0，不然它会阻止得到0的损失。除非能通过这一个正常性检查，不然进行整个数据集训练是没有意义的。但是注意，能对小数据集进行过拟合并不代表万事大吉，依然有可能存在不正确的实现。比如，因为某些错误，数据点的特征是随机的，这样算法也可能对小数据进行过拟合，但是在整个数据集上跑算法的时候，就没有任何泛化能力。</li></ul><h2 id="检查学习过程"><a href="#检查学习过程" class="headerlink" title="检查学习过程"></a>检查学习过程</h2><p>在训练神经网络的时候，应该跟踪多个重要数值。这些数值输出的图表是观察训练进程的一扇窗口，是直观理解不同的超参数设置效果的工具，从而知道如何修改超参数以获得更高效的学习过程。<br>在下面的图表中，x轴通常都是表示周期（epochs）单位，该单位衡量了在训练中每个样本数据都被观察过次数的期望（一个周期意味着每个样本数据都被观察过了一次）。相较于迭代次数（iterations），一般更倾向跟踪周期，这是因为迭代次数与数据的批尺寸（batchsize）有关，而批尺寸的设置又可以是任意的。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>训练期间第一个要跟踪的数值就是损失值，它再前向传播时对每个独立的批数据进行计算。下图是展示的是损失值随着时间的变化，尤其是曲线形状会给出关于学习率设置的情况：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171208/8Ala2gIhjB.jpg?imageslim" alt="mark"><br></div><br>左图展示了不同的学习率的效果。过低的学习率导致算法的改善是线性的。高一些的学习率会看起来呈几何指数下降，更高的学习率会让损失值很快下降，但是接着就停在一个不好的损失值上（绿线）。这是因为最优化的“能量”太大，参数在混沌中随机震荡，不能最优化到一个很好的点上。右图显示了一个典型的随时间变化的损失函数值，在CIFAR-10数据集上面训练了一个小的网络，这个损失函数值曲线看起来比较合理（虽然可能学习率有点小，但是很难说），而且指出了批数据的数量可能有点太小（因为损失值的噪音很大）。</p><p>损失值的震荡程度和批尺寸（batch size）有关，当批尺寸为1，震荡会相对较大。当批尺寸就是整个数据集时震荡就会最小，因为每个梯度更新都是单调地优化损失函数（除非学习率设置得过高）。</p><p>有的研究者喜欢用对数域对损失函数值作图。因为学习过程一般都是采用指数型的形状，图表就会看起来更像是能够直观理解的直线，而不是呈曲棍球一样的曲线状。还有，如果多个交叉验证模型在一个图上同时输出图像，它们之间的差异就会比较明显。</p><h3 id="训练集与验证集准确率"><a href="#训练集与验证集准确率" class="headerlink" title="训练集与验证集准确率"></a>训练集与验证集准确率</h3><p>在训练分类器的时候，需要跟踪的第二重要的数值是验证集和训练集的准确率。这个图表能够展现知道模型过拟合的程度：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171208/JJaikb2iaI.jpg?imageslim" alt="mark"><br></div><br>在训练集准确率和验证集准确率中间的空隙指明了模型过拟合的程度。在图中，蓝色的验证集曲线显示相较于训练集，验证集的准确率低了很多，这就说明模型有很强的过拟合。遇到这种情况，就应该增大正则化强度（更强的L2权重惩罚，更多的随机失活等）或收集更多的数据。另一种可能就是验证集曲线和训练集曲线如影随形，这种情况说明你的模型容量还不够大：应该通过增加参数数量让模型容量更大些。</p><h3 id="权重：更新比例"><a href="#权重：更新比例" class="headerlink" title="权重：更新比例"></a>权重：更新比例</h3><p>最后一个应该跟踪的量是权重中更新值的数量和全部值的数量之间的比例。注意：是更新的，而不是原始梯度（比如，在普通sgd中就是梯度乘以学习率）。需要对每个参数集的更新比例进行单独的计算和跟踪。一个经验性的结论是这个比例应该在1e-3左右。如果更低，说明学习率可能太小，如果更高，说明学习率可能太高。下面是具体例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 假设参数向量为W，其梯度向量为dW</span></div><div class="line">param_scale = np.linalg.norm(W.ravel())</div><div class="line">update = -learning_rate*dW <span class="comment"># 简单SGD更新</span></div><div class="line">update_scale = np.linalg.norm(update.ravel())</div><div class="line">W += update <span class="comment"># 实际更新</span></div><div class="line"><span class="keyword">print</span> update_scale / param_scale <span class="comment"># 要得到1e-3左右</span></div></pre></td></tr></table></figure></p><p>相较于跟踪最大和最小值，有研究者更喜欢计算和跟踪梯度的范式及其更新。这些矩阵通常是相关的，也能得到近似的结果。</p><h3 id="每层的激活数据与梯度分布"><a href="#每层的激活数据与梯度分布" class="headerlink" title="每层的激活数据与梯度分布"></a>每层的激活数据与梯度分布</h3><p>一个不正确的初始化可能让学习过程变慢，甚至彻底停止。还好，这个问题可以比较简单地诊断出来。其中一个方法是输出网络中所有层的激活数据和梯度分布的柱状图。直观地说，就是如果看到任何奇怪的分布情况，那都不是好兆头。比如，对于使用tanh的神经元，我们应该看到激活数据的值在整个[-1,1]区间中都有分布。如果看到神经元的输出全部是0，或者全都饱和了往-1和1上跑，那肯定就是有问题了。</p><h3 id="第一层可视化"><a href="#第一层可视化" class="headerlink" title="第一层可视化"></a>第一层可视化</h3><p>最后，如果数据是图像像素数据，那么把第一层特征可视化会有帮助。</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171208/mKheECkaAi.jpg?imageslim" alt="mark"><br></div><br>将神经网络第一层的权重可视化的例子。左图中的特征充满了噪音，这暗示了网络可能出现了问题：网络没有收敛，学习率设置不恰当，正则化惩罚的权重过低。右图的特征不错，平滑，干净而且种类繁多，说明训练过程进行良好。</p><h2 id="参数更新"><a href="#参数更新" class="headerlink" title="参数更新"></a>参数更新</h2><p>一旦能使用反向传播计算解析梯度，梯度就能被用来进行参数更新。进行参数更新有好几种方法，接下来都会进行讨论。</p><p>深度网络的最优化是现在非常活跃的研究领域。本节将重点介绍一些公认有效的常用的技巧，这些技巧都是在实践之中会遇到的。我们将简要介绍这些技巧的直观概念，但不进行细节分析。对细节感兴趣的读者，我们提供一些拓展阅读。</p><h3 id="随机梯度下降及各种更新方法"><a href="#随机梯度下降及各种更新方法" class="headerlink" title="随机梯度下降及各种更新方法"></a>随机梯度下降及各种更新方法</h3><p><strong>普通更新</strong>，最简单的更新形式是沿着负梯度方向改变参数（因为梯度指向的是上升的方法，但是我们通常希望最小化损失函数）。假设有一个参数向量x及其梯度dx，那么最简单的更新的形式是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 普通更新</span></div><div class="line">x += - learning_rate * dx</div></pre></td></tr></table></figure></p><p>其中，learning_rate是一个超参数，它是一个固定的常量。当在整个数据集上进行计算时，只要学习率足够低，总是能在损失函数上得到非负的进展。</p><p><strong>动量（Momentum）更新</strong>是另外一个方法，这个方法在深度网络上几乎总能得到更好的收敛速度。该方法可以看成是从物理角度上对最优化问题的得到的启发。损失函数可以理解为是山的高度（因此高度的势能是U=mgh），用随机数字初始化参数等同于在某个位置给质点设定初始速度为0.这样最优化过程就可以看成是模拟参数向量（即质点）在地形上滚动的过程。</p><p>因为作用于质点的力与梯度的潜在能量($F=-\nabla U$)有关，质点所受的力就是损失函数的负梯度。还有，因为F=ma，所以在这个观点下负梯度与质点的加速度是成比例的。注意这个理解和上面的随机梯度下降SGD是不同的，在普通版本中，梯度直接影响位置。而在这个版本的更新中，物理观点建议梯度只是影响速度，然后速度再影响位置：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 动量更新</span></div><div class="line">v = mu * v - learning_rate * dx <span class="comment"># 与速度融合</span></div><div class="line">x += v <span class="comment"># 与位置融合</span></div></pre></td></tr></table></figure></p><p>在这里引入一个初始化为0的变量v和一个超参数mu。说的不恰当一点，这个变量mu，在最优化的过程中被看做动量（一般值设为0.9），但其物理意义与摩擦系数更一致。这个变量有效地抑制了速度，降低了系统的动能，不然质点在山底永远不会停下来。通过交叉验证，这个参数通常设置为[0.5,0.9,0.95,0.99]中的一个。和学习率随着时间退火类似，动量随时间变化的设置有时能略微改善最优化效果，其中动量在学习过程的后阶段会上升。一个典型的设置是刚开始将动量设置为0.5,而在后面的多个周期（epoch）中慢慢提升到0.99。</p><blockquote><p>通过动量更新，参数向量会在任何有持续梯度的方向上增加速度。</p></blockquote><p><strong>Nesterov动量</strong>与普通动量有些许不同，最近变得比较流行。在理论上对于凸函数它能得到更好的收敛，在实践中也确实比标准动量表现更好一些。<br><strong>Nesterov动量的核心思路是</strong>，当参数向量位于某个位置x时，观察上面的动量更新公式可以发现，动量部分（忽视带梯度的第二个部分）会通过mu<em> v稍微改变参数向量。因此，如果要计算梯度，那么可以将未来的近似位置x+mu</em> v看做是“向前看”，这个点在我们一会儿要停止的位置附近。因此，计算x+mu* v的梯度而不是“旧”位置x的梯度就有意义了。</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171209/j819bJD0FH.jpg?imageslim" alt="mark"><br></div><br>Nesterov动量。既然我们知道动量将会把我们带到绿色箭头指向的点，我们就不要在原点（红色点）那里计算梯度了。使用Nesterov动量，我们就在这个“向前看”的地方计算梯度。<br>也就是说，添加一些注释后，实现代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">x_ahead = x + mu * v</div><div class="line"><span class="comment"># 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)</span></div><div class="line">v = mu * v - learning_rate * dx_ahead</div><div class="line">x += v</div></pre></td></tr></table></figure></p><p>然而在实践中，人们更喜欢和普通SGD或上面的动量方法一样简单的表达式。通过对x_ahead = x + mu * v使用变量变换进行改写是可以做到的，然后用x_ahead而不是x来表示上面的更新。也就是说，实际存储的参数向量总是向前一步的那个版本。x_ahead的公式（将其重新命名为x）就变成了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">v_prev = v <span class="comment"># 存储备份</span></div><div class="line">v = mu * v - learning_rate * dx <span class="comment"># 速度更新保持不变</span></div><div class="line">x += -mu * v_prev + (<span class="number">1</span> + mu) * v <span class="comment"># 位置更新变了形式</span></div></pre></td></tr></table></figure></p><p>对于NAG（Nesterov’s Accelerated Momentum）的来源和数学公式推导，我们推荐以下的拓展阅读：</p><ul><li>Yoshua Bengio的Advances in optimizing Recurrent Networks，Section 3.5。</li><li><a href="http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf在section" target="_blank" rel="external">http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf在section</a> 7.2对于这个主题有更详尽的阐述。</li></ul><h3 id="学习率退火"><a href="#学习率退火" class="headerlink" title="学习率退火"></a>学习率退火</h3><p>在训练深度网络的时候，让学习率随着时间退火通常是有帮助的。可以这样理解：如果学习率很高，系统的动能就过大，参数向量就会无规律地跳动，不能够稳定到损失函数更深更窄的部分去。知道什么时候开始衰减学习率是有技巧的：慢慢减小它，可能在很长时间内只能是浪费计算资源地看着它混沌地跳动，实际进展很少。但如果快速地减少它，系统可能过快地失去能量，不能到达原本可以到达的最好位置。通常，实现学习率退火有3种方式：</p><ul><li><strong>随步数衰减：</strong>每进行几个周期就根据一些因素降低学习率。典型的值是每过5个周期就将学习率减少一半，或者每20个周期减少到之前的0.1。这些数值的设定是严重依赖具体的问题和模型的选择的。在实践中可能看见这么一种经验做法：使用一个固定的学习率来进行训练的同时观察验证集错误率，每当验证集错误率停止下降，就乘以一个常数（比如0.5）来降低学习率。</li><li><strong>指数衰减：</strong>数学公式是$\alpha = \alpha_0e^{-kt}$，其中,$\alpha_0,k$是超参数，t是迭代次数（也可以使用周期作为单位）。</li><li><strong>1/t衰减：</strong>数学公式是$\alpha=\alpha_0/(1+kt)$,$\alpha_0,k$是超参数，t是迭代次数。<br>在实践中，我们发现随步数衰减的随机失活（dropout）更受欢迎，因为它使用的超参数（衰减系数和以周期为时间单位的步数）比k更有解释性。最后，如果你有足够的计算资源，可以让衰减更加缓慢一些，让训练时间更长些。</li></ul><h3 id="二阶方法"><a href="#二阶方法" class="headerlink" title="二阶方法"></a>二阶方法</h3><p>在深度网络背景下，第二类常用的最优化方法是基于牛顿法的，其迭代如下$$<br>x \leftarrow x - [Hf(x)]^{-1}\nabla f(x)<br>$$<br>这里Hf(x)是Hessian矩阵，它是函数的二阶偏导数的平方矩阵。$\nabla f(x)$是梯度向量，这和梯度下降中一样。直观理解上，Hessian矩阵描述了损失函数的局部曲率，从而使得可以进行更高效的参数更新。具体来说，就是乘以Hessian转置矩阵可以让最优化过程在曲率小的时候大步前进，在曲率大的时候小步前进。需要重点注意的是，在这个公式中是没有学习率这个超参数的，这相较于一阶方法是一个巨大的优势。<br>然而，上述更新方法很难运用到实际的深度学习应用中去，这是因为计算（以及求逆）Hessian矩阵操作非常耗费时间和空间。举例来说，假设一个有一百万个参数的神经网络，其Hessian矩阵大小就是[1,000,000 x 1,000,000]，将占用将近3,725GB的内存。这样，各种各样的拟-牛顿法就被发明出来用于近似转置Hessian矩阵。在这些方法中最流行的是L-BFGS，该方法使用随时间的梯度中的信息来隐式地近似（也就是说整个矩阵是从来没有被计算的）。</p><p>然而，即使解决了存储空间的问题，L-BFGS应用的一个巨大劣势是需要对整个训练集进行计算，而整个训练集一般包含几百万的样本。和小批量随机梯度下降（mini-batch SGD）不同，让L-BFGS在小批量上运行起来是很需要技巧，同时也是研究热点。</p><p><strong>实践</strong>，在深度学习和卷积神经网络中，使用L-BFGS之类的二阶方法并不常见。相反，基于（Nesterov的）动量更新的各种随机梯度下降方法更加常用，因为它们更加简单且容易扩展。</p><p>参考资料：</p><ul><li>Large Scale Distributed Deep Networks 一文来自谷歌大脑团队，比较了在大规模数据情况下L-BFGS和SGD算法的表现。</li><li>SFO算法想要把SGD和L-BFGS的优势结合起来。</li></ul><h3 id="逐参数适应学习率方法"><a href="#逐参数适应学习率方法" class="headerlink" title="逐参数适应学习率方法"></a>逐参数适应学习率方法</h3><p>前面讨论的所有方法都是对学习率进行全局地操作，并且对所有的参数都是一样的。学习率调参是很耗费计算资源的过程，所以很多工作投入到发明能够适应性地对学习率调参的方法，甚至是逐个参数适应学习率调参。很多这些方法依然需要其他的超参数设置，但是其观点是这些方法对于更广范围的超参数比原始的学习率方法有更良好的表现。在本小节我们会介绍一些在实践中可能会遇到的常用适应算法：</p><p>Adagrad是一个由Duchi等提出的适应性学习率算法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 假设有梯度和参数向量x</span></div><div class="line">cache += dx**<span class="number">2</span></div><div class="line">x += - learning_rate * dx / (np.sqrt(cache) + eps)</div></pre></td></tr></table></figure></p><p>注意，变量cache的尺寸和梯度矩阵的尺寸是一样的，还跟踪了每个参数的梯度的平方和。这个一会儿将用来归一化参数更新步长，归一化是逐元素进行的。注意，接收到高梯度值的权重更新的效果被减弱，而接收到低梯度值的权重的更新效果将会增强。有趣的是平方根的操作非常重要，如果去掉，算法的表现将会糟糕很多。用于平滑的式子eps（一般设为1e-4到1e-8之间）是防止出现除以0的情况。Adagrad的一个缺点是，在深度学习中单调的学习率被证明通常过于激进且过早停止学习。</p><p><strong>RMSprop</strong>是一个非常高效，但没有公开发表的适应性学习率方法。有趣的是，每个使用这个方法的人在他们的论文中都引用自Geoff Hinton的Coursera课程的第六课的第29页PPT。这个方法用一种很简单的方式修改了Adagrad方法，让它不那么激进，单调地降低了学习率。具体说来，就是它使用了一个梯度平方的滑动平均：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cache =  decay_rate * cache + (<span class="number">1</span> - decay_rate) * dx**<span class="number">2</span></div><div class="line">x += - learning_rate * dx / (np.sqrt(cache) + eps)</div></pre></td></tr></table></figure></p><p>在上面的代码中，decay_rate是一个超参数，常用的值是[0.9,0.99,0.999]。其中x+=和Adagrad中是一样的，但是cache变量是不同的。因此，RMSProp仍然是基于梯度的大小来对每个权重的学习率进行修改，这同样效果不错。但是和Adagrad不同，其更新不会让学习率单调变小。</p><p><strong>Adam</strong>是最近才提出的一种更新方法，它看起来像是RMSProp的动量版。简化的代码是下面这样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">m = beta1*m + (<span class="number">1</span>-beta1)*dx</div><div class="line">v = beta2*v + (<span class="number">1</span>-beta2)*(dx**<span class="number">2</span>)</div><div class="line">x += - learning_rate * m / (np.sqrt(v) + eps)</div></pre></td></tr></table></figure></p><p>注意这个更新方法看起来真的和RMSProp很像，除了使用的是平滑版的梯度m，而不是用的原始梯度向量dx。论文中推荐的参数值eps=1e-8, beta1=0.9, beta2=0.999。在实际操作中，我们推荐Adam作为默认的算法，一般而言跑起来比RMSProp要好一点。但是也可以试试SGD+Nesterov动量。完整的Adam更新算法也包含了一个偏置（bias）矫正机制，因为m,v两个矩阵初始为0，在没有完全热身之前存在偏差，需要采取一些补偿措施。建议读者可以阅读论文查看细节，或者课程的PPT。<br>拓展阅读：</p><ul><li>Unit Tests for Stochastic Optimization一文展示了对于随机最优化的测试。</li></ul><h2 id="参数调优"><a href="#参数调优" class="headerlink" title="参数调优"></a>参数调优</h2><p>我们已经看到，训练一个神经网络会遇到很多超参数设置，神经网络最常用的设置有：</p><ul><li>初始化学习率；</li><li>学习率衰减方式（例如一个衰减常量）</li><li>正则化强度（L2惩罚，随机失活强度）<br>但是也可以看到，还有很多相对不那么敏感的超参数。比如在逐参数适应学习方法中，对于动量及时间表的设置等。在本节中将介绍一些额外的调参要点和技巧：</li></ul><p><strong>实现</strong>：更大的神经网络需要更长的时间去训练，所以调参可能需要几天甚至几周。记住这一点很重要，因为这会影响你设计代码的思路。一个具体的设计是用<strong>仆程序</strong>持续地随机设置参数然后进行最优化。在训练过程中，<strong>仆程序</strong>会对每个周期后验证集的准确率进行监控，然后向文件系统写下一个模型的记录点（记录点中有各种各样的训练统计数据，比如随着时间的损失值变化等），这个文件系统最好是可共享的。在文件名中最好包含验证集的算法表现，这样就能方便地查找和排序了。然后还有一个<strong>主程序</strong>，它可以启动或者结束计算集群中的<strong>仆程序</strong>，有时候也可能根据条件查看<strong>仆程序</strong>写下的记录点，输出它们的训练统计数据等。</p><p><strong>比起交叉验证最好使用一个验证集</strong>：在大多数情况下，一个尺寸合理的验证集可以让代码更简单，不需要用几个数据集来交叉验证。你可能会听到人们说他们“交叉验证”一个参数，但是大多数情况下，他们实际是使用的一个验证集。</p><p><strong>超参数范围</strong>，在对数尺度上进行超参数搜索，例如，一个典型的学习率应该看起来是这样：learning_rate = 10**uniform(-6, 1)。也就是说，我们从标准分布中随机生成了一个数字，然后让它成为10的阶数。对于正则化强度，可以采用同样的策略。直观地说，这是因为学习率和正则化强度都对于训练的动态进程有承的效果。例如：当学习率是0.001的时候，如果对其固定地增加0.001，那么对于学习进程会有很大的影响。然而当学习率是10的时候，影响就微乎其微了。。这就是因为学习率乘以了计算出的梯度。因此，比起加上或者减少某些值，思考学习率的范围是乘以或者除以某些值更加自然。但是有一些参数（比如随机失活）还是在原始尺度上进行搜索（例如：dropout=uniform(0,1)）。</p><p><strong>随机搜索优于网格搜索</strong>，Bergstra和Bengio在文章Random Search for Hyper-Parameter Optimization中说“随机选择比网格化的选择更加有效”，而且在实践中也更容易实现。</p><p><strong>对于边界上的最优值要小心：</strong>这种情况一般发生在你在一个不好的范围内搜索超参数（比如学习率）的时候。比如，假设我们使用learning_rate = 10**uniform(-6,1)来进行搜索。一旦我们得到一个比较好的值，一定确认你的值不是出于这个范围的边界上，不然你可能错过更好的其他搜索范围。</p><p><strong>从粗到细地分阶段搜索</strong>，在实践中，先进行初略范围（比如10 ** [-6, 1]）搜索，然后根据好的结果出现的地方，缩小范围进行搜索。进行粗搜索的时候，让模型训练一个周期就可以了，因为很多超参数的设定会让模型没法学习，或者突然就爆出很大的损失值。第二个阶段就是对一个更小的范围进行搜索，这时可以让模型运行5个周期，而最后一个阶段就在最终的范围内进行仔细搜索，运行很多次周期。</p><p><strong>贝叶斯超参数最优化</strong>是一整个研究领域，主要是研究在超参数空间中更高效的导航算法。其核心的思路是在不同超参数设置下查看算法性能时，要在探索和使用中进行合理的权衡。基于这些模型，发展出很多的库，比较有名的有： Spearmint, SMAC, 和Hyperopt。然而，在卷积神经网络的实际使用中，比起上面介绍的先认真挑选的一个范围，然后在该范围内随机搜索的方法，这个方法还是差一些。这里有<a href="http://nlpers.blogspot.com/2014/10/hyperparameter-search-bayesian.html更详细的讨论。" target="_blank" rel="external">http://nlpers.blogspot.com/2014/10/hyperparameter-search-bayesian.html更详细的讨论。</a></p><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><h3 id="模型集成"><a href="#模型集成" class="headerlink" title="模型集成"></a>模型集成</h3><p>在实践的时候，有一个总是能提升神经网络几个百分点准确率的办法，就是在训练的时候训练几个独立的模型，然后在测试的时候平均它们预测结果。集成的模型数量增加，算法的结果也单调提升（但提升效果越来越少）。还有模型之间的差异度越大，提升效果可能越好。进行集成有以下几种方法：</p><ul><li><strong>同一个模型，不同的初始化</strong>，使用交叉验证来得到最好的超参数，然后用最好的参数来训练不同初始化条件的模型。这种方法的风险在于多样性只来自于不同的初始化条件。</li><li><strong>在交叉验证中发现最好的模型</strong>，使用交叉验证来得到最好的超参数，然后取其中最好的几个（比如10个）模型来进行集成。这样就提高了集成的多样性，但风险在于可能会包含不够理想的模型。在实际操作中，这样操作起来比较简单，在交叉验证后就不需要额外的训练了。</li><li><strong>一个模型设置多个记录点</strong>，如果训练非常耗时，那就在不同的训练时间对网络留下记录点（比如每个周期结束），然后用它们来进行模型集成。很显然，这样做多样性不足，但是在实践中效果还是不错的，这种方法的优势是代价比较小。</li><li><strong>在训练的时候跑参数的平均值</strong>，和上面一点相关的，还有一个也能得到1-2个百分点的提升的小代价方法，这个方法就是在训练过程中，如果损失值相较于前一次权重出现指数下降时，就在内存中对网络的权重进行一个备份。这样你就对前几次循环中的网络状态进行了平均。你会发现这个“平滑”过的版本的权重总是能得到更少的误差。直观的理解就是目标函数是一个碗状的，你的网络在这个周围跳跃，所以对它们平均一下，就更可能跳到中心去。</li></ul><p>模型集成的一个劣势就是在测试数据的时候会花费更多时间。最近Geoff Hinton在“Dark Knowledge”上的工作很有启发：其思路是通过将集成似然估计纳入到修改的目标函数中，从一个好的集成中抽出一个单独模型。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>训练一个神经网络需要：</p><ul><li>利用小批量的数据对实现进行梯度检查，还要注意各种错误。</li><li>进行合理性检查，确认初始损失值是合理的，在小数据集上能得到100%的准确率。</li><li>在训练时，跟踪损失函数值，训练集和验证集准确率，如果愿意，还可以跟踪更新的参数相对于总参数的比例（一般在1e-3左右）然后如果是对于卷积神经网络，可以将第一层的权重可视化。</li><li>推荐的两个更新方法是SGD+Nesterov动量方法，或者是Adam方法。</li><li>随着训练进行学习率衰减。比如，在固定多少个周期后让学习率减半，或者当验证集准确率下降的时候。</li><li>使用随机搜索（不要使用网格搜索）来搜索最优的超参数。分阶段从粗（比较宽的超参数范围训练1-5个周期）到细（窄范围训练很多个周期）地来搜索。</li><li>进行模型集成来获得额外的性能提高。</li></ul><h2 id="拓展阅读"><a href="#拓展阅读" class="headerlink" title="拓展阅读"></a>拓展阅读</h2><ul><li>Leon Botton的《SGD要点和技巧》：<a href="https://www.microsoft.com/en-us/research/publication/stochastic-gradient-tricks/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F192769%2Ftricks-2012.pdf" target="_blank" rel="external">https://www.microsoft.com/en-us/research/publication/stochastic-gradient-tricks/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F192769%2Ftricks-2012.pdf</a></li><li>Yann LeCun的《Efficient BackProp》：<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target="_blank" rel="external">http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf</a></li><li>Yoshua Bengio的《Practical Recommendations for Gradient-Based Training of Deep Architectures》。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转载自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit，原文为：http://cs231n.github.io/neural-networks-3/，并进行一定的修改。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit，原文为：http://cs231n.github.io/neural-networks-3/，并进行一定的修改。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="课程笔记" scheme="https://ilewseu.github.io/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="cs231n" scheme="https://ilewseu.github.io/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>CS231n课程笔记(7)  Neural Nets Notes 2</title>
    <link href="https://ilewseu.github.io/2017/12/12/CS231n%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E7%AC%AC7%E8%AF%BE-Neural-Nets-Notes-2/"/>
    <id>https://ilewseu.github.io/2017/12/12/CS231n课程笔记-第7课-Neural-Nets-Notes-2/</id>
    <published>2017-12-12T14:17:23.000Z</published>
    <updated>2017-12-16T16:06:55.660Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转自：<a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/neural-networks-2/" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/neural-networks-2/</a></p></blockquote><p><strong>目录</strong><br><a id="more"></a></p><ul><li>设置数据和模型<ul><li>数据预处理</li><li>权重初始化</li><li>批量归一化（Batch Normalization）</li><li>正则化（L1/L2/Maxnorm/Dropout）</li></ul></li><li>损失函数</li><li>小结</li></ul><h2 id="设置数据和模型"><a href="#设置数据和模型" class="headerlink" title="设置数据和模型"></a>设置数据和模型</h2><p>上一节中介绍了神经元的模型，它在计算内积后进行非线性激活函数计算，神经网络将这些神经元组织成各个层。这些做法共同定义了评分函数（score function）的新形式，该形式是从前面线性分类章节中的简单线性映射发展而来的。具体来说，神经网络就是进行了一系列的线性映射与非线性激活函数交织的运算。本节将讨论更多的算法设计选项，比如数据预处理，权重初始化和损失函数。</p><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>关于数据预处理我们有3个常用的符号，数据矩阵X，假设其尺寸是[N x D]（N是数据样本的数量，D是数据的维度）。</p><p><strong>均值减法（Mean Subtraction）</strong>:是预处理最常用的形式。它对数据中每个独立特征减去平均值，从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。在numpy中，该操作可以通过代码X-=np.mean(X,axis=0)实现。对于图像，更常用的是对所有像素都减去一个值，可以用X -= np.mean(X)实现，也可以在3个颜色通道上分别操作。</p><p><strong>归一化操作（Normalization）</strong>:是指将数据的所有维度都归一化，使其数值范围都近似相等。有两种常用方法可以实现归一化。第一种是先对数据做零中心化（zero-centered）处理，然后每个维度都除以其标准差，实现代码为X /= np.std(X, axis=0)。第二种方法是对每个维度都做归一化，使得每个维度的最大和最小值是1和-1。这个预处理操作只有在确信不同的输入特征有不同的数值范围（或计量单位）时才有意义，但要注意预处理操作的重要性几乎等同于学习算法本身。在图像处理中，由于像素的数值范围几乎是一致的（都在0-255之间），所以进行这个额外的预处理步骤并不是很必要。</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171207/4171gcBfCK.jpg?imageslim" alt="mark"><br></div><br>一般数据预处理流程：左边：原始的2维输入数据。中间：在每个维度上都减去平均值后得到零中心化数据，现在数据云是以原点为中心的。右边：每个维度都除以其标准差来调整其数值范围。红色的线指出了数据各维度的数值范围，在中间的零中心化数据的数值范围不同，但在右边归一化数据中数值范围相同。<br><strong>PCA和白化（Whitening）</strong>:是另一种数据预处理形式。在这种处理中，先对数据进行零中心化处理，然后计算协方差矩阵，它展示了数据中的相关性结构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 假设输入数据矩阵X的尺寸为[N x D]</span></div><div class="line">X -= np.mean(X, axis = <span class="number">0</span>) <span class="comment"># 对数据进行零中心化(重要)</span></div><div class="line">cov = np.dot(X.T, X) / X.shape[<span class="number">0</span>] <span class="comment"># 得到数据的协方差矩阵</span></div></pre></td></tr></table></figure><p>数据协方差矩阵的第(i, j)个元素是数据第i个和第j个维度的协方差。具体来说，该矩阵的对角线上的元素是方差。还有，协方差矩阵是对称和半正定的。我们可以对数据协方差矩阵进行SVD（奇异值分解）运算。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">U,S,V = np.linalg.svd(cov)</div></pre></td></tr></table></figure></p><p>U的列是特征向量，S是装有奇异值的1维数组（因为cov是对称且半正定的，所以S中元素是特征值的平方）。为了去除数据相关性，将已经零中心化处理过的原始数据投影到特征基准上：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Xrot = np.dot(X,U) <span class="comment"># 对数据去相关性</span></div></pre></td></tr></table></figure></p><p>注意U的列是标准正交向量的集合（范式为1，列之间标准正交），所以可以把它们看做标准正交基向量。因此，投影对应x中的数据的一个旋转，旋转产生的结果就是新的特征向量。如果计算Xrot的协方差矩阵，将会看到它是对角对称的。np.linalg.svd的一个良好性质是在它的返回值U中，特征向量是按照特征值的大小排列的。我们可以利用这个性质来对数据降维，只要使用前面的小部分特征向量，丢弃掉那些包含的数据没有方差的维度。 这个操作也被称为主成分分析（ Principal Component Analysis 简称PCA）降维：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Xrot_reduced = np.dot(X, U[:,:<span class="number">100</span>]) <span class="comment"># Xrot_reduced 变成 [N x 100]</span></div></pre></td></tr></table></figure></p><p>经过上面的操作，将原始的数据集的大小由[N x D]降到了[N x 100]，留下了数据中包含最大方差的100个维度。通常使用PCA降维过的数据训练线性分类器和神经网络会达到非常好的性能效果，同时还能节省时间和存储器空间。<br>最后一个在实践中会看见的变换是白化（whitening）。白化操作的输入是特征基准上的数据，然后对每个维度除以其特征值来对数值范围进行归一化。该变换的几何解释是：如果数据服从多变量的高斯分布，那么经过白化后，数据的分布将会是一个均值为零，且协方差相等的矩阵。该操作的代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对数据进行白化操作:</span></div><div class="line"><span class="comment"># 除以特征值 </span></div><div class="line">Xwhite = Xrot / np.sqrt(S + <span class="number">1e-5</span>)</div></pre></td></tr></table></figure></p><p>警告：夸大的噪声。注意分母中添加了1e-5（或一个更小的常量）来防止分母为0。该变换的一个缺陷是在变换的过程中可能会夸大数据中的噪声，这是因为它将所有维度都拉伸到相同的数值范围，这些维度中也包含了那些只有极少差异性(方差小)而大多是噪声的维度。在实际操作中，这个问题可以用更强的平滑来解决（例如：采用比1e-5更大的值）。</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171207/5iFjlf3GKE.jpg?imageslim" alt="mark"><br></div><br>PCA/白化。左边是二维的原始数据。中间：经过PCA操作的数据。可以看出数据首先是零中心的，然后变换到了数据协方差矩阵的基准轴上。这样就对数据进行了解相关（协方差矩阵变成对角阵）。右边：每个维度都被特征值调整数值范围，将数据协方差矩阵变为单位矩阵。从几何上看，就是对数据在各个方向上拉伸压缩，使之变成服从高斯分布的一个数据点分布。</p><p><strong>实践操作</strong>：在这个笔记中提到PCA和白化主要是为了介绍的完整性，实际上在卷积神经网络中并不会采用这些变换。然而对数据进行零中心化操作还是非常重要的，对每个像素进行归一化也很常见。</p><p><strong>常见错误</strong>：进行预处理很重要的一点是：任何预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。例如，如果先计算整个数据集图像的平均值然后每张图片都减去平均值，最后将整个数据集分成训练、验证、测试集，那么这个做法是错误的。<strong>应该怎么做呢？应该先分成训练、验证、测试集，只是从训练集中求图片平均值，然后各个集（训练、验证、测试集）中的图像再减去这个平均值。</strong></p><h2 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h2><p>我们已经看到如何构建一个神经网络的结构并对数据进行预处理，但是在开始训练网络之前，还需要初始化网络的参数。</p><p><strong>错误：全零初始化</strong>：让我们从应该避免的错误开始。在训练完毕后，虽然不知道网络中每个权重的最终值应该是多少，但如果数据经过了恰当的归一化的话，就可以假设所有权重数值中大约一半为正数，一半为负数。这样，一个听起来蛮合理的想法就是把这些权重的初始值都设为0吧，因为在期望上来说0是最合理的猜测。这个做法错误的！因为如果网络中的每个神经元都计算出同样的输出，然后它们就会在反向传播中计算出同样的梯度，从而进行同样的参数更新。换句话说，如果权重被初始化为同样的值，神经元之间就失去了不对称性的源头。</p><p><strong>小随机数初始化：</strong>因此，权重初始值要非常接近0又不能等于0。解决方法就是将权重初始化为很小的数值，以此来打破对称性。其思路是：如果神经元刚开始的时候是随机且不相等的，那么它们将计算出不同的更新，并将自身变成整个网络的不同部分。小随机数权重初始化的实现方法是：W = 0.01 * np.random.randn(D,H)。其中，randn函数是基于零均值和标准差的一个高斯分布来生成随机数的。根据这个式子，每个神经元的权重向量都被初始化为一个随机向量，而这些随机向量又服从一个多变量高斯分布，这样在输入空间中，所有的神经元的指向是随机的。也可以使用均匀分布生成的随机数，但是从实践结果来看，对于算法的结果影响极小。</p><p><strong>警告：</strong>并不是小数值一定会得到好的结果。例如，一个神经网络的层中的权重值很小，那么在反向传播的时候就会出现非常小的梯度（因为梯度与权重值是成比例的）。这就会很大程度上减小反向传播中的“梯度信号”，在深度网络中，就会出现问题。</p><p><strong>使用1/sqrt(n)校准方差</strong>，上面的做法存在一个问题，随着输入数据量的增长，随机初始化的神经元的输出数据的分布中的方差也在增大。我们可以除以输入数据量的平方根来调整其数值范围，这样神经元输出的方差就归一化到1了。也就是说，建议将神经元的权重向量初始化为：w = np.random.randn(n) / sqrt(n)。其中n是输入数据的数量。这样就保证了网络中所有神经元起始时有近似同样的输出分布。实践经验证明，这样做可以提高收敛的速度。<br>上述结论的推导过程如下：假设权重w和输入x之间的内积为$s=\sum^n_iw_ix_i$，这是还没有进行非线性激活函数运算之前的原始数值。我们可以检查s的方差：$$<br>Var(s)=Var(\sum_i^n w_ix_i)\\\\=\sum_i^nVar(w_ix_i)\\\\=\sum_i^n[E(w_i)]^2Var(x_i)+E[(x_i)]^2Var(w_i)+Var(xIi)Var(w_i)\\\\=\sum_i^nVar(x_i)Var(w_i)\\\\=(nVar(w))Var(x)<br>$$<br>在前两步，使用了方差的性质。在第三步，因为假设输入和权重的平均值都是0，所以$E[x_i]=E[w_i]=0$。注意这并不是一般化情况，比如在ReLU单元中均值就为正。在最后一步，我们假设所有的$w_i,x_i$都服从同样的分布。从这个推导过程我们可以看见，如果想要s有和输入x一样的方差，那么在初始化的时候必须保证每个权重w的方差是1/n。又因为对于一个随机变量X和标量a，有$Var(aX)=a^2Var(X)$，这就说明可以基于一个标准高斯分布，然后乘以$a=\sqrt{1/n}$，使其方差为1/n，于是得出：w = np.random.randn(n) / sqrt(n)。</p><p>Glorot等在论文Understanding the difficulty of training deep feedforward neural networks中作出了类似的分析。在论文中，作者推荐初始化公式为 $Var(w) = 2/(n_{in} + n_{out})$ ，其中$n_{in}, n_{out}$是在前一层和后一层中单元的个数。这是基于妥协和对反向传播中梯度的分析得出的结论。该主题下最新的一篇论文是：Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification，作者是He等人。文中给出了一种针对ReLU神经元的特殊初始化，并给出结论：网络中神经元的方差应该是2.0/n。代码为w = np.random.randn(n) * sqrt(2.0/n)。这个形式是神经网络算法使用ReLU神经元时的当前最佳推荐。</p><p><strong>稀疏初始化（Sparse initialization）</strong>:另一个处理非标定方差的方法就是将所有权重矩阵设为0，但是为了打破对称性，每个神经元都同下一层固定数目的神经元随机连接（其权重数值由一个小的高斯分布生成）。一个比较典型的连接数目是10个。</p><p><strong>偏置（biases）的初始化</strong>，通常将偏置初始化为0，这是因为随机小数值权重矩阵已经打破了对称性。对于ReLU非线性激活函数，有研究人员喜欢使用如0.01这样的小数值常量作为所有偏置的初始值，这是因为他们认为这样做能让所有的ReLU单元一开始就激活，这样就能保存并传播一些梯度。然而，这样做是不是总是能提高算法性能并不清楚（有时候实验结果反而显示性能更差），所以通常还是使用0来初始化偏置参数。</p><p><strong>实践</strong>，当前的推荐是使用ReLU激活函数，并且使用w = np.random.randn(n) * sqrt(2.0/n)来进行权重初始化。</p><p><strong>批量归一化（Batch Normalization）</strong>:批量归一化是loffe和Szegedy最近才提出的方法，该方法减轻了如何合理初始化神经网络这个棘手问题带来的头痛：）,其做法是让激活数据在训练开始前通过一个网络，网络处理数据使其服从标准高斯分布。因为归一化是一个简单可求导的操作，所以上述思路是可行的。在实现层面，应用这个技巧通常意味着全连接层与激活函数之间添加一个BatchNorm层。对于这个技巧本节不会展开讲，因为参考文献：<a href="https://arxiv.org/abs/1502.03167中已经讲得很清楚了，需要知道的是在神经网络中使用批量归一化已经变得非常常见。在实践中，使用了批量归一化的网络对于不好的初始值有更强的鲁棒性。最后一句话总结：批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起。搞定！" target="_blank" rel="external">https://arxiv.org/abs/1502.03167中已经讲得很清楚了，需要知道的是在神经网络中使用批量归一化已经变得非常常见。在实践中，使用了批量归一化的网络对于不好的初始值有更强的鲁棒性。最后一句话总结：批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起。搞定！</a></p><h2 id="正则化Regularization"><a href="#正则化Regularization" class="headerlink" title="正则化Regularization"></a>正则化Regularization</h2><p>有不少方法是通过控制神经网络的容量来防止其过拟合的：<br><strong>L2正则化</strong>可能是最常用的正则化方法了，可以通过惩罚目标函数中所有参数的平方将其实现。即对网络中的每个权重w，向目标函数中增加一个$\frac {1}{2}\lambda w^2$，其中$\lambda$是正则化强度。前面这个1/2很常见，是因为加上1/2后，该式子关于w梯度就是$\lambda w$而不是$2\lambda w$了，L2正则化可以直观理解为它对于大数值的权重向量进行严厉惩罚，倾向于更加分散的权重向量。在线性分类章节中讨论过，由于输入和权重之间的乘法操作，这样就有了一个优良的特性：使网络更倾向于使用所有输入特征，而不是严重依赖输入特征中某些小部分特征。最后需要注意在梯度下降和参数更新的时候，使用L2正则化意味着所有的权重都以w += -lambda * W向着0线性下降。</p><p>L1正则化是另一个相对常用的正则化方法。对于每个w我们都向目标函数增加一个\lambda|w|。L1和L2正则化也可以进行组合：$\lambda_1|w|+\lambda_2w^2$，这也被称作Elastic net regularizaton。L1正则化有一个有趣的性质，它会让权重向量在最优化的过程中变得稀疏（即非常接近0）。也就是说，使用L1正则化的神经元最后使用的是它们最重要的输入数据的稀疏子集，同时对于噪音输入则几乎是不变的了。相较L1正则化，L2正则化中的权重向量大多是分散的小数字。在实践中，如果不是特别关注某些明确的特征选择，一般说来L2正则化都会比L1正则化效果好。</p><p><strong>最大范式约束（Max norm constraints)</strong>,另一种形式的正则化是给每个神经元中权重向量的量级设定上限，并使用投影梯度下降来确保这一约束。在实践中，与之对应的是参数更新方式不变，然后要求神经元中的权重向量$\overrightarrow{w}$必须满足$||\overrightarrow{w}||_2&lt;c$这一条件，一般c值为3或者4。有研究者发文称在使用这种正则化方法时效果更好。这种正则化还有一个良好的性质，即使在学习率设置过高的时候，网络中也不会出现数值“爆炸”，这是因为它的参数更新始终是被限制着的。</p><p><strong>随机失活（Dropout）</strong>是一个简单又极其有效的正则化方法。该方法由Srivastava在论文Dropout: A Simple Way to Prevent Neural Networks from Overfitting中提出的，与L1正则化，L2正则化和最大范式约束等方法互为补充。在训练的时候，随机失活的实现方法是让神经元以超参数p的概率被激活或者被设置为0。</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171207/L8ekkFIBfC.jpg?imageslim" alt="mark"><br></div><br>图片来自于论文：<a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf。展示其核心思路，在训练过程中，随机失活可以被认为是对完整的神经网络抽样出一些子集，每次基于输入数据只更新子网络的参数（然而，数量巨大的子网络们并不是相对独立的，因为它们都共享参数）。在测试过程中不使用随机失活，可以理解为对数量巨大的子网们做了模型集成，以此来计算出一个平均的预测。" target="_blank" rel="external">http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf。展示其核心思路，在训练过程中，随机失活可以被认为是对完整的神经网络抽样出一些子集，每次基于输入数据只更新子网络的参数（然而，数量巨大的子网络们并不是相对独立的，因为它们都共享参数）。在测试过程中不使用随机失活，可以理解为对数量巨大的子网们做了模型集成，以此来计算出一个平均的预测。</a></p><p>一个3层神经网络的普通版随机失活可以用下面代码实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="string">""" 普通版随机失活: 不推荐实现 (看下面笔记) """</span></div><div class="line"></div><div class="line">p = <span class="number">0.5</span> <span class="comment"># 激活神经元的概率. p值更高 = 随机失活更弱</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(X)</span>:</span></div><div class="line">  <span class="string">""" X中是输入数据 """</span></div><div class="line">  </div><div class="line">  <span class="comment"># 3层neural network的前向传播</span></div><div class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</div><div class="line">  U1 = np.random.rand(*H1.shape) &lt; p <span class="comment"># 第一个随机失活遮罩</span></div><div class="line">  H1 *= U1 <span class="comment"># drop!</span></div><div class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</div><div class="line">  U2 = np.random.rand(*H2.shape) &lt; p <span class="comment"># 第二个随机失活遮罩</span></div><div class="line">  H2 *= U2 <span class="comment"># drop!</span></div><div class="line">  out = np.dot(W3, H2) + b3</div><div class="line">  </div><div class="line">  <span class="comment"># 反向传播:计算梯度... (略)</span></div><div class="line">  <span class="comment"># 进行参数更新... (略)</span></div><div class="line">  </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X)</span>:</span></div><div class="line">  <span class="comment"># 前向传播时模型集成</span></div><div class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) * p <span class="comment"># 注意：激活数据要乘以p</span></div><div class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2) * p <span class="comment"># 注意：激活数据要乘以p</span></div><div class="line">  out = np.dot(W3, H2) + b3</div></pre></td></tr></table></figure></p><p>在上面的代码中，train_step函数在第一个隐层和第二个隐层上进行了两次随机失活。在输入层上面进行随机失活也是可以的，为此需要为输入数据X创建一个二值的遮罩。反向传播保持不变，但是肯定需要将遮罩U1和U2加入进去。</p><p>注意：在predict函数中不进行随机失活，但是对于两个隐层的输出都要乘以p，调整其数值范围。这一点非常重要，因为在测试时所有的神经元都能看见它们的输入，因此我们想要神经元的输出与训练时的预期输出是一致的。以p=0.5为例，在测试时神经元必须把它们的输出减半，这是因为在训练的时候它们的输出只有一半。为了理解这点，先假设有一个神经元x的输出，那么进行随机失活的时候，该神经元的输出就是px+(1-p)0，这是有1-p的概率神经元的输出为0。在测试时神经元总是激活的，就必须调整$x\to px$来保持同样的预期输出。在测试时会在所有可能的二值遮罩（也就是数量庞大的所有子网络）中迭代并计算它们的协作预测，进行这种减弱的操作也可以认为是与之相关的。</p><p>上述操作不好的性质是必须在测试时对激活数据要按照p进行数值范围调整。既然测试性能如此关键，实际更倾向使用反向随机失活（inverted dropout），它是在训练时就进行数值范围调整，从而让前向传播在测试时保持不变。这样做还有一个好处，无论你决定是否使用随机失活，预测方法的代码可以保持不变。反向随机失活的代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="string">""" </span></div><div class="line"><span class="string">反向随机失活: 推荐实现方式.</span></div><div class="line"><span class="string">在训练的时候drop和调整数值范围，测试时不做任何事.</span></div><div class="line"><span class="string">"""</span></div><div class="line"></div><div class="line">p = <span class="number">0.5</span> <span class="comment"># 激活神经元的概率. p值更高 = 随机失活更弱</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(X)</span>:</span></div><div class="line">  <span class="comment"># 3层neural network的前向传播</span></div><div class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</div><div class="line">  U1 = (np.random.rand(*H1.shape) &lt; p) / p <span class="comment"># 第一个随机失活遮罩. 注意/p!</span></div><div class="line">  H1 *= U1 <span class="comment"># drop!</span></div><div class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</div><div class="line">  U2 = (np.random.rand(*H2.shape) &lt; p) / p <span class="comment"># 第二个随机失活遮罩. 注意/p!</span></div><div class="line">  H2 *= U2 <span class="comment"># drop!</span></div><div class="line">  out = np.dot(W3, H2) + b3</div><div class="line"></div><div class="line">  <span class="comment"># 反向传播:计算梯度... (略)</span></div><div class="line">  <span class="comment"># 进行参数更新... (略)</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X)</span>:</span></div><div class="line">  <span class="comment"># 前向传播时模型集成</span></div><div class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) <span class="comment"># 不用数值范围调整了</span></div><div class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</div><div class="line">  out = np.dot(W3, H2) + b3</div></pre></td></tr></table></figure></p><p>在随机失活发布后，很快有大量研究为什么它的实践效果如此之好，以及它和其他正则化方法之间的关系。如果你感兴趣，可以看看这些文献：</p><ul><li>Dropout paper by Srivastava et al. 2014.</li><li>Dropout Training as Adaptive Regularization：“我们认为：在使用费希尔信息矩阵（fisher information matrix）的对角逆矩阵的期望对特征进行数值范围调整后，再进行L2正则化这一操作，与随机失活正则化是一阶相等的。”</li></ul><p><strong>前向传播中的噪音：</strong>在更一般化的分类上，随机失活属于网络在前向传播中有随机行为的方法。测试时，通过分析法（在使用随机失活的本例中就是乘以p）或数值法（例如通过抽样出很多子网络，随机选择不同子网络进行前向传播，最后对它们取平均）将噪音边缘化。在这个方向上的另一个研究是DropConnect，它在前向传播的时候，一系列权重被随机设置为0。提前说一下，卷积神经网络同样会吸取这类方法的优点，比如随机汇合（stochastic pooling），分级汇合（fractional pooling），数据增长（data augmentation）。我们在后面会详细介绍。</p><p><strong>偏置正则化：</strong>在线性分类器的章节中介绍过，对于偏置参数的正则化并不常见，因为它们在矩阵乘法中和输入数据并不产生互动，所以并不需要控制其在数据维度上的效果。然而在实际应用中（使用了合理数据预处理的情况下），对偏置进行正则化也很少会导致算法性能变差。这可能是因为相较于权重参数，偏置参数实在太少，所以分类器需要它们来获得一个很好的数据损失，那么还是能够承受的。</p><p><strong>每层正则化：</strong>对于不同的层进行不同强度的正则化很少见（可能除了输出层以外），关于这个思路的相关文献也很少。</p><p><strong>实践</strong>：通过交叉验证获得一个全局使用的L2正则化强度是比较常见的。在使用L2正则化的同时在所有层后面使用随机失活也很常见。p值一般默认设为0.5，也可能在验证集上调参。</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>我们已经讨论过损失函数的正则化损失部分，它可以看做是对模型复杂程度的某种惩罚。损失函数的第二个部分时数据损失。它是一个有监督学习问题，用于衡量分类算法的预测结果（即分类评分）和真实标签结果之间的一致性。数据损失是对所有样本的数据损失求平均。也就是说，$L=\frac{1}{N}\sum_iL_i$中，N是训练集数据的样本数。让我们把神经网络中输出层的激活函数简写为f=f(x_i;W)，在实际中你可能需要解决以下几类问题：</p><p><strong>分类问题</strong>我们一直讨论的。在该问题中，假设有一个装满样本的数据集，每个样本都有一个唯一的正确标签（是固定分类标签之一）。在这类问题中，一个最常见的损失函数就是SVM（是Weston Watkins 公式）：<br>$$L_i=\sum_{j\not=y_i}max(0,f_j-f_{y_i}+1)$$<br>之前简要提起过，有些学者的论文中指出平方折叶损失（即使用max(0,f_j-f_{y_i}+1)^2）算法的结果会更好。第二个常用的损失函数是Softmax分类器，它使用交叉熵损失：<br>$$\displaystyle L_i=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})$$</p><p><strong>问题：类别数目巨大。</strong>当标签集非常庞大（例如字典中的所有英语单词，或者ImageNet中的22000种分类），就需要使用分层Softmax（Hierarchical Softmax）了（参考文献：<a href="https://arxiv.org/pdf/1310.4546.pdf）分层softmax将标签分解成一个树。每个标签都表示成这个树上的一个路径，这个树的每个节点处都训练一个Softmax分类器来在左和右分枝之间做决策。树的结构对于算法的最终结果影响很大，而且一般需要具体问题具体分析。" target="_blank" rel="external">https://arxiv.org/pdf/1310.4546.pdf）分层softmax将标签分解成一个树。每个标签都表示成这个树上的一个路径，这个树的每个节点处都训练一个Softmax分类器来在左和右分枝之间做决策。树的结构对于算法的最终结果影响很大，而且一般需要具体问题具体分析。</a></p><p><strong>属性（Attribute）分类。</strong>上面两个损失公式的前提，都是假设每个样本只有一个正确的标签y_i。但是如果y_i是一个二值向量，每个样本可能有，也可能没有某个属性，而且属性之间并不相互排斥呢？比如在Instagram上的图片，就可以看成是被一个巨大的标签集合中的某个子集打上标签，一张图片上可能有多个标签。在这种情况下，一个明智的方法是为每个属性创建一个独立的二分类的分类器。例如，针对每个分类的二分类器会采用下面的公式：$$<br>L_i=\sum_j max(0,1-y_{ij}f_j)<br>$$<br>上式中，求和是对所有分类j，$y_{ij}$的值为1或者-1，具体根据第i个样本是否被第j个属性打标签而定，当该类别被正确预测并展示的时候，分值向量$f_j$为正，其余情况为负。可以发现，当一个正样本的得分小于+1，或者一个负样本的得分大于-1的时候，算法就会累计损失值。</p><p>另一种方法是对每种属性训练一个独立的逻辑回归分类器，二分类的逻辑回归只有两个分类（0，1），其中对于分类1的概率计算为：<br>$$P(y=1|x;w,b) = \frac {1}{1+e^{-(w^Tx+b)}}=\sigma(w^Tx+b)$$因为类别0和类别1的概率和为1，所以类别0的概率为：$\displaystyle P(y=0|x;w,b)=1-P(y=1|x;w,b)$。这样，如果$\sigma(w^Tx+b)&gt;0.5$或者$w^Tx+b&gt;0$，那么样本就要被分类成为正样本（y=1）。然后损失函数最大化这个对数似然函数，问题可以简化为：$$<br>L_i = \sum_j y_{ij}log(\sigma(f_j)) + (1-y_{ij})log(1-\sigma(f_j))$$式中，假设标签$y_{ij}$非0即1，$\sigma(.)$就是sigmoid函数。上面的公式看起来吓人，但是f的梯度实际上非常简单：$\displaystyle \frac{\partial L_i}{\partial f_j}=y_{ij}-\sigma(f_j)$（你可以自己求导来验证）。</p><p><strong>回归问题</strong>是预测实数的值的问题，比如房价预测，预测图片中某个东西的长度等等。对于这种问题，通常是计算预测值和真实值之间的损失。然后用L2或者L1范数度量差异。对于某个样本，L2范数计算如下：$$L_i=||f-y_i||_2^2<br>$$<br>之所以在目标函数中要进行平方，是因为梯度算起来更加简单。因为平方是一个单调运算，所以不用改变最优参数。L1范式则是要将每个维度上的绝对值加起来：$$<br>L_i = ||f - y_i||_1=\sum_j|f_j - (y_i)j|<br>$$<br>在上式中，如果有多个数量被预测了，就要对预测的所有维度的预测求和，即$\sum_j$。观察第i个样本的第j维，用$\delta_{ij}$表示预测值与真实值之间的差异。关于该维度的梯度（也就是$\partial L_i/\partial f_j）$能够轻松地通过被求导为L2范式的$\delta_{ij}$或$sign(\delta_{ij})$。这就是说，评分值的梯度要么与误差中的差值直接成比例，要么是固定的并从差值中继承sign。</p><p>注意：L2损失比起较为稳定的Softmax损失来，其最优化过程要困难很多。直观而言，它需要网络具备一个特别的性质，即对于每个输入（和增量）都要输出一个确切的正确值。而在Softmax中就不是这样，每个评分的准确值并不是那么重要：只有当它们量级适当的时候，才有意义。还有，L2损失鲁棒性不好，因为异常值可以导致很大的梯度。所以在面对一个回归问题时，先考虑将输出变成二值化是否真的不够用。例如，如果对一个产品的星级进行预测，使用5个独立的分类器来对1-5星进行打分的效果一般比使用一个回归损失要好很多。分类还有一个额外优点，就是能给出关于回归的输出的分布，而不是一个简单的毫无把握的输出值。如果确信分类不适用，那么使用L2损失吧，但是一定要谨慎：L2非常脆弱，在网络中使用随机失活（尤其是在L2损失层的上一层）不是好主意。</p><blockquote><p>当面对一个回归任务，首先考虑是不是必须这样。一般而言，尽量把你的输出变成二分类，然后对它们进行分类，从而变成一个分类问题。</p></blockquote><p><strong>结构化预测（structured prediction）</strong>,结构化损失是指标签可以是任意的结构，例如图表、树或者其他复杂物体的情况。通常这种情况还会假设结构空间非常巨大，不容易进行遍历。结构化SVM背后的基本思想就是在正确的结构y_i和得分最高的非正确结构之间画出一个边界。解决这类问题，并不是像解决一个简单无限制的最优化问题那样使用梯度下降就可以了，而是需要设计一些特殊的解决方案，这样可以有效利用对于结构空间的特殊简化假设。我们简要地提一下这个问题，但是详细内容就超出本课程范围。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>推荐的预处理操作是对数据的每个特征都进行零中心化，然后将其数值范围都归一化到[-1,1]范围之内。</li><li>使用标准差为\sqrt{2/n}的高斯分布来初始化权重，其中n是输入的神经元数。例如用numpy可以写作：w = np.random.randn(n) * sqrt(2.0/n)。</li><li>使用L2正则化和随机失活的倒置版本。</li><li>使用批量归一化。</li><li>讨论了在实践中可能要面对的不同任务，以及每个任务对应的常用损失函数。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/neural-networks-2/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/neural-networks-2/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="课程笔记" scheme="https://ilewseu.github.io/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="cs231n" scheme="https://ilewseu.github.io/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>CS231n课程笔记(6)  Neural Nets Notes 1</title>
    <link href="https://ilewseu.github.io/2017/12/10/CS231n%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E7%AC%AC6%E8%AF%BE-Neural-Nets-Notes-1/"/>
    <id>https://ilewseu.github.io/2017/12/10/CS231n课程笔记-第6课-Neural-Nets-Notes-1/</id>
    <published>2017-12-10T14:17:23.000Z</published>
    <updated>2017-12-16T16:06:37.837Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转自：<a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/neural-networks-1/" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/neural-networks-1/</a></p></blockquote><p><strong>目录</strong></p><ul><li>简介<a id="more"></a></li><li>单个神经元建模<ul><li>生物动机和连接</li><li>作为线性分类器的单个神经元</li><li>常用的激活函数</li></ul></li><li>神经网络结构<ul><li>层组织</li><li>前向传播计算例子</li><li>表达能力</li><li>设置层的数量和尺寸</li></ul></li><li>小结</li></ul><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在线性分类一节中，在给出图像的情况下，使用$s=Wx$来计算不同视觉类别的评分，其中W是一个矩阵，x是一个输入列向量，它包含了图像的全部像素数据。在使用数据库CIFAR-10的案例中，x是一个[3072<em>1]的列向量，W是一个[10</em>3072]的矩阵，所有输出的评分是一个包含10个类别评分的向量。<br>神经网络算法则不同，它的计算公式是$s=W_2max(0,W_1x)$。其中$W_1$的含义是这样的：举个例子来说，它可以是一个[100*3072]的矩阵，其作用是将图像转化为一个100维的过渡向量。函数max(0,-)是非线性的，它会作用到每个元素。这个非线性函数有多种选择，后续将会学到。但这个形式是一个最常用的选择，它就是简单地设置阈值，将所有小于0的值变成0。最终，矩阵$W_2$的尺寸是[10x100]，因此将得到10个数字，这10个数字可以解释为是分类的评分。注意非线性函数在计算上是至关重要的，如果略去这一步，那么两个矩阵将会合二为一，对于分类的评分计算将重新变成关于输入的线性函数。这个非线性函数就是改变的关键点。参数$W_1$,$W_2$将通过随机梯度下降来学习到，他们的梯度在反向传播过程中，通过链式法则来求导计算得出。</p><p>一个三层的神经网络可以类比地看做$s=W_3max(0,W_2max(0,W_1x))$，其中$W_1$,$W_2$,$W_3$是需要进行学习的参数。中间隐层的尺寸是网络的超参数，后续将学习如何设置它们。现在让我们先从神经元或者网络的角度理解上述计算。</p><h2 id="单个神经元建模"><a href="#单个神经元建模" class="headerlink" title="单个神经元建模"></a>单个神经元建模</h2><p>神经网络算法领域最初是对生物神经系统建模这一目标启发，但随后与其分道扬镳，成为一个工程问题，并在机器学习领域取得良好的效果。然而，讨论将还是从对生物系统的一个高层次的简要描述开始，因为神经网络毕竟是从这里得到了启发。</p><h3 id="生物动机与连接"><a href="#生物动机与连接" class="headerlink" title="生物动机与连接"></a>生物动机与连接</h3><p>大脑的基本计算单位是神经元（neuron）。人类的神经系统中大约有860亿个神经元，它们被大约10^14-10^15个突触（synapses）连接起来。下面图表的左边展示了一个生物学的神经元，右边展示了一个常用的数学模型。每个神经元都从它的树突获得输入信号，然后沿着它唯一的轴突（axon）产生输出信号。轴突在末端会逐渐分枝，通过突触和其他神经元的树突相连。</p><p><div align="center"><br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/171205/EK18LFI9dh.jpg?imageslim" alt="mark"><br></div><br>在神经元的计算模型中，沿着轴突传播信号（比如将$x_0$）将基于突触的突触强度（比如$w_0$）<br>，与其他神经元的树突进行乘法交互（比如$w_0x_0$）。其观点是，突触的强度（也就是权重w），是可学习的且可以控制一个神经元对于另一个神经元的影响强度（还可以控制影响方向：使其兴奋（正权重）或使其抑制（负权重））。在基本模型中，树突将信号传递到细胞体，信号在细胞体中相加。如果最终之和高于某个阈值，那么神经元将会激活，向其轴突输出一个峰值信号。在计算模型中，我们假设峰值信号的准确时间点不重要，是激活信号的频率在交流信息。基于这个速率编码的观点，将神经元的激活率建模为激活函数（activation function）f，它表达了轴突上激活信号的频率。由于历史原因，激活函数常常选择使用sigmoid函数$\sigma$，该函数输入实数值（求和后的信号强度），然后将输入值压缩到0-1之间。在本节后面部分会看到这些激活函数的各种细节。<br>一个神经元前向传播的实例代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Neuron</span><span class="params">(object)</span>:</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(inputs)</span>:</span></div><div class="line">    <span class="string">""" 假设输入和权重是1-D的numpy数组，偏差是一个数字 """</span></div><div class="line">    cell_body_sum = np.sum(inputs * self.weights) + self.bias</div><div class="line">    firing_rate = <span class="number">1.0</span> / (<span class="number">1.0</span> + math.exp(-cell_body_sum)) <span class="comment"># sigmoid激活函数</span></div><div class="line">    <span class="keyword">return</span> firing_rate</div></pre></td></tr></table></figure></p><p>换句话说，每个神经元都对它的输入和权重进行点积，然后加上偏差，最后使用非线性函数（或称为激活函数）。本例中使用的是sigmoid函数$\sigma(x)=1/(1+e^{-x})$。在本节的末尾部分将介绍不同激活函数的细节。</p><h3 id="作为线性分类器的单个神经元"><a href="#作为线性分类器的单个神经元" class="headerlink" title="作为线性分类器的单个神经元"></a>作为线性分类器的单个神经元</h3><p>神经元模型的前向计算数学公式看起来可能比较眼熟。就像在线性分类器中看到的那样，神经元有能力”喜欢”（激活函数值接近1），或者不喜欢（激活函数值接近0）输入空间中的某些线性区域。因此，只要在神经元的输出端有一个合适的损失函数，就能让单个神经元变成一个线性分类器。</p><p><strong>二分类Softmax分类器</strong>，举例来说，可以把$\sigma(\sum_i w_ib_i+b)$看做其中一个分类的概率$P(y_i=1|x_i;w)$，其他分类的概率为$P(y_i=0|x_i;w)=1-P(y_i=1|x_i;w)$，因为它们加起来必须为1。根据这种理解，可以得到交叉熵损失，这个在线性分一节中已经介绍。然后将它最优化为二分类的Softmax分类器（也就是逻辑回归）。因为sigmoid函数输出限定在0-1之间，所以分类器做出预测的基准是神经元的输出是否大于0.5。</p><p><strong>二分类SVM分类器</strong>，或者可以在神经元的输出外增加一个最大边界折叶损失（max-margin hinge loss）函数，将其训练成一个二分类的支持向量机。</p><blockquote><p>一个单独的神经元可以用来实现一个二分类器，比如二分类的Softmax或者SVM分类器。</p></blockquote><h2 id="常用的激活函数"><a href="#常用的激活函数" class="headerlink" title="常用的激活函数"></a>常用的激活函数</h2><p>每个激活函数（或非线性函数）的输入都是一个数字，然后对其进行某种固定的数学操作。下面是在实践中可能遇到的几种激活函数：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171205/d62HBm98JC.jpg?imageslim" alt="mark"><br></div><br>左边是Sigmoid非线性函数，将实数压缩到[0,1]之间。右边是tanh函数，将实数压缩到[-1,1]。</p><p><strong>Sigmoid函数</strong><br>Sigmoid非线性函数的数学公式是$\sigma(x) = \frac {1}{1+e^{-x}}$，函数图像如上图的左边所示。在前面一节中已经提到，它输入实数值，并将其“挤压”到0到1范围内。更具体的说很大的负数变成0，很大的正数变成1。在历史上，sigmoid函数非常常用，这是因为它对于神经元的激活频率有良好的解释：从完全不激活(0)到在求和后的最大频率处的完全饱和的激活（1）。然而，现在sigmoid函数已经不太受欢迎，实际很少使用了，这是因为它有两个主要缺点：</p><ul><li><strong>Sigmoid函数饱和使梯度消失</strong>：Sigmoid神经元有一个不好的特性，就是当神经元的激活在接近0或1处时会饱和：在这些区域，梯度几乎为0。回忆一下，在反向传播的时候，这个（局部）梯度将会与整个损失函数关于该门单元输出的梯度相乘。因此，如果局部梯度非常小，那么相乘的结果也会接近零，这会有效地“杀死”梯度，几乎就有没有信号通过神经元传到权重再到数据了。还有，为了防止饱和，必须对于权重矩阵初始化特别留意。比如，如果初始化权重过大，那么大多数神经元将会饱和，导致网络就几乎不学习了。</li><li><strong>Sigmoid函数的输出不是零中心的：</strong>这个性质并不是我们想要的，因为在神经网络后面层中的神经元得到的数据将不是零中心的。这一情况将影响梯度下降的运作，因为如果输入神经元的数据总是正数（比如在$f=w^Tx+b$中每个元素都x&gt;0），那么关于w的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数（具体依整个表达式f而定）。这将会导致梯度下降权重更新时出现z字型的下降。然而，可以看到整个批量的数据的梯度被加起来后，对于权重的最终更新将会有不同的正负，这样就从一定程度上减轻了这个问题。因此，该问题相对于上面的神经元饱和问题来说只是个小麻烦，没有那么严重。</li></ul><p><strong>Tanh函数</strong><br>Tanh函数图像如上图右边所示。它将实数值压缩到[-1,1]之间。和Sigmoid神经元一样，它也存在饱和的问题，但是和sigmoid神经元不同的是，它的输出是零中心的。因此，在实际操作中，tanh非线性函数比sigmoid非线性函数更受欢迎。注意tanh神经元是一个简单放大的sigmoid神经元，具体说来就是：$tanh(x)=2\sigma(2x)-1$。</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171206/FFaKj6dLAf.jpg?imageslim" alt="mark"><br></div><br>左边是ReLU（校正线性单元：Rectified Linear Unit）激活函数，当x=0时函数值为0。当x&gt;0函数的斜率为1。右边是从Krizhevsky等的论文中截取的图表，指明使用ReLU比使用tanh的收敛快6倍。</p><p><strong>ReLU</strong>:在近些年ReLU变得非常流行。它的函数公式是$f(x)=max(0,x)$。换句话说，这个激活函数就是一个关于0的阈值。使用Relu有以下一些优缺点：</p><ul><li>优点：相较于Sigmoid和Tanh函数，ReLU对于随机梯度下降的收敛有巨大的加速作用。据称这是由它的线性，非饱和的公式导致的。</li><li>优点：Sigmoid和Tanh神经元含有指数运算等耗费计算资源的操作，而Relu可以简单地对一个矩阵进行阈值计算得到。</li><li>缺点：在训练的时候，ReLU单元比较脆弱并且可能“死掉”。举例来说，当一个很大的梯度流过ReLU的神经元的时候，可能会导致梯度更新到一种特别的状态，在这种状态下神经元将无法被其他任何数据点再次激活。如果这种情况发生，那么从此所以流过这个神经元的梯度将都变成0。也就是说，这个ReLU单元在训练中将不可逆转的死亡，因为这导致了数据多样化的丢失。例如，如果学习率设置得太高，可能会发现网络中40%的神经元都会死掉（在整个训练集中这些神经元都不会被激活）。通过合理设置学习率，这种情况的发生概率会降低。</li></ul><p><strong>Leaky ReLU:</strong>Leaky ReLU是为解决“ReLU死亡”问题的尝试。ReLU中当x<0时，函数值为0。而leaky relu则是给出一个很小的负数梯度值，比如0.01。所以其函数公式为$f(x)="1(x<0)(\alpha" x)+1(x="">=0)(x)$其中$\alpha$是一个小的常量。有些研究者的论文指出这个激活函数表现很不错，但是其效果并不是很稳定。</0时，函数值为0。而leaky></p><p><strong>Maxout</strong>:一些其他类型的单元被提了出来，它们对于权重和数据的内积结果不再使用$f(w^Tx+b)$函数形式。一个相关的流行选择是Maxout（最近由Goodfellow等发布）神经元。Maxout是对ReLU和leaky ReLU的一般化归纳，它的函数是：$max(w^T_1x+b_1,w^T_2x+b_2)$。ReLU和Leaky ReLU都是这个公式的特殊情况（比如ReLU就是当$w_1,b_1=0$的时候）。这样Maxout神经元就拥有ReLU单元的所有优点（线性操作和不饱和），而没有它的缺点（死亡的ReLU单元）。然而和ReLU对比，它每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。</p><p>以上就是一些常用的神经元及其激活函数。最后需要注意一点：在同一个网络中混合使用不同类型的神经元是非常少见的，虽然没有什么根本性问题来禁止这样做。</p><p><strong>一句话</strong>：“那么该用那种呢？”用ReLU非线性函数。注意设置好学习率，或许可以监控你的网络中死亡的神经元占的比例。如果单元死亡问题困扰你，就试试Leaky ReLU或者Maxout，不要再用sigmoid了。也可以试试tanh，但是其效果应该不如ReLU或者Maxout。</p><h2 id="神经网络结构"><a href="#神经网络结构" class="headerlink" title="神经网络结构"></a>神经网络结构</h2><h3 id="灵活地组织层"><a href="#灵活地组织层" class="headerlink" title="灵活地组织层"></a>灵活地组织层</h3><p><strong>将神经网络算法以神经元的形式图形化</strong>。神经网络被建模成神经元的集合，神经元之间以无环图的形式进行连接。也就是说，一些神经元的输出是另一些神经元的输入。在网络中是不允许循环的，因为这样会导致前向传播的无限循环。通常神经网络模型中神经元是分层的，而不是像生物神经元一样聚合成大小不一的团状。对于普通神经网络，最普通的层的类型是全连接层（fully-connected layer）。全连接层中的神经元与其前后两层的神经元是完全成对连接的，但是在同一个全连接层内的神经元之间没有连接。下面是两个神经网络的图例，都使用的全连接层：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171206/7bhbD6c9F0.jpg?imageslim" alt="mark"><br></div><br>左边是一个2层神经网络，隐层由4个神经元（也可称为单元（unit））组成，输出层由2个神经元组成，输入层是3个神经元。右边是一个3层神经网络，两个含4个神经元的隐层。注意：层与层之间的神经元是全连接的，但是层内的神经元不连接。<br><strong>命名规则</strong>：当我们说N层神经网络的时候，我们没有把输入层算入。因此，单层的神经网络就是没有隐层的（输入直接映射到输出）。因此，有的研究者会说LR或者SVM只是单层神经网络的一个特例。研究者们也会使用人工神经网络或者多层感知器来指代神经网络。很多研究者并不喜欢神经网络算法和人类大脑之间的类比，它们更倾向于用单元(unit)而不是神经元作为术语。<br><strong>输出层</strong>：和神经网络中其他层不同，输出层的神经元一般是不会有激活函数的（或者也可以认为它们有一个线性相等的激活函数）。这是因为最后的输出层大多用于表示分类评分值，因此是任意值的实数，或者某种实数值的目标数（比如在回归中）。<br><strong>确定网络尺寸：</strong>用来度量神经网络的尺寸的标准主要有两个：一个是神经元的个数，另一个是参数的个数，用上面图示的两个网络举例：</p><ul><li>第一个网络有4+2=6个神经元（输入层不算），[3x4]+[4x2]=20个权重，还有4+2=6个偏置，共26个可学习的参数。</li><li>第二个网络有4+4+1=9个神经元，[3x4]+[4x4]+[4x1]=32个权重，4+4+1=9个偏置，共41个可学习的参数。</li></ul><p>为了方便对比，现代卷积神经网络能包含约1亿个参数，可由10-20层构成（这就是深度学习）。然而，有效（effective）连接的个数因为参数共享的缘故大大增多。在后面的卷积神经网络内容中我们将学习更多。</p><h2 id="前向传播计算举例"><a href="#前向传播计算举例" class="headerlink" title="前向传播计算举例"></a>前向传播计算举例</h2><p>不断重复的矩阵乘法与激活函数交织。将神经网络组织成层状的一个主要原因，就是这个结构让神经网络算法使用矩阵向量操作变得简单和高效。用上面用上面那个3层神经网络举例，输入是[3x1]的向量。一个层所有连接的强度可以存在一个单独的矩阵中。比如第一个隐层的权重W1是[4x3]，所有单元的偏置储存在b1中，尺寸[4x1]这样，每个神经元的权重都在W1的一个行中，于是矩阵乘法np.dot(W1, x)就能计算该层中所有神经元的激活数据。类似的，W2将会是[4x4]矩阵，存储着第二个隐层的连接，W3是[1x4]的矩阵，用于输出层。完整的3层神经网络的前向传播就是简单的3次矩阵乘法，其中交织着激活函数的应用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 一个3层神经网络的前向传播:</span></div><div class="line">f = <span class="keyword">lambda</span> x: <span class="number">1.0</span>/(<span class="number">1.0</span> + np.exp(-x)) <span class="comment"># 激活函数(用的sigmoid)</span></div><div class="line">x = np.random.randn(<span class="number">3</span>, <span class="number">1</span>) <span class="comment"># 含3个数字的随机输入向量(3x1)</span></div><div class="line">h1 = f(np.dot(W1, x) + b1) <span class="comment"># 计算第一个隐层的激活数据(4x1)</span></div><div class="line">h2 = f(np.dot(W2, h1) + b2) <span class="comment"># 计算第二个隐层的激活数据(4x1)</span></div><div class="line">out = np.dot(W3, h2) + b3 <span class="comment"># 神经元输出(1x1)</span></div></pre></td></tr></table></figure></p><p>在上面的代码中，W1，W2，W3，b1，b2，b3都是网络中可以学习的参数。注意x并不是一个单独的列向量，而可以是一个批量的训练数据（其中每个输入样本将会是x中的一列），所有的样本将会被并行化的高效计算出来。注意神经网络最后一层通常是没有激活函数的（例如，在分类任务中它给出一个实数值的分类评分）。</p><blockquote><p>全连接层的前向传播一般就是先进行一个矩阵乘法，然后加上偏置并运用激活函数。</p></blockquote><h2 id="表达能力"><a href="#表达能力" class="headerlink" title="表达能力"></a>表达能力</h2><p>理解具有全连接层的神经网络的一个方式是：可以认为它们定义了一个由一系列函数组成的函数族，网络的权重就是每个函数的参数。如此产生的问题是：该函数族的表达能力如何？存在不能被神经网络表达的函数吗？</p><p>现在看来，拥有至少一个隐层的神经网络是一个通用的近似器。在研究（例如1989年的论文Approximation by Superpositions of Sigmoidal Function，或者Michael Nielsen的这个直观解释。）中已经证明，给出任意连续函数f(x)和任意$\epsilon &gt;0$，均存在一个至少含1个隐层的神经网络g(x)（并且网络中有合理选择的非线性激活函数，比如sigmoid，对于$\forall x$，使得$|f(x)-g(x)|&lt;\epsilon$。换句话说，<strong>神经网络可以近似任何连续函数。</strong></p><p><strong>既然一个隐层就能近似任何函数，那为什么还要构建更多层来将网络做得更深？</strong></p><p>答案是：虽然一个2层网络在数学理论上能完美地近似所有连续函数，但在实际操作中效果相对较差。在一个维度上，虽然以a,b,c为参数向量“指示块之和”函数$g(x)=\sum_ic_i1(a_i&lt;x&lt;b_i)$ 也是通用的近似器，但是谁也不会建议在机器学习中使用这个函数公式。神经网络在实践中非常好用，是因为它们表达出的函数不仅平滑，而且对于数据的统计特性有很好的拟合。同时，网络通过最优化算法（例如梯度下降）能比较容易地学习到这个函数。类似的，虽然在理论上深层网络（使用了多个隐层）和单层网络的表达能力是一样的，但是就实践经验而言，深度网络效果比单层网络好。</p><p>另外，在实践中3层的神经网络会比2层的表现好，然而继续加深（做到4，5，6层）很少有太大帮助。卷积神经网络的情况却不同，在卷积神经网络中，对于一个良好的识别系统来说，深度是一个极端重要的因素（比如数十(以10为量级)个可学习的层）。对于该现象的一种解释观点是：因为图像拥有层次化结构（比如脸是由眼睛等组成，眼睛又是由边缘组成），所以多层处理对于这种数据就有直观意义。</p><h2 id="设置层的数量和尺寸"><a href="#设置层的数量和尺寸" class="headerlink" title="设置层的数量和尺寸"></a>设置层的数量和尺寸</h2><p>在面对一个具体问题的时候该确定网络结构呢？到底是不用隐层呢？还是一个隐层？两个隐层或更多？每个层的尺寸该多大？</p><p>首先，要知道当我们增加层的数量和尺寸时，网络容量上升了。即神经元们可以合作表达许多复杂的函数，所以表达函数的空间增加。例如，如果有一个在二维平面上的二分类问题，我们可以训练3个不同的神经网络，每个网络都只有一个隐藏层，但是每层的神经元数目不同：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171206/ik4JL8K3l1.jpg?imageslim" alt="mark"><br></div><br>数据是用不同颜色的圆点表示他们的不同类别，决策边界是由训练过的神经网络做出的。</p><p>在上图中，可以看见有更多神经元的神经网络可以表达更复杂的函数。然而，这既是优势也是不足，优势是可以分类更复杂的数据，不足是可能造成对训练数据的过拟合。过拟合是网络对数据中的噪音有很强的拟合能力，而没有重视数据间（假设）的潜在基本关系。举例来说，有20个神经元隐层的网络拟合了所有的训练数据，但是其代价是把决策边界变成了许多不相连的红绿区域。而有3个神经元的模型的表达能力只能用比较宽泛的方式去分类数据。它将数据看做是两个大块，并把个别在绿色区域内的红色点看做噪声。在实际中，这样可以在测试数据中获得更好的泛化（generalization）能力。</p><p>基于上面的讨论，看起来如果数据不是足够复杂，则似乎小一点的网络更好，因为可以防止过拟合。然而并非如此，防止神经网络的过拟合有很多方法（L2正则化，dropout和输入噪音等），后面会详细讨论。在实践中，使用这些方法来控制过拟合比减少网络神经元数目要好得多。</p><p>不要减少网络神经元的数目的主要原因<strong>在于小网络更难使用梯度下降等局部方法来进行训练。</strong>虽然小型网络的损失函数的局部极小值更少，也比较容易收敛到这些局部极小值，但是这些最小值一般都很差，损失值很高。相反，大网络拥有更多的局部极小值，但就实际损失值来看，这些局部极小值表现更好，损失更小。因为神经网络是非凸的，就很难从数学上研究这些特性。即便如此，还是有一些文章尝试对这些目标函数进行理解，例如The Loss Surfaces of Multilayer Networks这篇论文。在实际中，你将发现如果训练的是一个小网络，那么最终的损失值将展现出多变性：某些情况下运气好会收敛到一个好的地方，某些情况下就收敛到一个不好的极值。从另一方面来说，如果你训练一个大的网络，你将发现许多不同的解决方法，但是最终损失值的差异将会小很多。这就是说，所有的解决办法都差不多，而且对于随机初始化参数好坏的依赖也会小很多。<br>重申一下，<strong>正则化强度是控制神经网络过拟合的好方法</strong>。看下图结果：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171206/08eJ9cAAKD.jpg?imageslim" alt="mark"><br></div><br>不同正则化强度的效果：每个神经网络都有20个隐层神经元，但是随着正则化强度增加，它的决策边界变得更加平滑。</p><p><strong>需要记住的是：不应该因为害怕出现过拟合而使用小网络。相反，应该尽可能使用大网络，然后使用正则化技术来控制过拟合。</strong></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本节课主要介绍如下内容：</p><ul><li>介绍了生物神经元的粗略模型；</li><li>讨论了几种不同类型的激活函数，其中ReLU是最佳推荐；</li><li>介绍了神经网络，神经元通过全连接层连接，层间神经元两两相连，但是层内神经元不连接；</li><li>理解了分层的结构能够让神经网络高效地进行矩阵乘法和激活函数运算；</li><li>理解了神经网络是一个通用函数近似器，但是该性质与其广泛使用无太大关系。之所以使用神经网络，是因为它们对于实际问题中的函数的公式能够某种程度上做出“正确”假设。</li><li>讨论了更大网络总是更好的这一事实。然而更大容量的模型一定要和更强的正则化（比如更高的权重衰减）配合，否则它们就会过拟合。在后续章节中我们讲学习更多正则化的方法，尤其是dropout。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>使用Theano的deeplearning.net tutorial:<a href="http://www.deeplearning.net/tutorial/mlp.html" target="_blank" rel="external">http://www.deeplearning.net/tutorial/mlp.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/neural-networks-1/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/neural-networks-1/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;简介
    
    </summary>
    
      <category term="课程笔记" scheme="https://ilewseu.github.io/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="cs231n" scheme="https://ilewseu.github.io/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>CS231n课程笔记(5)  Backprop Note</title>
    <link href="https://ilewseu.github.io/2017/12/09/CS231n%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E7%AC%AC5%E8%AF%BE-Backprop-Note/"/>
    <id>https://ilewseu.github.io/2017/12/09/CS231n课程笔记-第5课-Backprop-Note/</id>
    <published>2017-12-09T14:17:23.000Z</published>
    <updated>2017-12-16T16:06:23.168Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转自：<a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/optimization-2/" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/optimization-2/</a></p></blockquote><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>目的</strong>:本节帮助读者对<strong>反向传播</strong>形成直观而专业的理解。反向传播是利用链式法则递归计算梯度的方法。理解反向传播过程及其精妙之处，对于理解、实现、设计和调试神经网络非常关键。<br><a id="more"></a><br><strong>问题描述</strong>：核心问题是：给定函数f(x),其中x是输入数据向量，需要计算函数f关于x的梯度，也就是$\nabla f(x)$</p><p><strong>原因</strong>：之所以关注上述问题，是因为在神经网络中f对应的是损失函数L，输入x里面包含训练数据和神经网络权重。举个例子，损失函数可以是SVM的损失函数，输入则包含了训练数据$(x_i,y_i),i=1,…N$，权重W和偏差b。给定训练数据，权重是可以控制的变量。因此，即使使用反向传播计算输入数据$x_i$上的梯度，但在实践上为了进行参数更新，通常也只计算参数(W和b)的梯度。然而$x_i$<br> 的梯度有时仍然是有用的：比如将神经网络所做的事情可视化便于直观理解的时候，就能用上。</p><h2 id="梯度的简单表达、解释"><a href="#梯度的简单表达、解释" class="headerlink" title="梯度的简单表达、解释"></a>梯度的简单表达、解释</h2><p>首先，考虑一个简单的二元函数f(x,y)=xy。对两个输入变量分别求偏导数，能够很简单求出：$$<br>f(x,y)=xy \rightarrow \frac {df}{dx}=y \frac {df}{dy}=x$$<br><strong>解释：</strong>要牢记导数的意义：函数变量在某个点周围的极小区域内变化，而导数就是变量变化导致的函数在该方向上的变化率。$$<br>\frac {df(x)}{dx} = \lim_{h\rightarrow0} \frac {f(x+h)-f(x)}{h}$$<strong>对于上述公式，当h的值非常小时，函数可以被一条直线近似，而导数就是这条直线的斜率。</strong>换句话说，每个变量的导数指明了整个表达式对于该变量的值的敏感程度。例如，若x=4,y=-3，则f(x,y)=-12,x的导数$\frac {\partial f}{\partial x}=-3$，这就说明将变量x的值变大一点，整个表达式的值就会变小，而且变小的量是x变大的量的三倍。</p><p>如上所述，梯度$\nabla f$是偏导数的向量，所以有$\nabla f(x)=[\frac {\partial f}{\partial x},\frac {\partial f}{\partial y}] = [y,x]$。我们可以对加法操作进行求导：$$f(x,y)=x+y \rightarrow \frac {df}{dx}=1 \frac {df}{dy}=1$$这就是说，无论其值如何，x,y的导数均为1。这是有道理的，因为无论增加x,y中任一个的值，函数f的值都会增加，并且增加的变化率独立于x,y的具体值（情况和乘法操作不同）。取最大值操作也是常常使用的：$$<br>f(x,y)=max(x,y)\rightarrow \frac {df}{dx}=1(x&gt;=y) \frac {df}{dy}=1(y&gt;=x)$$上式是说，如果该变量比另一个变量大，那么梯度是1，反之为0。例如，若x=4,y=2，那么max是4，所以函数对于y就不敏感。也就是说，在y上增加h，函数还是输出为4，所以梯度是0：因为对于函数输出是没有效果的。当然，如果给y增加一个很大的量，比如大于2，那么函数f的值就变化了，但是导数并没有指明输入量有巨大变化情况对于函数的效果，他们只适用于输入量变化极小时的情况，因为定义已经指明：$lim_{h\to 0}$。</p><h2 id="使用链式法则计算复杂表达式的导数"><a href="#使用链式法则计算复杂表达式的导数" class="headerlink" title="使用链式法则计算复杂表达式的导数"></a>使用链式法则计算复杂表达式的导数</h2><p>现在考虑更复杂的包含多个函数的复合函数，比如$f(x,y,z)=(x+y)z$。虽然，这个表达式足够简单，可以直接进行微分，但是在此使用一种有助于直观理解反向传播的算法。将公式分为两部分：$q=x+y,f=qz$。在前面已经介绍过如何对这分开的两个公式进行计算导数：$$<br>\frac {\partial f}{\partial q} = z,\frac {\partial f}{\partial z}=q<br>$$因为，q=x+y，所以，$$<br>\frac {\partial q}{\partial x}=1,\frac {\partial q}{\partial y}=1<br>$$然而，并不需要关心中间量q的梯度，因为$\frac {\partial f}{\partial q}$没有用。相反，函数f关于x、y、z的梯度才是需要关注的。<strong>链式法则</strong>指出将这些梯度表达式链接起来的正确方式是相乘，比如$\frac {\partial f}{\partial x}=\frac {\partial f}{\partial q} \frac {\partial q}{\partial x}$在实际的操作中，只是简单地将两个梯度数值相乘。<br>最后得到变量的梯度[dfdx, dfdy, dfdz]，它们告诉我们函数f对于变量[x, y, z]的敏感程度。这是一个最简单的反向传播。一般会使用一个更简洁的表达符号，这样就不用写df了。这就是说，用dq来代替dfdq，且总是假设梯度是关于最终输出的。<br>这次计算可以被可视化为如下计算线路的图像：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171202/eicdBebej5.jpg?imageslim" alt="mark"><br></div><br>上图的真实值计算线路展示了计算的视觉化过程。前向传播从输入计算到输出（绿色），反向传播从尾部开始，根据链式法则递归地向前计算梯度（显示为红色），一直到网络的输入端。可以认为，梯度是从计算链路中回流。</p><h2 id="反向传播的直观理解"><a href="#反向传播的直观理解" class="headerlink" title="反向传播的直观理解"></a>反向传播的直观理解</h2><p>反向传播是一个优美的局部过程。在整个计算线路图中，每个门单元都会得到一些输出并立即计算两个东西：</p><ol><li>这个门的输出值；</li><li>其输出值关于输入值的局部梯度。<br>门单元完成这两件事是完全独立的，它不需要知道计算路线中的其他细节。然而，一旦前向传播完毕，在反向传播的过程中，门单元将最终获得整个网络的最终输出值在自己的输出值上的梯度。<strong>链式法则指出，门单元应该将回传的梯度乘以它对其的输入的局部梯度，从而得到整个网络的输出对该门单元的每个输入值的梯度。</strong></li></ol><blockquote><p>这里对于每个输入的乘法操作是基于链式法则的。该操作让一个相对独立的门单元变成复杂计算线路中不可或缺的一部分，这个复杂计算线路可以是神经网络等等。</p></blockquote><p>下面通过例子来对这一过程进行理解。加法门收到了输入[-2, 5]，计算输出是3。既然这个门是加法操作，那么对于两个输入的局部梯度都是+1。网络的其余部分计算出的最终值为-12。在反向传播时将递归地使用链式法则，算到加法门的时候，知道加法门的输出梯度是-4。如果网络想要输出值更高，那么可以认为它会想要加法门的输出更小一点，而且还有一个4的倍数。继续递归并对梯度使用链式法则，加法门拿到梯度，然后把这个梯度分别乘到每个输入值的局部梯度（就是让-4乘以x和y的局部梯度，x和y的局部梯度都是1，所以最终都是-4）。可以看到得到了想要的效果：如果x，y减小（它们的梯度为负），那么加法门的输出值减小，这会让乘法门的输出值增大。</p><p>因此，反向传播可以看做是门单元之间在通过梯度信号相互通信，只要让它们的输入沿着梯度方向变化，无论它们自己的输出值在何种程度上升或降低，都是为了让整个网络的输出值更高。</p><h2 id="模块化：Sigmoid例子"><a href="#模块化：Sigmoid例子" class="headerlink" title="模块化：Sigmoid例子"></a>模块化：Sigmoid例子</h2><p>上面介绍的门是相对随意的。任何可微分的函数都可以看做门。可以将多个门组合成一个门，也可以根据需求将一个函数拆成多个门。现在看一个表达式：$$<br>f(w, x) = \frac {1}{1+e^{-(w_0x_0+w_1x_1+w_2}}<br>$$<br>在后面的课程中可以看到，这个表达式描述了一个含输入x和权重w的2维的神经元，该神经元使用了sigmoid激活函数。但是现在只是看做是一个简单的输入为x和w，输出为一个数字的函数。这个函数是由多个门组成的。除了上文介绍的加法门，乘法门，取最大值门，还有下面这4种：$$<br>f(x) = \frac {1}{x} \rightarrow \frac{df}{dx} = - \frac {1}{x^2}\\\\<br>f_c(x) = c+x \rightarrow \frac{df}{dx} = 1 \\\\<br>f(x) = e^x \rightarrow \frac{df}{dx} = e^x\\\\<br>f_a(x) = ax \rightarrow \frac{df}{dx} = a\\\\<br>$$其中，函数$f_c$使用对输入值进行了常量c的平移，$f_a$将输入值扩大了常量a倍。它们是加法和乘法的特例，但是这里将其看做一元门单元，因为确实需要计算常量c，a的梯度，整个计算的线路如下：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171205/bdDBIj68lK.jpg?imageslim" alt="mark"><br></div><br>在上面的例子中可以看见一个函数操作的长链条，链条上的门都对w和x的点积结果进行操作。该函数被称作为sigmoid函数，sigmoid函数关于其输入的求导是可以简化的：$$<br>\sigma(x) = \frac {1}{1+e^{-x}}\\\\<br>\frac {d\sigma(x)}{dx} = \frac {e^{-x}}{(1+e^{-x})^2}=(\frac {1+e^{-x}-1}{1+e^{-x}})(\frac {1}{1+e^{-x}}) = (1-\sigma(x))\sigma(x)<br>$$可以看到梯度计算简单了很多。举个例子，sigmoid表达式输入为1.0，则在前向传播中计算出输出为0.73。根据上面的公式，局部梯度为(1-0.73)*0.73~=0.2，和之前的计算流程比起来，现在的计算使用一个单独的简单表达式即可。</p><h2 id="反向传播实践：分段计算"><a href="#反向传播实践：分段计算" class="headerlink" title="反向传播实践：分段计算"></a>反向传播实践：分段计算</h2><p>看另外一个例子，假设有如下函数：$$<br>f(x,y) = \frac {x+\sigma(y)}{\sigma(x)+(x+y)^2}<br>$$首先要说的是，这个函数完全没用，读者是不会用到它来进行梯度计算的，这里只是用来作为实践反向传播的一个例子，需要强调的是，如果对x或y进行微分运算，运算结束后会得到一个巨大而复杂的表达式。然而做如此复杂的运算实际上并无必要，因为我们不需要一个明确的函数来计算梯度，只需知道如何使用反向传播计算梯度即可。下面是构建前向传播的代码模式：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">x = <span class="number">3</span> <span class="comment"># 例子数值</span></div><div class="line">y = <span class="number">-4</span></div><div class="line"><span class="comment"># 前向传播</span></div><div class="line">sigy = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-y)) <span class="comment"># 分子中的sigmoi          #(1)</span></div><div class="line">num = x + sigy <span class="comment"># 分子                                    #(2)</span></div><div class="line">sigx = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-x)) <span class="comment"># 分母中的sigmoid         #(3)</span></div><div class="line">xpy = x + y                                              <span class="comment">#(4)</span></div><div class="line">xpysqr = xpy**<span class="number">2</span>                                          <span class="comment">#(5)</span></div><div class="line">den = sigx + xpysqr <span class="comment"># 分母                               #(6)</span></div><div class="line">invden = <span class="number">1.0</span> / den                                       <span class="comment">#(7)</span></div><div class="line">f = num * invden                                         <span class="comment">#(8)</span></div></pre></td></tr></table></figure></p><p>到了表达式最后，就完成了前向传播。注意在构建代码s时创建了多个中间变量，每个都是比较简单的表达式，它们计算局部梯度的方法是已知的。这样计算反向传播就简单了：我们对前向传播时产生每个变量(sigy, num, sigx, xpy, xpysqr, den, invden)进行回传。我们会有同样数量的变量，但是都以d开头，用来存储对应变量的梯度。注意在反向传播的每一小块中都将包含了表达式的局部梯度，然后根据使用链式法则乘以上游梯度。对于每行代码，我们将指明其对应的是前向传播的哪部分。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 回传 f = num * invden</span></div><div class="line">dnum = invden <span class="comment"># 分子的梯度                                         #(8)</span></div><div class="line">dinvden = num                                                     <span class="comment">#(8)</span></div><div class="line"><span class="comment"># 回传 invden = 1.0 / den </span></div><div class="line">dden = (<span class="number">-1.0</span> / (den**<span class="number">2</span>)) * dinvden                                <span class="comment">#(7)</span></div><div class="line"><span class="comment"># 回传 den = sigx + xpysqr</span></div><div class="line">dsigx = (<span class="number">1</span>) * dden                                                <span class="comment">#(6)</span></div><div class="line">dxpysqr = (<span class="number">1</span>) * dden                                              <span class="comment">#(6)</span></div><div class="line"><span class="comment"># 回传 xpysqr = xpy**2</span></div><div class="line">dxpy = (<span class="number">2</span> * xpy) * dxpysqr                                        <span class="comment">#(5)</span></div><div class="line"><span class="comment"># 回传 xpy = x + y</span></div><div class="line">dx = (<span class="number">1</span>) * dxpy                                                   <span class="comment">#(4)</span></div><div class="line">dy = (<span class="number">1</span>) * dxpy                                                   <span class="comment">#(4)</span></div><div class="line"><span class="comment"># 回传 sigx = 1.0 / (1 + math.exp(-x))</span></div><div class="line">dx += ((<span class="number">1</span> - sigx) * sigx) * dsigx <span class="comment"># Notice += !! See notes below  #(3)</span></div><div class="line"><span class="comment"># 回传 num = x + sigy</span></div><div class="line">dx += (<span class="number">1</span>) * dnum                                                  <span class="comment">#(2)</span></div><div class="line">dsigy = (<span class="number">1</span>) * dnum                                                <span class="comment">#(2)</span></div><div class="line"><span class="comment"># 回传 sigy = 1.0 / (1 + math.exp(-y))</span></div><div class="line">dy += ((<span class="number">1</span> - sigy) * sigy) * dsigy                                 <span class="comment">#(1)</span></div><div class="line"><span class="comment"># 完成!</span></div></pre></td></tr></table></figure></p><p>需要注意的一些事情：<br><strong>对前向传播变量进行缓存：</strong>计算反向传播时，前向传播过程中得到的一些中间变量非常有用。在实际的操作中，最好代码实现对于这些中间变量的缓存，这样在反向传播时也能用上。如果这样做过于困难，也可以（但是浪费计算资源）重新计算它们。</p><p><strong>在不同分支的梯度要相加</strong>：如果变量x、y在前向传播的表达式中出现多次，那么进行反向传播时要非常小心使用+=而不是=来累计这些变量的梯度（不然就会造成覆写）。这是遵循了在微积分中的多元链式法则，该法则指出如果变量在线路中分支走向不同的部分，那么梯度在回传的时候，就应该进行累加。</p><h2 id="回传流中的模式"><a href="#回传流中的模式" class="headerlink" title="回传流中的模式"></a>回传流中的模式</h2><p>一个有趣的现象是在多数情况下，反向传播中的梯度可以被很直观的解释。例如，神经网络中最常用的加法、乘法和取最大值的这三个门单元，它们在反向传播过程中的行为都非常简单的解释，先看下面的这个例子：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171205/9j7IEJIBf6.jpg?imageslim" alt="mark"><br></div><br>一个展示反向传播的例子。加法操作将梯度相等地分发给它的输入。取最大操作将梯度路由给更大的输入。乘法门拿取输入激活数据，对它们进行交换，然后乘以梯度。从此例可知：</p><p><strong>加法门单元</strong>：把输出的梯度相等地分发给它所有的输入，这一行为与输入值在前向传播时的值无关。这是因为加法操作的局部梯度都是简单的+1，所以所有的梯度实际上就等于输出的梯度，因为乘以1.0保持不变。上例中，加法门就把梯度2.0不变且相等地路由给了两个输入。</p><p><strong>取最大值门单元</strong>：对梯度做路由，和加法门不同，取最大值门将梯度转给其中一个输入，这个输入是在前向传播中值最大的那个输入。这是因为在取最大值门中，最高值的局部梯度是1.0，其余是0。上例中，取最大值门将梯度2.0转给类z变量，因为z的值比w高，于是w的梯度保持为0。</p><p><strong>乘法门单元</strong>：相对不容易解释，它的局部梯度就是输入值，但是是相互交换之后的，然后根据链式法则乘以输出值的梯度。上例中，x的梯度是-4.0*2.0 = -8.0。</p><p>非直观影响及其结果。注意一种比较特殊的情况，如果乘法门单元的其中一个输入非常小，而另一个输入非常大，那么乘法门的操作将会不是那么直观：它将会把大的梯度分配给小的输入，把小的梯度分配给大的输入。在线性分类器中，权重和输入是进行点积$w^Tx_i$，这说明输入数据的大小对于权重梯度的大小有影响。例如，在计算过程中对所有输入数据样本$x_i$乘以1000，那么权重的梯度将会增大1000倍，这样就必须降低学习率来弥补。这就是为什么数据预处理关系重大，它即使只是有微小变化，也会产生巨大影响。对于梯度在计算线路中是如何流动的有一个直观的理解，可以帮助读者调试网络。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li><p>对梯度的含义有了直观理解，知道了梯度是如何在网络中反向传播的，知道了它们是如何与网络的不同部分通信并控制其升高或者降低，并使得最终输出值更高的。</p></li><li><p>讨论了分段计算在反向传播的实现中的重要性。应该将函数分成不同的模块，这样计算局部梯度相对容易，然后基于链式法则将其“链”起来。重要的是，不需要把这些表达式写在纸上然后演算它的完整求导公式，因为实际上并不需要关于输入变量的梯度的数学公式。只需要将表达式分成不同的可以求导的模块（模块可以是矩阵向量的乘法操作，或者取最大值操作，或者加法操作等），然后在反向传播中一步一步地计算梯度。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/optimization-2/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit，并进行一定修改。原文为：http://cs231n.github.io/optimization-2/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;目的&lt;/strong&gt;:本节帮助读者对&lt;strong&gt;反向传播&lt;/strong&gt;形成直观而专业的理解。反向传播是利用链式法则递归计算梯度的方法。理解反向传播过程及其精妙之处，对于理解、实现、设计和调试神经网络非常关键。&lt;br&gt;
    
    </summary>
    
      <category term="课程笔记" scheme="https://ilewseu.github.io/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="cs231n" scheme="https://ilewseu.github.io/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>CS231n课程笔记(4)  Optimization Note</title>
    <link href="https://ilewseu.github.io/2017/12/04/CS231n%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E7%AC%AC4%E8%AF%BE-Optimization/"/>
    <id>https://ilewseu.github.io/2017/12/04/CS231n课程笔记-第4课-Optimization/</id>
    <published>2017-12-04T14:17:23.000Z</published>
    <updated>2017-12-16T16:06:09.140Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转载自：<a href="https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit，原文：http://cs231n.github.io/optimization-1/" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit，原文：http://cs231n.github.io/optimization-1/</a></p></blockquote><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>图像分类任务中的两个关键部分：</p><ol><li>基于参数的评分函数。该函数将原始图像像素映射为分类评分值（例如，一个线性函数）。</li><li>损失函数。该函数能够根据评分和训练集图像数据实际分类的一致性，衡量某个具体参数集的质量好坏。损失函数有多种版本和不同的实现方式（例如：Softmax或SVM）。<a id="more"></a><br>上节，线性函数的形式是$f(x_i,W)=Wx_i$，而SVM实现的公式是：$$<br>L=\frac {1}{N}\sum_i\sum_{j \neq y_i} [max(0,f(x_i;W)_j - f(x_i;W)_{y_i}+1)]+\alpha R(W)$$<br>对于图像数据$x_i$，如果基于参数集W做出的分类预测与真实情况比较一致，那么计算出来的损失值L就很低。现在介绍第三个，也是最后一个关键部分：最优化Optimization。最优化是寻找能使得损失函数值最小化的参数W的过程。<h2 id="损失函数可视化"><a href="#损失函数可视化" class="headerlink" title="损失函数可视化"></a>损失函数可视化</h2>课程讨论的损失函数一般都是定义在高维度的空间中，这样要将其进行可视化就很困难。然而办法还是有的，在1个维度或者2个维度的方向上对高维空间进行切片，就能够得到一些直观的感受。例如，随机生成一个权重矩阵W，该矩阵就与高维空间中的一个点对应。然后，沿着某个维度方向前进的同时记录损失函数值的变化。换句话说，就是生成一个随机的方向$W_1$并且沿着某个维度方向计算损失值，计算方法是根据不同的a值来计算$L(W+aW_1)$。这个过程将生成一个图标，x轴为a值，y轴为损失函数值。同样的方法还可以用在两个维度上，通过改变a、b来计算损失函数值$L(W+aW_1+bW_2)$，从而给出二维的图像。在图像中，a、b可以分别用x轴和y轴表示，而损失函数的值可以用颜色变化表示：<br><div align="center"><br> <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171202/j58jchI41f.jpg?imageslim" alt="mark"><br></div><br>一个无正则化的多类SVM的损失函数的图示。左边和中间只有一个样本数据，右边是CIFAR-10中的100个数据。<strong>左</strong>：a值变化在某个维度方向上对应的的损失值变化。<strong>中和右</strong>：两个维度方向上的损失值切片图，蓝色部分是低损失值区域，红色部分是高损失值区域。注意损失函数的分段线性结构。多个样本的损失值是总体的平均值，所以右边的碗状结构是很多的分段线性结构的平均（比如中间这个就是其中之一）。</li></ol><p>可以通过数学公式来解释损失函数的分段线性结构，对于一个单独的数据，有损失函数的计算公式如下：$$<br>L_i = \sum_{j \neq y_i}[max(0, W_j^Tx_i - W_{y_i}^Tx_i + 1)]<br>$$<br>通过公式可见，每个样本的数据损失值是以W为参数的线性函数的总和（0阈值来源于max(0,-)函数）。W的每一行（即$w_j$）,有时候它前面是一个正号（比如当它对应错误分类的时候），有时候它前面是一个负号（比如当它是是正确分类的时候）。为进一步阐明，假设有一个简单的数据集，其中包含有3个只有1个维度的点，数据集数据点有3个类别。那么完整的无正则化SVM的损失值计算如下：$$<br>L_0 = max(0, w_1^Tx_0 - w_0^Tx_0 + 1)+max(0, w_2^Tx_0 - w_0^Tx_0 + 1)\\\\<br>L_1 = max(0, w_0^Tx_1 - w_1^Tx_1 + 1)+max(0, w_2^Tx_1 - w_1^Tx_1 + 1)\\\\<br>L_2 = max(0, w_0^Tx_2 - w_2^Tx_2 + 1)+max(0, w_1^Tx_2 -w_2^Tx_2 + 1)\\\\<br>L=(L_0+L_1+L_2)/3<br>$$<br>因为这些例子都是一维的，所以数据$x_i$和权重$w_j$都是数字。观察$w_0$，可以看到上面的式子中一些项是$w_0$的线性函数，且每一项都会与0比较，取两者的最大值。可作图如下：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171202/Hbk48D1cJ5.jpg?imageslim" alt="mark"><br></div><br>从一个维度方向上对数据损失值的展示。x轴方向就是一个权重，y轴就是损失值。数据损失是多个部分组合而成。其中每个部分要么是某个权重的独立部分，要么是该权重的线性函数与0阈值的比较。完整的SVM数据损失就是这个形状的30730维版本。</p><h2 id="最优化"><a href="#最优化" class="headerlink" title="最优化"></a>最优化</h2><p>损失函数可以量化某个具体权重集W的质量，而最优化的目标就是找到能够最小化损失函数值的W。我们现在就朝着这个目标前进，实现一个能够最优化损失函数的方法。对于一些有经验的同学，这节课看起来有点奇怪，因为使用的例子（SVM损失函数）是一个凸函数。但是要记得，最终的目标是不仅仅对凸函数做最优化，而是能够最优化一个神经网络，而对于神经网络是不能简单的使用凸函数的最优化技巧的。<br><strong>策略1：随机搜索</strong><br>既然确认参数集W的好坏蛮简单的，那第一个想到的（差劲）方法，就是可以随机尝试很多不同的权重，然后看其中哪个最好。<br><strong>蒙眼徒步者的比喻</strong>：一个助于理解的比喻是把你自己想象成一个蒙着眼睛的徒步者，正走在山地地形上，目标是要慢慢走到山底。在CIFAR-10的例子中，这山是30730维的（因为W是3073x10）。我们在山上踩的每一点都对应一个的损失值，该损失值可以看做该点的海拔高度。</p><p><strong>策略2：随机本地搜索</strong><br>第一个策略可以看做是每走一步都尝试几个随机方向，如果某个方向是向山下的，就向该方向走一步。这次我们从一个随机W开始，然后生成一个随机的扰动$\delta W$ ，只有当$W+\delta W$的损失值变低，我们才会更新。</p><p><strong>策略3：梯度跟随</strong><br>前两个策略中，我们是尝试在权重空间中找到一个方向，沿着该方向能降低损失函数的损失值。其实不需要随机寻找方向，因为可以直接计算出最好的方向，这就是从数学上计算出最陡峭的方向。这个方向就是损失函数的梯度（gradient）。在蒙眼徒步者的比喻中，这个方法就好比是感受我们脚下山体的倾斜程度，然后向着最陡峭的下降方向下山。<br>在一维函数中，斜率是函数在某一点的瞬时变化率。梯度是函数的斜率的一般化表达，它不是一个值，而是一个向量。在输入空间中，梯度是各个维度的斜率组成的向量（或者称为倒数）。对一维函数的求导公式如下：$$<br>\frac {df(x)}{dx} = \lim_{h\rightarrow0}\frac {f(x+h)-f(x)}{h}<br>$$<br>当函数有多个参数的时候，我们称导数为偏导数。而梯度就是在每个维度上偏导数所形成的向量。</p><h2 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h2><p>计算梯度有两种方法：一个是缓慢的近似方法（数值梯度法），实现相对简单。另一个方法是（分析梯度法）计算迅速，结果精确，但是实现时容易出错，且需要使用微分。现在对这两种方法进行介绍：<br><strong>利用有限差值计算梯度</strong><br>上节中的公式已经给出数值计算梯度的方法。下面代码是一个输入为函数f和向量x，计算f的梯度的通用函数，它返回函数f在点x处的梯度：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_numerical_gradient</span><span class="params">(f, x)</span>:</span></div><div class="line">  <span class="string">"""  </span></div><div class="line"><span class="string">  一个f在x处的数值梯度法的简单实现</span></div><div class="line"><span class="string">  - f是只有一个参数的函数</span></div><div class="line"><span class="string">  - x是计算梯度的点</span></div><div class="line"><span class="string">  """</span> </div><div class="line">  fx = f(x) <span class="comment"># 在原点计算函数值</span></div><div class="line">  grad = np.zeros(x.shape)</div><div class="line">  h = <span class="number">0.00001</span></div><div class="line">  <span class="comment"># 对x中所有的索引进行迭代</span></div><div class="line">  it = np.nditer(x, flags=[<span class="string">'multi_index'</span>], op_flags=[<span class="string">'readwrite'</span>])</div><div class="line">  <span class="keyword">while</span> <span class="keyword">not</span> it.finished:</div><div class="line">    <span class="comment"># 计算x+h处的函数值</span></div><div class="line">    ix = it.multi_index</div><div class="line">    old_value = x[ix]</div><div class="line">    x[ix] = old_value + h <span class="comment"># 增加h</span></div><div class="line">    fxh = f(x) <span class="comment"># 计算f(x + h)</span></div><div class="line">    x[ix] = old_value <span class="comment"># 存到前一个值中 (非常重要)</span></div><div class="line">    <span class="comment"># 计算偏导数</span></div><div class="line">    grad[ix] = (fxh - fx) / h <span class="comment"># 坡度</span></div><div class="line">    it.iternext() <span class="comment"># 到下个维度</span></div><div class="line">  <span class="keyword">return</span> grad</div></pre></td></tr></table></figure></p><p>根据上面的梯度公式，代码对所有维度进行迭代，在每个维度上产生一个很小的变化h，通过观察函数值变化，计算函数在该维度上的偏导数。最后，所有的梯度存储在变量grad中。</p><p><strong>实践考虑</strong>：注意在数学公式中，h的取值是趋近于0的，然而在实际中， 用一个很小的数值就足够了。而不产生数值计算出错的理想前提下，使用尽可能小的h。还有，实际中用中心差值公式（centered difference formula）[f(x+h)-f(x-h)]/2h效果较好。</p><p><strong>在扶梯度方向上更新：</strong>要注意我们是向着梯度df的负方向去更新，这是因为我们希望损失函数值是降低而不是升高。<br><strong>步长的影响：</strong>梯度指明了函数在哪个方向是变化率最大的，但是没有指明在这个方向上应该走多远。选择步长（也叫作学习率）将会是神经网络训练中最重要（也是最头痛）的超参数设定之一。从某个具体的点W开始计算梯度（白箭头方向是负梯度方向），梯度告诉了我们损失函数下降最陡峭的方向。小步长下降稳定但进度慢，大步长进展快但是风险更大。采取大步长可能导致错过最优点，让损失值上升。步长（后面会称其为学习率）将会是我们在调参中最重要的超参数之一。</p><p><strong>微分分析计算梯度</strong><br>使用有限差值近似计算梯度比较简单，但缺点在于终究只是近似（因为我们对于h值是选取了一个很小的数值，但真正的梯度定义中h趋向0的极限），且耗费计算资源太多。第二个梯度计算方法是利用微分来分析，能得到计算梯度的公式（不是近似），用公式计算梯度速度很快，唯一不好的就是实现的时候容易出错。为了解决这个问题，在实际操作时常常将分析梯度法的结果和数值梯度法的结果作比较，以此来检查其实现的正确性，这个步骤叫做<strong>梯度检查</strong>。<br>用SVM的损失函数在某个数据点上的计算来举例：$$<br>L_i = \sum_{j\neq y_i} [max(0, w_j^Tx_i - w_{y_i}^Tx_i)+\Delta]<br>$$<br>可以对函数进行微分，比如，对$w_{y_i}$进行微分得到：<br>$$<br>\nabla_{w_{y_i}}L_i = -(\sum_{j\neq y_i} 1(w_j^Tx_i-w_{y_i}^Tx_i+\Delta&gt;0))x_i<br>$$<br>其中1是一个示性函数，如果括号中的条件为真，那么函数值为1，如果为假，则函数值为0。虽然上述公式看起来复杂，但在代码实现的时候比较简单：只需要计算没有满足边界值的分类的数量（因此对损失函数产生了贡献），然后乘以x_i就是梯度了。注意，这个梯度只是对应正确分类的W的行向量的梯度，那些$j\neq =y_i$行的梯度是：<br>$$<br>\nabla_{w_j}L_i=1(w_j^Tx_i-w_{y_i}^Tx_i+\Delta&gt;0)x_i<br>$$<br>一旦将梯度的公式微分出来，代码实现公式并用于梯度更新就比较顺畅了。</p><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>现在可以计算损失函数的梯度了，程序重复地计算梯度然后对参数进行更新，这一过程称为梯度下降，他的普通版本是这样的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 普通的梯度下降</span></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">  weights_grad = evaluate_gradient(loss_fun, data, weights)</div><div class="line">  weights += - step_size * weights_grad <span class="comment"># 进行梯度更新</span></div></pre></td></tr></table></figure></p><p>这个简单的循环在所有的神经网络核心库中都有。虽然也有其他实现最优化的方法（比如LBFGS），但是到目前为止，梯度下降是对神经网络的损失函数最优化中最常用的方法。课程中，我们会在它的循环细节增加一些新的东西（比如更新的具体公式），但是核心思想不变，那就是我们一直跟着梯度走，直到结果不再变化。</p><p><strong>小批量数据梯度下降(Mini-batch gradient descent)</strong>:在大规模的应用中（比如ILSVRC挑战赛），训练数据可以达到百万级量级。如果像这样计算整个训练集，来获得仅仅一个参数的更新就太浪费了。一个常用的方法是计算训练集中的小批量（batches）数据。这个方法之所以效果不错，是因为训练集中的数据都是相关的。</p><p>小批量数据策略有个极端情况，那就是每个批量中只有1个数据样本，这种策略被称为<strong>随机梯度下降</strong>（Stochastic Gradient Descent 简称SGD），有时候也被称为在线梯度下降。这种策略在实际情况中相对少见，因为向量化操作的代码一次计算100个数据 比100次计算1个数据要高效很多。即使SGD在技术上是指每次使用1个数据来计算梯度，你还是会听到人们使用SGD来指代小批量数据梯度下降（或者用MGD来指代小批量数据梯度下降，而BGD来指代则相对少见）。小批量数据的大小是一个超参数，但是一般并不需要通过交叉验证来调参。它一般由存储器的限制来决定的，或者干脆设置为同样大小，比如32，64，128等。之所以使用2的指数，是因为在实际中许多向量化操作实现的时候，如果输入数据量是2的倍数，那么运算更快。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>将损失函数比作了一个高维度的最优化地形，并尝试到达它的最底部。最优化的工作过程可以看做一个蒙着眼睛的徒步者希望摸索着走到山的底部。在例子中，可见SVM的损失函数是分段线性的，并且是碗状的。</li><li>提出了迭代优化的思想，从一个随机的权重开始，然后一步步地让损失值变小，直到最小。</li><li>函数的梯度给出了该函数最陡峭的上升方向。介绍了利用有限的差值来近似计算梯度的方法，该方法实现简单但是效率较低（有限差值就是h，用来计算数值梯度）。</li><li>参数更新需要有技巧地设置步长。也叫学习率。如果步长太小，进度稳定但是缓慢，如果步长太大，进度快但是可能有风险。</li><li>讨论权衡了数值梯度法和分析梯度法。数值梯度法计算简单，但结果只是近似且耗费计算资源。分析梯度法计算准确迅速但是实现容易出错，而且需要对梯度公式进行推导的数学基本功。因此，在实际中使用分析梯度法，然后使用梯度检查来检查其实现正确与否，其本质就是将分析梯度法的结果与数值梯度法的计算结果对比。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转载自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit，原文：http://cs231n.github.io/optimization-1/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit，原文：http://cs231n.github.io/optimization-1/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;图像分类任务中的两个关键部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基于参数的评分函数。该函数将原始图像像素映射为分类评分值（例如，一个线性函数）。&lt;/li&gt;
&lt;li&gt;损失函数。该函数能够根据评分和训练集图像数据实际分类的一致性，衡量某个具体参数集的质量好坏。损失函数有多种版本和不同的实现方式（例如：Softmax或SVM）。
    
    </summary>
    
      <category term="课程笔记" scheme="https://ilewseu.github.io/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="cs231n" scheme="https://ilewseu.github.io/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>CS231n课程笔记(3)  线性分类器</title>
    <link href="https://ilewseu.github.io/2017/12/03/CS231n%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E7%AC%AC3%E8%AF%BE-Linear-Classification/"/>
    <id>https://ilewseu.github.io/2017/12/03/CS231n课程笔记-第3课-Linear-Classification/</id>
    <published>2017-12-03T14:17:23.000Z</published>
    <updated>2017-12-16T16:05:44.987Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转自：<a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit，原文：http://cs231n.github.io/linear-classify/，并进行一定修改。" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit，原文：http://cs231n.github.io/linear-classify/，并进行一定修改。</a></p></blockquote><p>本节课主要介绍线性分类器相关的知识，并将其用于图像分类。</p><h2 id="线性分类器简介"><a href="#线性分类器简介" class="headerlink" title="线性分类器简介"></a>线性分类器简介</h2><p><strong>评分函数（score function)</strong>:它是原始图像数据到类别分值的映射。<br><strong>损失函数（loss function）</strong>：它是用来量化预测分类标签的得分与真实值之间的一致性。<br><a id="more"></a></p><h3 id="从图像到标签分值的参数化映射"><a href="#从图像到标签分值的参数化映射" class="headerlink" title="从图像到标签分值的参数化映射"></a>从图像到标签分值的参数化映射</h3><p>该方法的第一步就是定义一个评分函数，这个函数将图像的像素值映射为各个类别的得分，得分的高低代表图像属于该类别的可能性高低。假设一个包含很多图像的训练集$x_i \in R^D，i=1,..,N$，每个图像都对应一个分类标签$y_i，i=1,…,K$。在CIFAR-10中，N=50000的训练集，每个图像有D=32*32*3=3072像素，而K=10。因为，图片被分为10个不同的类别。定义评分函数：$f:R^D\rightarrow R^K$，该函数是原始图像像素得到分类分值的映射。<br><strong>线性分类器</strong>定义一个线性映射：$$<br>f(x_i,W,b)=Wx_i+b<br>$$<br>其中，参数W称为权重，b称为偏差向量，这是因为它影响输出数值，但是并不和原始数据$x_i$产生关联。同时，需要注意以下几点：</p><ul><li>一个单独的矩阵乘法$Wx_i$就可以高效并行评估10个不同的分类器（每个分类器针对一个分类），其中每个类的分类器就是W的一个行向量。</li><li>注意我们认为输入数据$(x_i,y_i)$是给定且不可改变的，但参数W和b是可控制改变的。我们通过设置这些参数，使得计算出的分类分值情况和训练集中图像数据的真实类别标签相符。</li><li>该方法的一个优势是训练数据是用来学习到参数W和b的，一旦训练完成，训练数据就可以丢弃，留下学习到的参数即可。</li><li>意只需要做一个矩阵乘法和一个矩阵加法就能对一个测试数据分类，这比k-NN中将测试图像和所有训练数据做比较的方法快多了。</li></ul><h3 id="理解线性分类器"><a href="#理解线性分类器" class="headerlink" title="理解线性分类器"></a>理解线性分类器</h3><p>线性分类器计算图像中3个颜色通道中所有像素的值与权重的矩阵乘，从而得到分类分值。根据我们对权重设置的值，对于图像中的某些位置的某些颜色，函数表现出喜好或者厌恶（根据每个权重的符号而定）。举个例子，可以想象“船”分类就是被大量的蓝色所包围（对应的就是水）。那么“船”分类器在蓝色通道上的权重就有很多的正权重（它们的出现提高了“船”分类的分值），而在绿色和红色通道上的权重为负的就比较多（它们的出现降低了“船”分类的分值）。</p><p><strong>将图像看做高维度的点</strong>：既然图像被伸展成为一个高维度的列向量，那么我们可以把图像看做这个高维度空间的一个点。整个数据集就是一个点的集合，每个点都带有1个分类标签。既然定义每个分类类别的分值是权重和图像的矩阵乘法，那么每个分类类别的分数就是这个空间中的一个线性函数的函数值。我们没办法可视化3072维空间中的线性函数，但假设把这些维度挤压到二维，那么就可以看出线性分类器在做什么了：</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171129/I8Di490iHf.jpg?imageslim" alt="mark"><br></div><br>在上图中，每个图像是一个点，有3个分类器，以红色的汽车分类器为例，红线表示空间中汽车分类分数为0的点的集合，红色的箭头表示分值上升的方向。所有红线右边的点的分数值均为正，且线性升高。红线左边的点分值为负，且线性降低。从上面可以看到，W的每一行都是一个分类类别的分类器。对于这些数字的几何解释是：如果改变其中一行的数字，会看见分类器在空间中对应的直线开始向着不同方向旋转。而偏差b，则允许分类器对应的直线平移。需要注意的是，如果没有偏差，无论权重如何，在$x_i=0$时分类分值始终为0。这样所有分类器的线都不得不穿过原点。<br><strong>偏差和权重的合并技巧</strong>：之前评分函数定义为：$$<br>f(x_i,W,b)=Wx_i+b<br>$$<br>分开处理这两个参数有点笨拙，一般常用的方法是把两个参数放到同一个矩阵中，同时$x_i$向量就要增加一个维度，这个维度的数值是常量1，这就是默认的偏差维度的权重。这样新的公式就简化成下面这样：<br>$f(x_i,W)=Wx_i$<br>如下图所示，左边是先做矩阵乘法然后做加法，右边是将所有输入向量的维度增加1个含常量1的维度，并且在权重矩阵中增加一个偏差列，最后做一个矩阵乘法即可。左右是等价的，通过右边这样做，我们只需要学习一个权重矩阵，而不用去学习两个分别装着权重和偏差的矩阵。<br><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171129/Gg03C99b1C.jpg?imageslim" alt="mark"><br></div><p><strong>图像数据处理</strong>：在图像分类的例子中，图像上的每个像素可以看做一个特征，在实践中，对每个特征减去平均值来中心化数据是非常重要的。在这些图片的例子中，该步骤意味着根据训练集中所有的图像计算出一个平均图像值，然后每个图像都减去这个平均值，这样图像的像素值就大约分布在[-127, 127]之间了。下一个常见步骤是，让所有数值分布的区间变为[-1, 1]。零均值的中心化是很重要的。</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>损失函数的具体形式多种多样。首先，介绍常用的多类支持向量机（SVM）损失函数。SVM的损失函数想要SVM在正确分类上的得分始终比不正确分类上的得分高出一个边界值$\Delta$。假设，第i个数据中包含图像$x_i$的像素和代表正确类别的标签$y_i$。评分函数输入像素数据，然后通过公式$f(x_i,W)$来计算不同分类类别的分值。这里将分值简写为s。比如，针对第j个类别的得分就是第j个元素：$s_j=f(x_i,W)_j$。针对第i个数据的多类SVM的损失函数定义如下：<br>$$L_i=\sum_{j \neq y_i} max(0, s_j - s_{y_i}+\Delta)$$<br>举个例子，假设有3个类别，并且得到了分值s=[13,-7,11]。其中第一个类别是正确的类别，即$y_i=0$。同时，假设$\Delta=10$。上面的公式是将所有不正确分类($j\neq y_i$)加起来，所以我们会得到两个部分：$$<br>L_i=max(0,-7-13+10) + max(0, 11-13+10)$$<br>可以看到，第一个部分的结果是0，这一对类别分数和标签的损失值为0，这是因为正确分类的得分13与错误分类的得分-7的差为20，高于边界值10，而SVM只关心差距至少要大于10，更大差值还是算作损失值为0。第二个部分计算[11-13+10]得到8。虽然正确分类的得分比不正确分类的得分要高（13&gt;11），但是比10的边界值还是小了，分差只有2，这就是为什么损失值等于8。简而言之，SVM的损失函数想要正确分类类别$y_i$的分数比不正确类别分数高，而且至少要高$\Delta$。如果不满足这点，就开始计算损失值。那么，我们面对的是线性评分函数($f(x_i,W)=Wx_i$)，所以我们可以将损失函数稍微改写一下：$$<br>L_i = \sum_{j \neq y_i} max(0, w_j^Tx_i-w_{y_i}^Tx_i+\Delta)<br>$$<br>其中，$w_j$是权重W的第j行，被变形为列向量。然而，一旦开始考虑更复杂的评分函数f，这样做就不是必须的了。<br>max(0,-)函数，它常被称为折页损失(hinge loss)，有时候会听到使用平方折页损失SVM（即L2-SVM）,它使用的是$max(0,-)^2$，将更强烈地惩罚过界的边界值。不使用平方的更标准的版本，但是在某些数据集中，平方折页损失会工作得更好。可以通过交叉验证来决定到底使用哪个。</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171130/4FKLFI5ki6.jpg?imageslim" alt="mark"><br></div><br>多类SVM“想要”正确类别的分类分数比其他不正确分类类别的分数要高，而且至少高出delta的边界值。如果其他分类分数进入了红色的区域，甚至更高，那么就开始计算损失。如果没有这些情况，损失值为0。我们的目标是找到一些权重，它们既能够让训练集中的数据样例满足这些限制，也能让总的损失值尽可能地低。</p><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>上面的损失函数有一个问题，假设有一个数据集和权重集W能够正确分类每个数据。问题在于这个W并不唯一：可能有很多相似的W都能正确地分类所有的数据。一个简单的例子：如果W能够正确分类所有数据，即对于每个数据，损失值都是0。那么当$\lambda&gt;1$时，任何数乘$\lambda W$都能使得损失值为0，因为这个变化将所有分值的大小都均等地扩大了，所以它们之间的绝对差值也扩大了。举个例子，如果一个正确分类的分值和举例它最近的错误分类的分值的差距是15，对W乘以2将使得差距变成30。</p><p>换句话说，我们希望能向某些特定的权重W添加一些偏好，对其他权重则不添加，以此来消除模糊性。这一点是能够实现的，方法是向损失函数增加一个正则化惩罚R(W)部分。最长用的正则化惩罚是L2范式，L2范式通过对所有参数进行逐元素的平方惩罚来抑制大数值的权重：$$<br>R(W)=\sum_k\sum_l W_{k,l}^2<br>$$<br>上面的表达式中，将W中所有元素平方求和。注意正则化函数不是数据的函数，仅基于权重。包含正则化惩罚后，就能够给出完整的多类SVM损失函数，它由两部分组成：数据损失，即所有样例的平均损失$L_i$，以及正则化损失。完整公式如下：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171201/f8I73cDDJi.jpg?imageslim" alt="mark"><br></div><br>将其展开完整公式是：$$<br>L = \frac {1}{N}\sum_i\sum_{j\neq y_i}[max(0,f(x_i;W)_j - f(x_i;W)y_i+\Delta)] + \lambda \sum_k\sum_l W_{k,l}^2$$<br>其中，N是训练数据集的数据量。现在正则化惩罚添加到了损失函数里面，并用超参数$\lambda$来计算权重。该超参数无法简单确定，需要通过交叉验证来获取。<br>正则化最好的性质就是对大数值权重进行惩罚，可以提升泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值由过大的影响。</p><p>举个例子，假设输入向量x=[1,1,1,1]，两个权重向量$w_1=[1,0,0,0]，w_2=[0.25,0.25,0.25,0.25]$。那么，$w_1^T=w_2^T=1$，两个权重向量都得到同样的内积，但是$w_1$的L2惩罚是1.0，而$w_2$的L2惩罚是0.25。因此，根据L2惩罚来看，$w_2$更好，因为它的正则化损失更小。从直观上来看，这是因为w_2的权重值更小且更分散。既然L2惩罚倾向于更小更分散的权重向量，这就会鼓励分类器最终将所有维度上的特征都用起来，而不是强烈依赖其中少数几个维度。在后面的课程中可以看到，这一效果将会提升分类器的泛化能力，并避免过拟合。</p><p>需要注意的是，和权重不同， 偏差没有这样的效果，因为它们并不控制输入维度上的影响强度。因此，通常只对权重W正则化，而不正则化偏差b。在实际操作中，可以发现这一操作的影响可忽略不计。最后，因为正则化惩罚的存在，不可能在所有的例子中得到0的损失值，这是因为只有当W=0的特殊情况下，才能得到损失值为0。</p><p><strong>设置$\Delta$</strong><br>$\Delta$这个超参数在绝大多数情况下被设置为$\Delta=1.0$。超参数$\Delta$和$\lambda$看起来是两个不同的超参数，但实际上他们一起控制同一个权衡：即损失函数中的数据损失和正则化损失之间的权衡。理解这一点的关键是要知道，权重W的大小对于分类分值有直接影响：当我们将W中值缩小，分类分值之间的差异也变小，反之亦然。因此，不同分类分值之间的边界的具体值（比如$\Delta=1$或$\Delta=100$）从某些角度来看是没意义的，因为权重自己就可以控制差异变大和缩小。也就是说，真正的权衡是我们允许权重能够变大到何种程度（通过正则化强度$\lambda$来控制)。</p><h2 id="Softmax分类器"><a href="#Softmax分类器" class="headerlink" title="Softmax分类器"></a>Softmax分类器</h2><p>SVM是最常用的两个分类器之一，而另一个就是Softmax分类器，它的损失函数和SVM的损失函数不同。Softmax分类器可以理解为逻辑回归分类器面对多个分类的一般化归纳。SVM将输出$f(x_i,W)$作为每个分类的评分。与SVM不同，Softmax的输出（归一化的分类概率）更加直观，并且从概率上可以解释。在Softmax分类器中，函数映射保持不变$f(x_i;W)=Wx_i$,但将这些评分视为每个分类的未归一化的对数概率，并将hinge loss替换为交叉熵损失(cross-entropy loss)。公式如下：$$<br>L_i=-log(\frac {e^{f_{y_i}}}{\sum_j e^{f_j}})<br>$$<br>在上式中，$f_j$表示评分向量f中的第j个元素。和之前一样，整个数据集的损失值是数据集中所有样本数据的损失值$L_i$的均值与正则化损失R(W)之和。其中函数$f_j(z) = \frac {e^{z_j}}{\sum_k e^{z_k}}$被称作为Softmax函数：其输入值是一个向量，向量中的元素为任意实数的评分值，函数对其进行压缩，输出一个向量，其中每个元素在0到1之间，且所有的元素之和为1。<br><strong>信息理论视角</strong>：在”真实”分布p和评估分布q之间的较差熵定义如下：$$<br>H(p,q)=-\sum_x p(x)logq(x)$$<br>因此，Softmax分类器所做的就是最小化在估计分类概率和在“真实”分布之间的较差熵。在这个解释中，“真实”分布就是所有概率密度都分布在正确的类别上（比如：p=[0,…,1,…,0]在某个位置就有一个单独的1）。还有，既然交叉熵可以写成熵和相对熵$H(p,q)=H(p)+D_{KL}(p||q)$，并且delta函数p的熵是0，那么就能等价的看做是对两个分别之间的相对熵做最小化操作。换句话说，交叉熵损失函数“想要”预测分布的所有概率密度都在正确分类上。</p><p><strong>概率论解释</strong>：先看下面的公式:$$<br>P(y_i|x_i,W)=\frac {e^{f_{y_i}}}{\sum_j e^{f_j}}$$<br>可以解释为是给定图像数据$x_i$，以W为参数，分配给正确分类标签$y_i$的归一化概率。为了理解这点，请回忆一下Softmax分类器将输出向量f中的评分值解释为没有归一化的对数概率。那么以这些数值做指数函数的幂就得到了没有归一化的概率，而除法操作则对数据进行了归一化处理，使得这些概率的和为1。从概率论的角度来理解，我们就是在最小化正确分类的负对数概率，这可以看做是在进行最大似然估计（MLE）。该解释的另一个好处是，损失函数中的正则化部分R(W)可以被看做是权重矩阵W的高斯先验，这里进行的是最大后验估计（MAP）而不是最大似然估计。</p><h2 id="SVM-和-Softmax的比较"><a href="#SVM-和-Softmax的比较" class="headerlink" title="SVM 和 Softmax的比较"></a>SVM 和 Softmax的比较</h2><p>下图有助于区分Softmax和SVM这两类分类器：</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171201/9kiELFfDg3.jpg?imageslim" alt="mark"><br></div><br>针对一个数据点，SVM和Softmax分类器的不同处理方式的例子。两个分类器都计算了同样的分值向量f（本节中是通过矩阵乘来实现）。不同之处在于对f中分值的解释：SVM分类器将它们看做是分类评分，它的损失函数鼓励正确的分类（本例中是蓝色的类别2）的分值比其他分类的分值高出至少一个边界值。Softmax分类器将这些数值看做是每个分类没有归一化的对数概率，鼓励正确分类的归一化的对数概率变高，其余的变低。SVM的最终的损失值是1.58，Softmax的最终的损失值是0.452，但要注意这两个数值没有可比性。只在给定同样数据，在同样的分类器的损失值计算中，它们才有意义。</p><p><strong>Softmax分类器为每个分类提供了“可能性”</strong>：SVM的计算是无标定的，而且难以针对所有分类的评分值给出直观解释。Softmax分类器则不同，它允许我们计算出对于所有分类标签的可能性。举个例子，针对给出的图像，SVM分类器可能给你的是一个[12.5, 0.6, -23.0]对应分类“猫”，“狗”，“船”。而softmax分类器可以计算出这三个标签的“可能性”是[0.9, 0.09, 0.01]，这就让你能看出对于不同分类准确性的把握。为什么我们要在“可能性”上面打引号呢？这是因为可能性分布的集中或离散程度是由正则化参数λ直接决定的，λ是你能直接控制的一个输入参数。举个例子，假设3个分类的原始分数是[1, -2, 0]，那么softmax函数就会计算：$$<br>[1,-2,0]\rightarrow[e^1,e^{-2},e^0]=[2.71,0.14,1]\rightarrow[0.7,0.004,0.26]$$<br>现在，如果正则化参数λ更大，那么权重W就会被惩罚的更多，然后他的权重数值就会更小。这样算出来的分数也会更小，假设小了一半吧[0.5, -1, 0]，那么Softmax函数的计算就是：$$[0.5,-1,0]\rightarrow[e^{0.5},e^{-1},e^0]=[1.65,0.73,1]\rightarrow[0.55,0.12,0.33]$$现在看起来，概率的分布就更加分散了。还有，随着正则化参数λ不断增强，权重数值会越来越小，最后输出的概率会接近于均匀分布。这就是说，<strong>softmax分类器算出来的概率最好是看成一种对于分类正确性的置信</strong>。和SVM一样，数字间相互比较得出的大小顺序是可以解释的，但其绝对值则难以直观解释。</p><p><strong>在实际使用中，SVM和Softmax经常是相似的</strong>:通常来说，这两种分类器的表现差别很小，不同的人对于哪个分类器更好有不同的看法。相对于Softmax分类器，SVM更加”局部目标化”，这既可以看做是一个特性，也可以看做是一个劣势。考虑一个评分是[10, -2, 3]的数据，其中第一个分类是正确的。那么一个SVM（$\Delta =1$）会看到正确分类相较于不正确分类，已经得到了比边界值还要高的分数，它就会认为损失值是0。SVM对于数字个体的细节是不关心的：如果分数是[10, -100, -100]或者[10, 9, 9]，对于SVM来说没设么不同，只要满足超过边界值等于1，那么损失值就等于0。</p><p>对于Softmax分类器，情况则不同。对于[10, 9, 9]来说，计算出的损失值就远远高于[10, -100, -100]的。换句话来说，softmax分类器对于分数是永远不会满意的：<strong>正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小。</strong>但是，SVM只要边界值被满足了就满意了，不会超过限制去细微地操作具体分数。这可以被看做是SVM的一种特性。举例说来，一个汽车的分类器应该把他的大量精力放在如何分辨小轿车和大卡车上，而不应该纠结于如何与青蛙进行区分，因为区分青蛙得到的评分已经足够低了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>与kNN分类器不同，参数方法的优势在于一旦通过训练学习到了参数，就可以将训练数据丢弃了。同时该方法对于新的测试数据的预测非常快，因为只需要与权重W进行一个矩阵乘法运算。</li><li>偏差技巧，让我们能够将偏差向量和权重矩阵合二为一，然后就可以只跟踪一个矩阵。</li><li>损失函数（SVM和Softmax线性分类器最常用的2个损失函数）。损失函数能够衡量给出的参数集与训练集数据真实类别情况之间的一致性。在损失函数的定义中可以看到，对训练集数据做出良好预测与得到一个足够低的损失值这两件事是等价的。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit，原文：http://cs231n.github.io/linear-classify/，并进行一定修改。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit，原文：http://cs231n.github.io/linear-classify/，并进行一定修改。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本节课主要介绍线性分类器相关的知识，并将其用于图像分类。&lt;/p&gt;
&lt;h2 id=&quot;线性分类器简介&quot;&gt;&lt;a href=&quot;#线性分类器简介&quot; class=&quot;headerlink&quot; title=&quot;线性分类器简介&quot;&gt;&lt;/a&gt;线性分类器简介&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;评分函数（score function)&lt;/strong&gt;:它是原始图像数据到类别分值的映射。&lt;br&gt;&lt;strong&gt;损失函数（loss function）&lt;/strong&gt;：它是用来量化预测分类标签的得分与真实值之间的一致性。&lt;br&gt;
    
    </summary>
    
      <category term="课程笔记" scheme="https://ilewseu.github.io/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="cs231n" scheme="https://ilewseu.github.io/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>CS231n课程笔记(2)  图像分类</title>
    <link href="https://ilewseu.github.io/2017/12/02/CS231n%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0-%E7%AC%AC2%E8%AF%BE-Image-Calssification/"/>
    <id>https://ilewseu.github.io/2017/12/02/CS231n课程笔记-第2课-Image-Calssification/</id>
    <published>2017-12-02T14:17:23.000Z</published>
    <updated>2017-12-16T16:05:27.102Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转自：<a href="https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit，原文：http://cs231n.github.io/classification/，并根据原文添加了部分内容。" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit，原文：http://cs231n.github.io/classification/，并根据原文添加了部分内容。</a></p></blockquote><h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><p><strong>图像分类问题</strong>，就是对已有的固定的分类标签集合，对于输入的图像，从分类标签集合中找到一个分类标签，最后把分类标签分配给该输入图像。虽然看起来很简单，但是是计算机视觉领域的核心问题之一，并且有着广泛的应用。<br><a id="more"></a><br>例如，以下图为例，图像分类模型读取该多，并生成该图片属于{cat,dog,hat,mug}中各个标签的概率。人类可以直接看到这个图像，但对于计算机来说，看到的确是由数字组成的巨大的3维数组。在此例中，图片的大小为248*400，有3个颜色通道，分别是红、绿和蓝。如此，图像就包含了248*400*3=297600个数字，每个数字都在0-255之间，图像分类的任务就是从这些数字中学习到知识，把该图像分类到“猫”。</p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171127/6i5L21B2E3.jpg?imageslim" alt="mark"><br></div><p><strong>困难和挑战</strong>：对于人类来说，从图片中识别“猫”非常简单，但是对于计算机而言却不是这么简单了。计算机视觉算法在图像识别方面遇到的一些困难：</p><ul><li><strong>视角变化（Viewpoint variation）</strong></li><li><strong>大小变化（Scale variation）</strong></li><li><strong>形变（Deformation)</strong></li><li><strong>遮挡（Occlusion)</strong></li><li><strong>光照条件（Illumination conditions)</strong></li><li><strong>背景干扰（Background clutter）</strong></li><li><strong>类内差异（Intra-class variation）</strong></li></ul><h2 id="数据驱动方法（Data-driven-approach）"><a href="#数据驱动方法（Data-driven-approach）" class="headerlink" title="数据驱动方法（Data-driven approach）"></a>数据驱动方法（Data-driven approach）</h2><p>数据驱动方法类似和教小孩看图识物类似：给计算机很多数据，让计算机进行学习，从而进行分类。该方法的流程如下：</p><ul><li><strong>输入</strong>：输入包含N个图像的集合，每个图像的标签是k种分类标签中的一种。这个集合称为<strong>训练集</strong>。</li><li><strong>学习</strong>：使用训练集来学习每个类到底长什么样。一般称为训练分类器或学习一个模型。</li><li><strong>评价</strong>：让分类器来预测它未见过的图像的分类标签，以此评价分类器的好坏。分类正确的图像数量越多，则分类器的性能越好。</li></ul><h2 id="Nearest-Neighbor分类器"><a href="#Nearest-Neighbor分类器" class="headerlink" title="Nearest Neighbor分类器"></a>Nearest Neighbor分类器</h2><p><strong>图像分类数据集</strong>：CIFAR-10，包含60000张32*32的小图像，数据集包含10中类别，60000张图片被分为包含50000张图片的训练集和包含10000张图片的测试集。下图就是10类的10张随机图片。</p><div align="center"><br><img src="http://of6h3n8h0.bkt.clouddn.com/blog/171127/a1cc26ejj4.jpg?imageslim" alt="mark"><br></div><p>上图的左边是训练样本集，右边：第一列是测试图像，然后第一列的每个图像的右边是使用Nearest Neighbor算法，根据像素的差异，从训练样本集中选出的10张最类似的图片。</p><p><strong>Nearest Neighbor算法</strong>，假设我们拿到包含50000张图片的训练集，对于一个要预测的图片，Nearest Neighbor算法会拿这张测试的图片和训练集中的每个图片去比较，然后将它认为最相似的那个训练集图片的标签赋给这张测试图片。至于判断两张图片是否相似，以及最相似，在本例中，就是比较32*32*3的像素块。最简单的方法就是逐个像素比较，最后将差异值全部加起来。也就是说，将两张图片先转化为向量$I_1$和$I_2$，然后计算$L_1$距离：$$<br>d_1(I_1,I_2)=\sum_p |I_1^p-I_2^p|<br>$$<br>以图片中的一个颜色通道为例来进行说明，两张图片使用$L_1$距离来进行比较。逐个像素求差值，然后将所有差值加起来得到一个数值。如果两张图片一模一样，那么$L_1$距离为0，但是如何两张图片很是不同，那么$L_1$值将会非常大。</p><p><strong>距离选择</strong>：计算向量间的距离方法有很多种，另一个常用的方法为$L_2$距离，从几何的角度看，可以理解为计算两个向量间的欧式距离。</p><p><strong>$L_1$和$L_2$比$L_2$</strong>的比较：在面对两个向量之间的差异时，$L_2$比$L_1$更不能容忍差异。也就是说，相对于一个巨大的差异，$L_2$距离更倾向于接受多个中等程度的差异。$L_1$和$L_2$都是在p-norm常用的特殊形式。</p><h2 id="k-Nearest-Neighbor分类器"><a href="#k-Nearest-Neighbor分类器" class="headerlink" title="k-Nearest Neighbor分类器"></a>k-Nearest Neighbor分类器</h2><p>Nearest Neighbor算法使用最相似的1张图片作为最终的预测结果。k-Nearest Neighbor算法则是找到最相似的k张图片，然后让它们针对测试图片进行投票，最后把票数最高的标签作为对测试图片的标签。当k=1时，K-Nearest Neighbor就变为Nearest Neighbor。从直观上可以看到，更高的k值可以让效果更平滑，使得分类器对于异常值更有抵抗力。</p><p><div align="center"><br>    <img src="http://of6h3n8h0.bkt.clouddn.com/blog/171127/a5i04DGA35.jpg?imageslim" alt="mark"><br></div><br>上图显示了Nearest Neighbor分类器和5-Nearest Neighbor分类器的区别。图中使用了2维的点来表示，分成3类。不同的颜色区域代表使用$L_2$距离的分类器的决策边界。白色的区域是分类模糊的例子（即图像与两个以上的分类标签绑定）。需要注意的是，在NN分类器中，异常的数据制造出一个不正确预测的孤岛。5—NN分类器将这些不规则都平滑了，使得针对测试数据的泛化能力更好。</p><p><strong>用于超参数调优的验证集</strong><br>k-NN分类器需要设定k值，选择哪个k值最合适呢?同样也距离函数也是可选择的，那么选哪个好？这些选择，被称为<strong>超参数（hyperparameter)</strong>。在基于数据进行学习的机器学习算法设计中，朝参数时非常常见的，但是如何选择这些超参数？</p><p>我们可能会尝试不同的值，看哪个值表现最好就选哪个。但这样做的时候要非常小心，特别注意：<strong>决不能使用测试集来进行调优</strong>。在训练机器学习模型时，应该把测试集看做非常宝贵的资源，不到最后一步，绝不使用它。如果使用测试集进行调优，而且算法看起来效果不错，但算法实际部署后，性能可能会远低于预期。这种情况，称之为<strong>过拟合</strong>。<strong>从另一个角度来说，如果使用测试集来调优，实际上就是把测试集当做训练集，由测试集训练出来的算法再跑测试集，自然性能看起来会很好。</strong>这其实是过于乐观了，实际部署起来效果就会差很多。所以，<strong>最终测试的时候再使用测试集，可以很好地近似度量你所设计的分类器的泛化性能</strong>。</p><blockquote><p>测试集只能使用一次，即在训练完成后评价最终的模型时使用。</p></blockquote><p>实际在进行参数调优的过程中，是从训练集中抽取一部分数据用来调优，称之为验证集（validation set）。以CIFAP-10数据集为例，我们可以用49000个图像作为训练集，用1000个图像作为验证集。验证集其实就是作为假的测试集来调优。</p><blockquote><p>把训练集分为训练集和验证集，使用验证集来对超参数进行调优，最后只在测试集上对模型进行评价。</p></blockquote><p><strong>交叉验证</strong>，有时候训练集较小，就会导致验证集的数量更小，人们会使用一种称为交叉验证的方法。这种方法把训练集评价分为K份，用其中的k-1份来训练，另1份来验证。然后循环着取其中的k-1份来训练，其中1份来验证。最后取所有k次验证的结果的平均值作为算法验证结果。<strong>在实际的应用中</strong>，一般会直接把训练集按照50%-90%的比例分为训练集和验证集。但这也是根据具体情况来定的：如果超参数数量较多，可能就想用更大的验证集，而验证集的数量不够，最好还是使用交叉验证。</p><h2 id="Nearest-Neighbor分类器的优劣"><a href="#Nearest-Neighbor分类器的优劣" class="headerlink" title="Nearest Neighbor分类器的优劣"></a>Nearest Neighbor分类器的优劣</h2><ul><li>易于理解，实现简单；</li><li>算法的训练不需要花时间，其训练只需要和所有存储的训练图像进行比较（缺点）；</li><li>虽然训练花费很多时间，但是一旦训练完成，对新的测试数据进行分类非常快。</li></ul><p>Nearset Neighbor分类器在某些特定的情况下，可能是不错的选择。但是在实际的图像分类工作中，很少使用。</p><h2 id="实际应用K-NN的流程"><a href="#实际应用K-NN的流程" class="headerlink" title="实际应用K-NN的流程"></a>实际应用K-NN的流程</h2><ul><li>预处理数据：对数据中的特征进行归一化，让其具有0均值和单位方差（unit variance)。</li><li>如果数据是高维数据，考虑使用降维方法。</li><li>将数据随机分为训练集和测试集。</li><li>在验证机上进行调优，尝试足够多的k值，尝试$L_1$和$L_2$两种距离。</li><li>如果分类器跑得太慢，尝试使用Approximate Nearest Neighbor库（比如FLANN）来加速这个过程，其代价是降低一些准确率。</li><li>对最优的超参数做记录。记录最优参数后，是否应该让使用最优参数的算法在完整的训练集上运行并再次训练呢？因为如果把验证集重新放回到训练集中（自然训练集的数据量就又变大了），有可能最优参数又会有所变化。在实践中，不要这样做。千万不要在最终的分类器中使用验证集数据，这样做会破坏对于最优参数的估计。直接使用测试集来测试用最优参数设置好的最优模型，得到测试集数据的分类准确率，并以此作为你的kNN分类器在该数据上的性能表现。</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>介绍了图像分类问题。在该问题中，给出一个由被标注了分类标签的图像组成的集合，要求算法能预测没有标签的图像的分类标签，并根据算法预测准确率进行评价。</li><li>Nearest Neighbor分类器，分类器中存在不同的超参数(比如k值或距离类型的选取)，要想选取好的超参数不是一件轻而易举的事。</li><li>选取超参数的正确方法是：将原始训练集分为训练集和验证集，我们在验证集上尝试不同的超参数，最后保留表现最好那个。</li><li>如果训练数据量不够，使用交叉验证方法，它能帮助我们在选取最优超参数的时候减少噪音。<br>一旦找到最优的超参数，就让算法以该参数在测试集跑且只跑一次，并根据测试结果评价算法。</li><li>最后，我们知道了仅仅使用L1和L2范数来进行像素比较是不够的，图像更多的是按照背景和颜色被分类，而不是语义主体分身。</li></ul><p>—end—</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit，原文：http://cs231n.github.io/classification/，并根据原文添加了部分内容。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit，原文：http://cs231n.github.io/classification/，并根据原文添加了部分内容。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;图像分类&quot;&gt;&lt;a href=&quot;#图像分类&quot; class=&quot;headerlink&quot; title=&quot;图像分类&quot;&gt;&lt;/a&gt;图像分类&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;图像分类问题&lt;/strong&gt;，就是对已有的固定的分类标签集合，对于输入的图像，从分类标签集合中找到一个分类标签，最后把分类标签分配给该输入图像。虽然看起来很简单，但是是计算机视觉领域的核心问题之一，并且有着广泛的应用。&lt;br&gt;
    
    </summary>
    
      <category term="课程笔记" scheme="https://ilewseu.github.io/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DeepLearning" scheme="https://ilewseu.github.io/tags/DeepLearning/"/>
    
      <category term="cs231n" scheme="https://ilewseu.github.io/tags/cs231n/"/>
    
  </entry>
  
</feed>
